[2025-04-02T09:17:30.342+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-02T09:17:30.539+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_dbt_spark_oracle.spark_load_to_oracle manual__2025-04-02T09:16:41.382092+00:00 [queued]>
[2025-04-02T09:17:30.559+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_dbt_spark_oracle.spark_load_to_oracle manual__2025-04-02T09:16:41.382092+00:00 [queued]>
[2025-04-02T09:17:30.560+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 1
[2025-04-02T09:17:30.586+0000] {taskinstance.py:2890} INFO - Executing <Task(BashOperator): spark_load_to_oracle> on 2025-04-02 09:16:41.382092+00:00
[2025-04-02T09:17:30.594+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=2746) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-02T09:17:30.596+0000] {standard_task_runner.py:72} INFO - Started process 2748 to run task
[2025-04-02T09:17:30.596+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'etl_dbt_spark_oracle', 'spark_load_to_oracle', 'manual__2025-04-02T09:16:41.382092+00:00', '--job-id', '26', '--raw', '--subdir', 'DAGS_FOLDER/dbt-spark-oracle.py', '--cfg-path', '/tmp/tmpy3gxgju_']
[2025-04-02T09:17:30.600+0000] {standard_task_runner.py:105} INFO - Job 26: Subtask spark_load_to_oracle
[2025-04-02T09:17:30.658+0000] {task_command.py:467} INFO - Running <TaskInstance: etl_dbt_spark_oracle.spark_load_to_oracle manual__2025-04-02T09:16:41.382092+00:00 [running]> on host a72b9165479b
[2025-04-02T09:17:30.781+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='etl_dbt_spark_oracle' AIRFLOW_CTX_TASK_ID='spark_load_to_oracle' AIRFLOW_CTX_EXECUTION_DATE='2025-04-02T09:16:41.382092+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-04-02T09:16:41.382092+00:00'
[2025-04-02T09:17:30.783+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-02T09:17:30.784+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-02T09:17:30.785+0000] {logging_mixin.py:190} INFO - Current task name:spark_load_to_oracle state:running start_date:2025-04-02 09:17:30.540215+00:00
[2025-04-02T09:17:30.786+0000] {logging_mixin.py:190} INFO - Dag name:etl_dbt_spark_oracle and current dag run status:running
[2025-04-02T09:17:30.787+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-02T09:17:30.789+0000] {subprocess.py:78} INFO - Tmp dir root location: /tmp
[2025-04-02T09:17:30.791+0000] {subprocess.py:88} INFO - Running command: ['/usr/bin/bash', '-c', 'cd /opt/spark && /opt/spark/sbin/stop-thriftserver.sh && spark-submit /spark/etl_to_oracle.py']
[2025-04-02T09:17:30.809+0000] {subprocess.py:99} INFO - Output:
[2025-04-02T09:17:30.831+0000] {subprocess.py:106} INFO - /opt/spark/bin/load-spark-env.sh: line 68: ps: command not found
[2025-04-02T09:17:30.844+0000] {subprocess.py:106} INFO - /opt/spark/sbin/spark-daemon.sh: line 214: ps: command not found
[2025-04-02T09:17:30.845+0000] {subprocess.py:106} INFO - no org.apache.spark.sql.hive.thriftserver.HiveThriftServer2 to stop
[2025-04-02T09:17:30.852+0000] {subprocess.py:106} INFO - /opt/spark/bin/load-spark-env.sh: line 68: ps: command not found
[2025-04-02T09:17:36.170+0000] {subprocess.py:106} INFO - 25/04/02 09:17:36 INFO SparkContext: Running Spark version 3.5.5
[2025-04-02T09:17:36.176+0000] {subprocess.py:106} INFO - 25/04/02 09:17:36 INFO SparkContext: OS info Linux, 6.12.5-linuxkit, amd64
[2025-04-02T09:17:36.177+0000] {subprocess.py:106} INFO - 25/04/02 09:17:36 INFO SparkContext: Java version 21
[2025-04-02T09:17:36.324+0000] {subprocess.py:106} INFO - 25/04/02 09:17:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2025-04-02T09:17:36.468+0000] {subprocess.py:106} INFO - 25/04/02 09:17:36 INFO ResourceUtils: ==============================================================
[2025-04-02T09:17:36.469+0000] {subprocess.py:106} INFO - 25/04/02 09:17:36 INFO ResourceUtils: No custom resources configured for spark.driver.
[2025-04-02T09:17:36.470+0000] {subprocess.py:106} INFO - 25/04/02 09:17:36 INFO ResourceUtils: ==============================================================
[2025-04-02T09:17:36.471+0000] {subprocess.py:106} INFO - 25/04/02 09:17:36 INFO SparkContext: Submitted application: ETL Spark to Oracle
[2025-04-02T09:17:36.507+0000] {subprocess.py:106} INFO - 25/04/02 09:17:36 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-04-02T09:17:36.517+0000] {subprocess.py:106} INFO - 25/04/02 09:17:36 INFO ResourceProfile: Limiting resource is cpu
[2025-04-02T09:17:36.518+0000] {subprocess.py:106} INFO - 25/04/02 09:17:36 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2025-04-02T09:17:36.597+0000] {subprocess.py:106} INFO - 25/04/02 09:17:36 INFO SecurityManager: Changing view acls to: ***
[2025-04-02T09:17:36.598+0000] {subprocess.py:106} INFO - 25/04/02 09:17:36 INFO SecurityManager: Changing modify acls to: ***
[2025-04-02T09:17:36.599+0000] {subprocess.py:106} INFO - 25/04/02 09:17:36 INFO SecurityManager: Changing view acls groups to:
[2025-04-02T09:17:36.600+0000] {subprocess.py:106} INFO - 25/04/02 09:17:36 INFO SecurityManager: Changing modify acls groups to:
[2025-04-02T09:17:36.601+0000] {subprocess.py:106} INFO - 25/04/02 09:17:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ***; groups with view permissions: EMPTY; users with modify permissions: ***; groups with modify permissions: EMPTY
[2025-04-02T09:17:37.077+0000] {subprocess.py:106} INFO - 25/04/02 09:17:37 INFO Utils: Successfully started service 'sparkDriver' on port 39365.
[2025-04-02T09:17:37.145+0000] {subprocess.py:106} INFO - 25/04/02 09:17:37 INFO SparkEnv: Registering MapOutputTracker
[2025-04-02T09:17:37.196+0000] {subprocess.py:106} INFO - 25/04/02 09:17:37 INFO SparkEnv: Registering BlockManagerMaster
[2025-04-02T09:17:37.232+0000] {subprocess.py:106} INFO - 25/04/02 09:17:37 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-04-02T09:17:37.233+0000] {subprocess.py:106} INFO - 25/04/02 09:17:37 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2025-04-02T09:17:37.240+0000] {subprocess.py:106} INFO - 25/04/02 09:17:37 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2025-04-02T09:17:37.278+0000] {subprocess.py:106} INFO - 25/04/02 09:17:37 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-3f0ce41c-2974-4b95-a08e-8611a5269289
[2025-04-02T09:17:37.305+0000] {subprocess.py:106} INFO - 25/04/02 09:17:37 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2025-04-02T09:17:37.323+0000] {subprocess.py:106} INFO - 25/04/02 09:17:37 INFO SparkEnv: Registering OutputCommitCoordinator
[2025-04-02T09:17:37.503+0000] {subprocess.py:106} INFO - 25/04/02 09:17:37 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[2025-04-02T09:17:37.585+0000] {subprocess.py:106} INFO - 25/04/02 09:17:37 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[2025-04-02T09:17:37.605+0000] {subprocess.py:106} INFO - 25/04/02 09:17:37 INFO Utils: Successfully started service 'SparkUI' on port 4041.
[2025-04-02T09:17:37.673+0000] {subprocess.py:106} INFO - 25/04/02 09:17:37 INFO SparkContext: Added JAR /opt/spark/jars/ojdbc17.jar at spark://a72b9165479b:39365/jars/ojdbc17.jar with timestamp 1743585456147
[2025-04-02T09:17:37.766+0000] {subprocess.py:106} INFO - 25/04/02 09:17:37 INFO Executor: Starting executor ID driver on host a72b9165479b
[2025-04-02T09:17:37.769+0000] {subprocess.py:106} INFO - 25/04/02 09:17:37 INFO Executor: OS info Linux, 6.12.5-linuxkit, amd64
[2025-04-02T09:17:37.771+0000] {subprocess.py:106} INFO - 25/04/02 09:17:37 INFO Executor: Java version 21
[2025-04-02T09:17:37.781+0000] {subprocess.py:106} INFO - 25/04/02 09:17:37 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
[2025-04-02T09:17:37.783+0000] {subprocess.py:106} INFO - 25/04/02 09:17:37 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@18ae5f31 for default.
[2025-04-02T09:17:37.797+0000] {subprocess.py:106} INFO - 25/04/02 09:17:37 INFO Executor: Fetching spark://a72b9165479b:39365/jars/ojdbc17.jar with timestamp 1743585456147
[2025-04-02T09:17:37.865+0000] {subprocess.py:106} INFO - 25/04/02 09:17:37 INFO TransportClientFactory: Successfully created connection to a72b9165479b/172.18.0.6:39365 after 37 ms (0 ms spent in bootstraps)
[2025-04-02T09:17:37.875+0000] {subprocess.py:106} INFO - 25/04/02 09:17:37 INFO Utils: Fetching spark://a72b9165479b:39365/jars/ojdbc17.jar to /tmp/spark-b225fb5e-6c08-4f4f-ba48-dfb9c4f10467/userFiles-ed707d9a-e8c1-44ce-95db-d992748af41e/fetchFileTemp688695833355266968.tmp
[2025-04-02T09:17:37.960+0000] {subprocess.py:106} INFO - 25/04/02 09:17:37 INFO Executor: Adding file:/tmp/spark-b225fb5e-6c08-4f4f-ba48-dfb9c4f10467/userFiles-ed707d9a-e8c1-44ce-95db-d992748af41e/ojdbc17.jar to class loader default
[2025-04-02T09:17:37.984+0000] {subprocess.py:106} INFO - 25/04/02 09:17:37 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39593.
[2025-04-02T09:17:37.985+0000] {subprocess.py:106} INFO - 25/04/02 09:17:37 INFO NettyBlockTransferService: Server created on a72b9165479b:39593
[2025-04-02T09:17:37.988+0000] {subprocess.py:106} INFO - 25/04/02 09:17:37 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-04-02T09:17:37.997+0000] {subprocess.py:106} INFO - 25/04/02 09:17:37 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, a72b9165479b, 39593, None)
[2025-04-02T09:17:38.004+0000] {subprocess.py:106} INFO - 25/04/02 09:17:38 INFO BlockManagerMasterEndpoint: Registering block manager a72b9165479b:39593 with 434.4 MiB RAM, BlockManagerId(driver, a72b9165479b, 39593, None)
[2025-04-02T09:17:38.007+0000] {subprocess.py:106} INFO - 25/04/02 09:17:38 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, a72b9165479b, 39593, None)
[2025-04-02T09:17:38.009+0000] {subprocess.py:106} INFO - 25/04/02 09:17:38 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, a72b9165479b, 39593, None)
[2025-04-02T09:17:38.708+0000] {subprocess.py:106} INFO - Processing table default.transformed_data to METADATA.TEST
[2025-04-02T09:17:38.830+0000] {subprocess.py:106} INFO - 25/04/02 09:17:38 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-04-02T09:17:38.842+0000] {subprocess.py:106} INFO - 25/04/02 09:17:38 INFO SharedState: Warehouse path is 'file:/opt/spark/spark-warehouse'.
[2025-04-02T09:17:40.624+0000] {subprocess.py:106} INFO - 25/04/02 09:17:40 INFO HiveConf: Found configuration file null
[2025-04-02T09:17:40.639+0000] {subprocess.py:106} INFO - 25/04/02 09:17:40 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
[2025-04-02T09:17:41.028+0000] {subprocess.py:106} INFO - 25/04/02 09:17:41 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/opt/spark/spark-warehouse
[2025-04-02T09:17:41.365+0000] {subprocess.py:106} INFO - 25/04/02 09:17:41 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
[2025-04-02T09:17:41.367+0000] {subprocess.py:106} INFO - 25/04/02 09:17:41 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
[2025-04-02T09:17:41.369+0000] {subprocess.py:106} INFO - 25/04/02 09:17:41 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
[2025-04-02T09:17:41.438+0000] {subprocess.py:106} INFO - 25/04/02 09:17:41 INFO ObjectStore: ObjectStore, initialize called
[2025-04-02T09:17:41.631+0000] {subprocess.py:106} INFO - 25/04/02 09:17:41 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
[2025-04-02T09:17:41.632+0000] {subprocess.py:106} INFO - 25/04/02 09:17:41 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
[2025-04-02T09:17:42.234+0000] {subprocess.py:106} INFO - 25/04/02 09:17:42 ERROR Schema: Failed initialising database.
[2025-04-02T09:17:42.235+0000] {subprocess.py:106} INFO - Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:42.237+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:42.238+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:42.240+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:42.241+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:42.243+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:42.243+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:42.246+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:42.246+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:42.248+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:42.249+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:42.249+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:42.250+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:42.252+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:42.253+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:42.254+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:42.255+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:42.255+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:42.256+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:42.257+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:42.258+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:42.258+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:42.259+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:42.260+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:42.261+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:42.261+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:42.262+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:42.263+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:42.264+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:42.265+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:42.265+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:42.266+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:42.267+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:42.268+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:42.269+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:42.270+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:42.273+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:42.274+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:42.274+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:42.275+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:42.276+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:42.277+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:42.278+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:42.279+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:42.280+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:42.280+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:42.281+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:42.282+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:42.283+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:42.284+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:42.285+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:42.286+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:42.287+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:42.288+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:42.290+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:42.290+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:42.291+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:42.292+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:42.293+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:42.294+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:42.295+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:42.295+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:42.296+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:42.297+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:42.297+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:42.298+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:42.299+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:42.300+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:42.301+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:42.302+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:42.302+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:42.303+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:42.304+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:42.305+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:42.306+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:42.307+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:42.308+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:42.308+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:42.309+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:42.310+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:42.311+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:42.312+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:42.313+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:42.314+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:42.316+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:42.317+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:42.318+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:42.319+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:42.320+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:42.321+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:42.323+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:42.324+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:42.325+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:42.326+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:42.327+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:42.328+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:42.331+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:42.332+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:42.333+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:42.334+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:42.335+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:42.336+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:42.337+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:42.338+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:42.340+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:42.341+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:42.342+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:42.343+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:42.345+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:42.346+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:42.347+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:42.348+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:42.349+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:42.350+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:42.350+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:42.351+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:42.352+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:42.354+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:42.356+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:42.357+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:42.358+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:42.359+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:42.360+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:42.361+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:42.362+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:42.363+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:42.364+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:42.365+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:42.366+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:42.368+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:42.369+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:42.371+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:42.372+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:42.374+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:42.375+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:42.376+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:42.377+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:42.378+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:42.379+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:42.380+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:42.382+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:42.383+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:42.384+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:42.385+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:42.386+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:42.387+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:42.388+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:42.389+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:42.391+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:42.391+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:42.392+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:42.393+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:42.394+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:42.395+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:42.395+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:42.396+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:42.398+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:42.400+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:42.401+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:42.402+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:42.404+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:42.405+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:42.407+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:42.408+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:42.410+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:42.412+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:42.413+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:42.414+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:42.415+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:42.416+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:42.417+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:42.418+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:42.420+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:42.421+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:42.422+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:42.424+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:42.425+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:42.426+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:42.427+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:42.428+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:42.429+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:42.430+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:42.431+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:42.432+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:42.433+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:42.434+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:42.435+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:42.437+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:42.438+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:42.438+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:42.439+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:42.440+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:42.442+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:42.443+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:42.444+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:42.445+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:42.445+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:42.446+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:42.447+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:42.448+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:42.449+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:42.450+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:42.451+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:42.451+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:42.452+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:42.454+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:42.455+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:42.456+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:42.457+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:42.458+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:42.459+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:42.461+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:42.461+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:42.462+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:42.463+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:42.464+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:42.465+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:42.466+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:42.467+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:42.468+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:42.469+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:42.470+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:42.471+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:42.472+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:42.473+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:42.474+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:42.475+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:42.475+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:42.476+0000] {subprocess.py:106} INFO - org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:42.477+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:42.479+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:42.480+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:42.481+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:42.481+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:42.482+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:42.483+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:42.484+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:42.484+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:42.485+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:42.487+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:42.488+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:42.489+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:42.490+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:42.491+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:42.492+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:42.493+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:42.494+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:42.495+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:42.496+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:42.497+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:42.498+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:42.499+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:42.499+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:42.500+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:42.501+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:42.503+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:42.504+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:42.505+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:42.506+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:42.507+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:42.508+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:42.509+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:42.509+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:42.510+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:42.511+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:42.511+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:42.512+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:42.513+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:42.514+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:42.515+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:42.516+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:42.517+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:42.518+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:42.520+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:42.521+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:42.522+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:42.523+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:42.525+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:42.526+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:42.526+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:42.527+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:42.528+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:42.529+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:42.530+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:42.531+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:42.532+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:42.533+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:42.534+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:42.535+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:42.536+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:42.537+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:42.538+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:42.539+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:42.540+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:42.541+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:42.542+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:42.543+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:42.543+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:42.544+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:42.545+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:42.545+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:42.546+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:42.546+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:42.547+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:42.548+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:42.548+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:42.549+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:42.550+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:42.550+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:42.551+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:42.552+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:42.553+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:42.554+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:42.555+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:42.556+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:42.557+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:42.558+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:42.559+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:42.560+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:42.561+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:42.562+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:42.562+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:42.563+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:42.564+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:42.564+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:42.565+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:42.566+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:42.566+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:42.568+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:42.569+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:42.570+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:42.570+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:42.571+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:42.572+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:42.572+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:42.573+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:42.574+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:42.575+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:42.575+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:42.576+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:42.577+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:42.578+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:42.579+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:42.580+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:42.580+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:42.581+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:42.582+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:42.583+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:42.584+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:42.585+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:42.585+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:42.586+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:42.587+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:42.588+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:42.588+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:42.589+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:42.590+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:42.591+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:42.592+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:42.592+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:42.593+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:42.594+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:42.595+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:42.595+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:42.596+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:42.597+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:42.597+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:42.598+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:42.598+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:42.599+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:42.599+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:42.600+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:42.600+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:42.601+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:42.602+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:42.603+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:42.604+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:42.604+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:42.605+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:42.606+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:42.607+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:42.607+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:42.608+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:42.610+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:42.610+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:42.611+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:42.612+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:42.614+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:42.615+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:42.616+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:42.617+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:42.617+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:42.618+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:42.619+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:42.620+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:42.620+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:42.621+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:42.622+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:42.622+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:42.623+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:42.624+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:42.625+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:42.626+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:42.627+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:42.627+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:42.628+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:42.629+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:42.630+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:42.630+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:42.631+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:42.632+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:42.633+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:42.634+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:42.635+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:42.637+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:42.640+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:42.641+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:42.642+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:42.643+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:42.643+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:42.643+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:42.644+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:42.644+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:42.645+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:42.645+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:42.646+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:42.646+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:42.647+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:42.647+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:42.648+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:42.648+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:42.648+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:42.649+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:42.650+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:42.650+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:42.651+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:42.652+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:42.653+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:42.654+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:42.655+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:42.656+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:42.657+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:42.657+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:42.658+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:42.659+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:42.660+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:42.661+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:42.661+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:42.662+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:42.663+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:42.663+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:42.664+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:42.664+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:42.665+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:42.665+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:42.666+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:42.666+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)
[2025-04-02T09:17:42.666+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:42.667+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:42.668+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:42.669+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:42.670+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:42.670+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:42.671+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:42.672+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:42.672+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:42.673+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:42.674+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:42.675+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:42.676+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:42.677+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:42.678+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:42.678+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:42.679+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:42.680+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:42.680+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:42.681+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:42.682+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:42.683+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:42.683+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:42.684+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:42.685+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:42.686+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:42.687+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:42.688+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:42.689+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:42.690+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:42.690+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:42.691+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:42.692+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:42.692+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:42.693+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:42.694+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:42.695+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:42.695+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:42.696+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:42.697+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:42.698+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:42.698+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:42.699+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:42.700+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:42.700+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:42.701+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:42.702+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:42.703+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:42.703+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:42.704+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:42.704+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:42.705+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:42.706+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:42.707+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:42.708+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:42.708+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:42.709+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:42.709+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:42.710+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:42.711+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:42.711+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:42.712+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:42.713+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:42.713+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:42.714+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:42.715+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:42.715+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:42.716+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:42.717+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:42.718+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:42.718+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:42.719+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:42.720+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:42.721+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:42.721+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:42.722+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:42.723+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:42.723+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:42.724+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:42.725+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:42.725+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:42.726+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:42.726+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:42.727+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:42.727+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:42.728+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:42.729+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:42.729+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:42.730+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:42.730+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:42.731+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:42.732+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:42.732+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:42.733+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:42.734+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:42.735+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:42.735+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:42.736+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:42.737+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:42.737+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:42.738+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:42.739+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:42.739+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:42.740+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:42.740+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:42.741+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:42.742+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:42.742+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:42.743+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:42.744+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:42.744+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:42.745+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:42.746+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:42.747+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:42.747+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:42.748+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:42.748+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:42.749+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:42.750+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:42.750+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:42.751+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:42.752+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:42.753+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:42.753+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:42.754+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:42.754+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:42.755+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:42.756+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:42.757+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:42.757+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:42.758+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:42.758+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:42.759+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:42.759+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:42.760+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:42.761+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:42.761+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:42.762+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:42.762+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:42.763+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:42.764+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:42.765+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:42.765+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:42.766+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:42.766+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:42.767+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:42.768+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:42.769+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:42.770+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:42.771+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:42.771+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:42.772+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:42.773+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:42.774+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:42.775+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:42.775+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:42.776+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:42.776+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:42.777+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:42.778+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:42.778+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:42.779+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:42.780+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:42.780+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:42.781+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:42.781+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:42.782+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:42.782+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:42.783+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:42.784+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:42.785+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:42.786+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:42.787+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:42.787+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:42.788+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:42.789+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:42.790+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:42.790+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:42.791+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:42.792+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:42.793+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:42.794+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:42.795+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:42.795+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:42.796+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:42.797+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:42.797+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:42.798+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:42.799+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:42.799+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:42.800+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:42.801+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:42.802+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:42.802+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:42.803+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:42.804+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:42.805+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:42.805+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:42.806+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:42.807+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:42.807+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:42.808+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:42.809+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:42.809+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:42.810+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:42.811+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:42.811+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:42.812+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:42.813+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:42.813+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:42.814+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:42.815+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:42.815+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:42.816+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:42.816+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:42.817+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:42.818+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:42.818+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:42.819+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:42.820+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:42.821+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:42.822+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:42.822+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:42.823+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:42.824+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:42.824+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:42.825+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:42.825+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:42.826+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:42.827+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:42.827+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:42.828+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:42.828+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:42.829+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:42.830+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:42.830+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:42.831+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:42.832+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:42.832+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:42.833+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:42.834+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:42.834+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:42.835+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:42.836+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:42.837+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:42.837+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:42.838+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:42.838+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:42.839+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:42.840+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:42.840+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:42.841+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:42.842+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:42.842+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:42.843+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:42.844+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:42.844+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:42.845+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:42.846+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:42.846+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:42.847+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:42.848+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:42.848+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:42.849+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:42.850+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:42.850+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:42.851+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:42.852+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:42.853+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:42.853+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:42.854+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:42.855+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:42.856+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:42.856+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:42.857+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:42.857+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:42.858+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:42.859+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:42.859+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:42.860+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:42.861+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:42.861+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:42.862+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:42.863+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:42.863+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:42.864+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:42.864+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:42.865+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:42.865+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:42.866+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:42.867+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:42.867+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:42.868+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:42.869+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:42.869+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:42.870+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:42.871+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:42.872+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:42.872+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:42.873+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:42.874+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:42.874+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:42.875+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:42.876+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:42.877+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:42.877+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:42.878+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:42.878+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:42.879+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:42.879+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:42.880+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:42.880+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:42.881+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:42.882+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:42.882+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:42.883+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:42.883+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:42.884+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:42.885+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:42.886+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:42.886+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:42.887+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:42.888+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:42.889+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:42.889+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:42.890+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:42.891+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:42.892+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:42.892+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:42.893+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:42.894+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:42.894+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:42.895+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:42.896+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:42.896+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:42.897+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:42.898+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:42.898+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:42.899+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:42.900+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:42.900+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:42.901+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:42.902+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:42.903+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:42.904+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:42.904+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:42.905+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:42.906+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:42.906+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:42.907+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:42.907+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:42.908+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:42.909+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:42.909+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:42.910+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:42.910+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:42.911+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:42.912+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:42.912+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:42.913+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:42.913+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:42.914+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:42.915+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:42.916+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:42.916+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:42.917+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:42.918+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:42.918+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:42.919+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:42.920+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:42.921+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:42.922+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:42.922+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:42.923+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:42.924+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:42.924+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:42.925+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:42.926+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:42.926+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:42.927+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:42.928+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:42.928+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:42.929+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:42.929+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:42.930+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:42.931+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:42.931+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:42.932+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)
[2025-04-02T09:17:42.932+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)
[2025-04-02T09:17:42.933+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:42.933+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:42.934+0000] {subprocess.py:106} INFO - 	... 154 more
[2025-04-02T09:17:42.935+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:42.936+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:42.937+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:42.937+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:42.938+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:42.939+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:42.939+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:42.940+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:42.941+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:42.941+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:42.942+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:42.943+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:42.943+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:42.944+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:42.945+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:42.945+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:42.946+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:42.947+0000] {subprocess.py:106} INFO - 	... 156 more
[2025-04-02T09:17:42.947+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:42.948+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:42.949+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:42.949+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:42.950+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:42.950+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:42.951+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:42.952+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:42.953+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:42.954+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:42.954+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:42.955+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:42.955+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:42.956+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:42.957+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:42.957+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:42.958+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:42.959+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:42.960+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:42.960+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:42.961+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:42.962+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:42.962+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:42.963+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:42.963+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:42.964+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:42.965+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:42.965+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:42.966+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:42.967+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:42.967+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:42.968+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:42.969+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:42.970+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:42.970+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:42.971+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:42.972+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:42.972+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:42.973+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:42.974+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:42.975+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:42.975+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:42.976+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:42.976+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:42.977+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:42.978+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:42.979+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:42.979+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:42.980+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:42.981+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:42.982+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:42.983+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:42.983+0000] {subprocess.py:106} INFO - Nested Throwables StackTrace:
[2025-04-02T09:17:42.984+0000] {subprocess.py:106} INFO - java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:42.985+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:42.986+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:42.987+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:42.988+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:42.989+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:42.990+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:42.991+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:42.991+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:42.992+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:42.993+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:42.994+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:42.994+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:42.995+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:42.996+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:42.996+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:42.997+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:42.997+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:42.998+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:42.998+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:42.999+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:43.000+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:43.001+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:43.001+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:43.002+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:43.003+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:43.004+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:43.005+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:43.005+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:43.006+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:43.007+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:43.007+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:43.008+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:43.009+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:43.009+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:43.010+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:43.011+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:43.011+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:43.012+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:43.013+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:43.013+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:43.014+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:43.015+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:43.015+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:43.016+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:43.017+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:43.017+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:43.018+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:43.019+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:43.020+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:43.021+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:43.021+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:43.022+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:43.023+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:43.024+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:43.025+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:43.025+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:43.026+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:43.027+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:43.027+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:43.028+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:43.029+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:43.029+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:43.030+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:43.031+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:43.032+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:43.032+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:43.033+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:43.033+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:43.034+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:43.035+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:43.036+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:43.036+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:43.037+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:43.038+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:43.039+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:43.039+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:43.040+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:43.041+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:43.041+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:43.042+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:43.043+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:43.043+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:43.044+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:43.045+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:43.045+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:43.046+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:43.047+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:43.047+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:43.048+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:43.049+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:43.049+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:43.050+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:43.051+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:43.051+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:43.052+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:43.053+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:43.054+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:43.054+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:43.055+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:43.056+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:43.056+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:43.057+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:43.058+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:43.058+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:43.059+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:43.059+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:43.060+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:43.060+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:43.061+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:43.062+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:43.062+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:43.063+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:43.064+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:43.064+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:43.065+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:43.066+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:43.067+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:43.067+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:43.068+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:43.069+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:43.070+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:43.070+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:43.071+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:43.072+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:43.073+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:43.073+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:43.074+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:43.075+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:43.075+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:43.076+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:43.077+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:43.078+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:43.078+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:43.079+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:43.080+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:43.080+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:43.081+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:43.081+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:43.082+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:43.083+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:43.083+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:43.084+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:43.085+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:43.086+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:43.087+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:43.087+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:43.088+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:43.088+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:43.089+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:43.090+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:43.090+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:43.091+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:43.091+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:43.092+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:43.093+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:43.093+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:43.094+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:43.095+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:43.096+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:43.096+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:43.097+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:43.097+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:43.098+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:43.099+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:43.100+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:43.100+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:43.101+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:43.102+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:43.103+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:43.104+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:43.104+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:43.105+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:43.106+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:43.106+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:43.107+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:43.108+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:43.109+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:43.109+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:43.110+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:43.110+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:43.111+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:43.112+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:43.112+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:43.113+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:43.114+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:43.114+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:43.115+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:43.116+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:43.116+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:43.117+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:43.118+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:43.119+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:43.120+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:43.120+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:43.121+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:43.122+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:43.123+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:43.123+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:43.124+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:43.125+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:43.126+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:43.127+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:43.127+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:43.128+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:43.129+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:43.130+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:43.131+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:43.131+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:43.132+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:43.133+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:43.134+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:43.134+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:43.135+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:43.136+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:43.137+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:43.138+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:43.139+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:43.139+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:43.140+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:43.141+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:43.142+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:43.143+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:43.143+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:43.144+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:43.145+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:43.146+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:43.146+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:43.147+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:43.148+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:43.149+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:43.149+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:43.150+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:43.151+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)
[2025-04-02T09:17:43.152+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)
[2025-04-02T09:17:43.153+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:43.153+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:43.154+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:43.155+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:43.156+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:43.157+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:43.158+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:43.158+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:43.159+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:43.160+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:43.160+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:43.161+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:43.162+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:43.163+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:43.163+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:43.164+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:43.165+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:43.166+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:43.167+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:43.170+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:43.171+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:43.171+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:43.172+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:43.173+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:43.174+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:43.175+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:43.175+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:43.176+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:43.176+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:43.177+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:43.179+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:43.180+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:43.181+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:43.181+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:43.182+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:43.183+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:43.184+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:43.185+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:43.186+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:43.187+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:43.188+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:43.189+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:43.189+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:43.190+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:43.191+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:43.192+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:43.192+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:43.193+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:43.194+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:43.195+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:43.195+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:43.196+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:43.197+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:43.198+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:43.198+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:43.199+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:43.200+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:43.200+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:43.201+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:43.202+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:43.203+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:43.204+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:43.204+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:43.205+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:43.206+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:43.207+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:43.208+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:43.209+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:43.209+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:43.210+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:43.211+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:43.211+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:43.212+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:43.213+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:43.213+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:43.214+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:43.215+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:43.215+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:43.216+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:43.216+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:43.217+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:43.218+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:43.219+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:43.220+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:43.220+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:43.221+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:43.222+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:43.223+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:43.224+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:43.224+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:43.225+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:43.226+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:43.226+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:43.227+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:43.228+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:43.229+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:43.229+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:43.230+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:43.231+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:43.231+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:43.232+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:43.233+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:43.233+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:43.234+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:43.235+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:43.236+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:43.237+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:43.237+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:43.238+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:43.239+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:43.240+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:43.241+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:43.241+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:43.242+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:43.242+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:43.243+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:43.244+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:43.245+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:43.245+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:43.246+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:43.247+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:43.248+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:43.248+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:43.249+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:43.250+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:43.250+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:43.251+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:43.252+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:43.253+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:43.254+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:43.255+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:43.255+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:43.256+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:43.257+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:43.258+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:43.265+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:43.266+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:43.266+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:43.267+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:43.268+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:43.269+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:43.269+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:43.270+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:43.271+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:43.272+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:43.272+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:43.273+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:43.274+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:43.275+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:43.276+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:43.277+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:43.277+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:43.278+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:43.279+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:43.279+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:43.280+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:43.281+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:43.281+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:43.282+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:43.283+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:43.283+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:43.284+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:43.285+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:43.286+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:43.287+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:43.287+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:43.288+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:43.289+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:43.290+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:43.290+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:43.291+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:43.292+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:43.292+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:43.293+0000] {subprocess.py:106} INFO - 	... 156 more
[2025-04-02T09:17:43.294+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:43.295+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:43.295+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:43.296+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:43.297+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:43.297+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:43.298+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:43.299+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:43.300+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:43.300+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:43.301+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:43.302+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:43.303+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:43.304+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:43.304+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:43.305+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:43.306+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:43.307+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:43.308+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:43.308+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:43.309+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:43.310+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:43.310+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:43.311+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:43.312+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:43.312+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:43.313+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:43.314+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:43.315+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:43.316+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:43.316+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:43.317+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:43.318+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:43.319+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:43.320+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:43.321+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:43.322+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:43.323+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:43.324+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:43.325+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:43.325+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:43.328+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:43.328+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:43.329+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:43.330+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:43.330+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:43.331+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:43.331+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:43.332+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:43.332+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:43.333+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:43.334+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:43.335+0000] {subprocess.py:106} INFO - 25/04/02 09:17:42 ERROR Datastore: Exception thrown creating StoreManager. See the nested exception
[2025-04-02T09:17:43.336+0000] {subprocess.py:106} INFO - Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:43.337+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:43.337+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:43.338+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:43.339+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:43.340+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:43.341+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:43.341+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:43.342+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:43.343+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:43.343+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:43.344+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:43.345+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:43.345+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:43.346+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:43.346+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:43.347+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:43.347+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:43.348+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:43.348+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:43.350+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:43.351+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:43.352+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:43.353+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:43.353+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:43.354+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:43.354+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:43.355+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:43.355+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:43.356+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:43.356+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:43.357+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:43.357+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:43.358+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:43.359+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:43.360+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:43.360+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:43.361+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:43.362+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:43.363+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:43.364+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:43.364+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:43.365+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:43.366+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:43.367+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:43.368+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:43.368+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:43.370+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:43.371+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:43.377+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:43.381+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:43.381+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:43.382+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:43.382+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:43.383+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:43.384+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:43.385+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:43.386+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:43.387+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:43.388+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:43.389+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:43.390+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:43.395+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:43.396+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:43.397+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:43.397+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:43.398+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:43.398+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:43.399+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:43.399+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:43.400+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:43.400+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:43.401+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:43.402+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:43.402+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:43.403+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:43.404+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:43.404+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:43.405+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:43.405+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:43.406+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:43.407+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:43.407+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:43.408+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:43.408+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:43.409+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:43.410+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:43.410+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:43.411+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:43.412+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:43.413+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:43.414+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:43.414+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:43.415+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:43.416+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:43.417+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:43.417+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:43.418+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:43.419+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:43.420+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:43.422+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:43.423+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:43.424+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:43.425+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:43.426+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:43.428+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:43.429+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:43.430+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:43.431+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:43.431+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:43.432+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:43.433+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:43.434+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:43.435+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:43.436+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:43.437+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:43.438+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:43.438+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:43.439+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:43.440+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:43.441+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:43.442+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:43.443+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:43.447+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:43.447+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:43.448+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:43.449+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:43.449+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:43.450+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:43.451+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:43.452+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:43.453+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:43.454+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:43.455+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:43.458+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:43.459+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:43.463+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:43.464+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:43.465+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:43.466+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:43.467+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:43.467+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:43.468+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:43.469+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:43.470+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:43.472+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:43.473+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:43.474+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:43.475+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:43.477+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:43.478+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:43.479+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:43.480+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:43.481+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:43.482+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:43.482+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:43.483+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:43.484+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:43.485+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:43.487+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:43.488+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:43.490+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:43.492+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:43.494+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:43.495+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:43.497+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:43.498+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:43.499+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:43.501+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:43.502+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:43.504+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:43.505+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:43.507+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:43.508+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:43.509+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:43.510+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:43.511+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:43.512+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:43.513+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:43.514+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:43.515+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:43.515+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:43.516+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:43.517+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:43.518+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:43.519+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:43.521+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:43.522+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:43.523+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:43.525+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:43.526+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:43.527+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:43.528+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:43.529+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:43.530+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:43.531+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:43.532+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:43.533+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:43.535+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:43.536+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:43.538+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:43.539+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:43.540+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:43.541+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:43.542+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:43.542+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:43.543+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:43.544+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:43.544+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:43.545+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:43.545+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:43.546+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:43.547+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:43.548+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:43.548+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:43.549+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:43.550+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:43.550+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:43.552+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:43.552+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:43.553+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:43.554+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:43.555+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:43.556+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:43.557+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:43.558+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:43.559+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:43.559+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:43.560+0000] {subprocess.py:106} INFO - org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:43.561+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:43.562+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:43.562+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:43.563+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:43.564+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:43.564+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:43.565+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:43.566+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:43.567+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:43.567+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:43.568+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:43.570+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:43.571+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:43.577+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:43.578+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:43.580+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:43.580+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:43.581+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:43.582+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:43.583+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:43.584+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:43.585+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:43.585+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:43.587+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:43.587+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:43.588+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:43.590+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:43.596+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:43.597+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:43.598+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:43.598+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:43.599+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:43.599+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:43.600+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:43.600+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:43.602+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:43.603+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:43.604+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:43.605+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:43.606+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:43.607+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:43.608+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:43.609+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:43.610+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:43.611+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:43.612+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:43.613+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:43.613+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:43.615+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:43.615+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:43.616+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:43.617+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:43.618+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:43.619+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:43.620+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:43.621+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:43.622+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:43.623+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:43.624+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:43.625+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:43.626+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:43.627+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:43.628+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:43.629+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:43.630+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:43.630+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:43.631+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:43.631+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:43.632+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:43.632+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:43.633+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:43.633+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:43.634+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:43.635+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:43.635+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:43.636+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:43.637+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:43.638+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:43.639+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:43.640+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:43.641+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:43.642+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:43.643+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:43.644+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:43.645+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:43.646+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:43.650+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:43.651+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:43.651+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:43.652+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:43.653+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:43.654+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:43.654+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:43.655+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:43.656+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:43.657+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:43.658+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:43.658+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:43.659+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:43.660+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:43.661+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:43.662+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:43.663+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:43.664+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:43.664+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:43.665+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:43.666+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:43.668+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:43.669+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:43.670+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:43.671+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:43.672+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:43.673+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:43.674+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:43.675+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:43.676+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:43.677+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:43.678+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:43.678+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:43.679+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:43.680+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:43.681+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:43.682+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:43.683+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:43.684+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:43.685+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:43.687+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:43.688+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:43.689+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:43.690+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:43.691+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:43.692+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:43.693+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:43.694+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:43.695+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:43.696+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:43.697+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:43.698+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:43.699+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:43.699+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:43.700+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:43.701+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:43.702+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:43.703+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:43.704+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:43.705+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:43.705+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:43.706+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:43.707+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:43.708+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:43.709+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:43.710+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:43.711+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:43.712+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:43.713+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:43.714+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:43.714+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:43.715+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:43.716+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:43.717+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:43.718+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:43.719+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:43.720+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:43.721+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:43.722+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:43.723+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:43.725+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:43.727+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:43.728+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:43.729+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:43.730+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:43.731+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:43.732+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:43.732+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:43.733+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:43.734+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:43.735+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:43.736+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:43.736+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:43.737+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:43.738+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:43.739+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:43.740+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:43.740+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:43.741+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:43.742+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:43.743+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:43.744+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:43.744+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:43.745+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:43.746+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:43.747+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:43.747+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:43.748+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:43.749+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:43.750+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:43.750+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:43.751+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:43.752+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:43.753+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:43.754+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:43.754+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:43.755+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:43.756+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:43.757+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:43.758+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:43.758+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:43.759+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:43.760+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:43.761+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:43.761+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:43.762+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:43.763+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:43.764+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:43.764+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:43.765+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:43.766+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:43.767+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:43.767+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:43.768+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:43.769+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:43.770+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:43.771+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:43.771+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:43.772+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:43.773+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:43.774+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:43.775+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)
[2025-04-02T09:17:43.775+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:43.776+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:43.777+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:43.777+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:43.777+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:43.778+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:43.778+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:43.779+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:43.779+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:43.780+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:43.780+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:43.780+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:43.781+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:43.781+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:43.782+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:43.782+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:43.782+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:43.783+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:43.784+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:43.784+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:43.785+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:43.786+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:43.786+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:43.787+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:43.788+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:43.788+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:43.789+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:43.790+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:43.790+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:43.791+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:43.791+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:43.792+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:43.793+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:43.794+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:43.794+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:43.795+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:43.796+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:43.797+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:43.797+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:43.798+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:43.799+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:43.800+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:43.800+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:43.801+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:43.802+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:43.803+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:43.807+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:43.808+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:43.809+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:43.810+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:43.811+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:43.812+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:43.813+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:43.814+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:43.815+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:43.816+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:43.817+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:43.818+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:43.819+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:43.820+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:43.821+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:43.822+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:43.822+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:43.823+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:43.824+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:43.825+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:43.826+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:43.827+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:43.828+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:43.829+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:43.830+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:43.831+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:43.831+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:43.832+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:43.833+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:43.834+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:43.836+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:43.837+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:43.837+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:43.838+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:43.839+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:43.840+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:43.840+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:43.842+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:43.843+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:43.844+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:43.844+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:43.845+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:43.846+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:43.847+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:43.847+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:43.848+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:43.849+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:43.850+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:43.851+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:43.852+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:43.852+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:43.853+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:43.854+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:43.855+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:43.855+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:43.856+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:43.857+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:43.858+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:43.858+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:43.859+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:43.859+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:43.860+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:43.861+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:43.861+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:43.862+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:43.863+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:43.863+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:43.864+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:43.865+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:43.866+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:43.866+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:43.867+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:43.868+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:43.869+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:43.869+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:43.870+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:43.871+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:43.872+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:43.872+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:43.873+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:43.874+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:43.875+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:43.876+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:43.876+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:43.877+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:43.878+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:43.879+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:43.880+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:43.881+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:43.882+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:43.882+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:43.883+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:43.884+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:43.885+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:43.886+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:43.886+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:43.887+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:43.888+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:43.888+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:43.889+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:43.890+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:43.891+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:43.892+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:43.892+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:43.893+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:43.894+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:43.894+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:43.895+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:43.896+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:43.896+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:43.897+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:43.898+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:43.899+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:43.899+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:43.900+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:43.901+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:43.902+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:43.903+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:43.904+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:43.904+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:43.905+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:43.906+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:43.906+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:43.907+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:43.908+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:43.909+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:43.909+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:43.910+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:43.911+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:43.911+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:43.912+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:43.913+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:43.913+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:43.918+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:43.919+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:43.920+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:43.921+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:43.921+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:43.922+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:43.923+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:43.924+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:43.924+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:43.925+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:43.926+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:43.926+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:43.927+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:43.927+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:43.928+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:43.929+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:43.930+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:43.930+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:43.931+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:43.932+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:43.933+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:43.933+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:43.934+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:43.935+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:43.936+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:43.937+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:43.938+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:43.939+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:43.940+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:43.940+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:43.941+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:43.942+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:43.942+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:43.943+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:43.944+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:43.944+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:43.945+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:43.946+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:43.947+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:43.948+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:43.949+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:43.949+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:43.950+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:43.951+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:43.952+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:43.953+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:43.954+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:43.956+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:43.956+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:43.957+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:43.958+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:43.959+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:43.960+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:43.961+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:43.961+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:43.962+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:43.963+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:43.963+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:43.964+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:43.965+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:43.965+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:43.966+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:43.967+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:43.968+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:43.969+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:43.970+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:43.970+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:43.971+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:43.972+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:43.973+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:43.974+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:43.974+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:43.975+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:43.976+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:43.977+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:43.977+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:43.978+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:43.979+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:43.979+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:43.980+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:43.981+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:43.982+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:43.986+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:43.988+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:43.989+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:43.990+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:43.991+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:43.991+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:43.992+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:43.993+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:43.993+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:43.994+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:43.994+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:43.995+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:43.996+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:43.997+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:43.997+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:43.998+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:43.999+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:44.000+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:44.000+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:44.001+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:44.002+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:44.003+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:44.004+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:44.004+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:44.005+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:44.006+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:44.007+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:44.007+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:44.008+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:44.009+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:44.010+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:44.010+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:44.011+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:44.012+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:44.013+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:44.013+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:44.014+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:44.015+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:44.015+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:44.016+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:44.017+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:44.017+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:44.018+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:44.019+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:44.020+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:44.021+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:44.021+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:44.022+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:44.023+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:44.024+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:44.025+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:44.026+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:44.027+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:44.027+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:44.028+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:44.029+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:44.029+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:44.030+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:44.031+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:44.032+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:44.032+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:44.033+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:44.034+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:44.034+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:44.035+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:44.036+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:44.037+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:44.038+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:44.038+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:44.039+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:44.040+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:44.041+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:44.041+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:44.042+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:44.043+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:44.043+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:44.044+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.045+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:44.045+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:44.046+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:44.047+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:44.047+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:44.048+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:44.049+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:44.050+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:44.051+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.052+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:44.053+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:44.053+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:44.054+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:44.055+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:44.055+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:44.056+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:44.057+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:44.058+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.058+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:44.059+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:44.060+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:44.060+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:44.061+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:44.062+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:44.062+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:44.063+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:44.063+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.064+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:44.065+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:44.065+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:44.066+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:44.067+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:44.067+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:44.068+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:44.069+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:44.070+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:44.071+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:44.072+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:44.072+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:44.073+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.074+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:44.075+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:44.076+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:44.076+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:44.077+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:44.078+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:44.078+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:44.079+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:44.080+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:44.080+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)
[2025-04-02T09:17:44.081+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)
[2025-04-02T09:17:44.082+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:44.082+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:44.083+0000] {subprocess.py:106} INFO - 	... 154 more
[2025-04-02T09:17:44.084+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:44.085+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:44.086+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:44.087+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:44.088+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:44.088+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:44.089+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:44.090+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:44.091+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.092+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:44.093+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:44.094+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:44.094+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:44.095+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:44.096+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:44.097+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:44.097+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:44.098+0000] {subprocess.py:106} INFO - 	... 156 more
[2025-04-02T09:17:44.099+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:44.100+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:44.100+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:44.101+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:44.102+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:44.103+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:44.104+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:44.105+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:44.106+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:44.107+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.107+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:44.108+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:44.109+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:44.110+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:44.110+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:44.111+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:44.112+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:44.113+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:44.113+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.114+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:44.115+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:44.116+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:44.116+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:44.117+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:44.118+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:44.119+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:44.120+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:44.121+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.122+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:44.122+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:44.123+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:44.124+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:44.124+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:44.125+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:44.126+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:44.127+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:44.127+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.128+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:44.129+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:44.129+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:44.130+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:44.130+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:44.131+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:44.132+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:44.133+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:44.134+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:44.135+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:44.136+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:44.136+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:44.137+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.138+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:44.139+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:44.140+0000] {subprocess.py:106} INFO - Nested Throwables StackTrace:
[2025-04-02T09:17:44.141+0000] {subprocess.py:106} INFO - java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:44.141+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:44.143+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:44.144+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:44.145+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:44.145+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:44.146+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:44.147+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:44.148+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:44.148+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.149+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:44.150+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:44.151+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:44.153+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:44.154+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:44.155+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:44.156+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:44.157+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:44.158+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:44.158+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:44.159+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:44.160+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:44.161+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:44.161+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:44.162+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:44.163+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:44.163+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:44.164+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:44.165+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:44.166+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:44.167+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:44.167+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:44.168+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:44.169+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:44.170+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:44.170+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:44.171+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:44.172+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:44.173+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.173+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:44.174+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:44.175+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:44.175+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:44.176+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:44.177+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:44.178+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:44.178+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:44.179+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:44.180+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:44.180+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:44.181+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:44.182+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:44.182+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:44.183+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:44.184+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:44.185+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:44.186+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:44.186+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:44.187+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:44.188+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:44.188+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:44.189+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:44.190+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:44.190+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:44.191+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:44.192+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:44.192+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:44.193+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:44.193+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:44.194+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:44.195+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:44.196+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:44.196+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:44.197+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:44.198+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:44.198+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:44.199+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:44.200+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:44.200+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:44.201+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:44.202+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:44.203+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:44.204+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:44.204+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:44.205+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:44.205+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:44.206+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:44.207+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:44.208+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:44.209+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:44.209+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:44.210+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:44.210+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:44.211+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:44.212+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:44.212+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:44.213+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:44.214+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:44.214+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:44.215+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:44.215+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:44.216+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:44.217+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:44.217+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:44.218+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:44.219+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:44.220+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:44.220+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:44.221+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:44.222+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:44.222+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:44.223+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:44.224+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:44.225+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:44.225+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:44.226+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:44.226+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:44.227+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:44.228+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:44.228+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:44.229+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:44.230+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:44.230+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:44.231+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:44.232+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:44.232+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:44.233+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:44.234+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:44.234+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:44.235+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:44.236+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:44.237+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:44.237+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:44.238+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:44.239+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:44.239+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:44.240+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:44.241+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:44.242+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:44.242+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:44.243+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:44.244+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:44.244+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:44.245+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:44.246+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:44.246+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:44.247+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:44.247+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:44.248+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:44.249+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:44.249+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:44.250+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:44.251+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:44.252+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:44.253+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:44.254+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:44.254+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:44.255+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:44.256+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:44.256+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:44.257+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:44.258+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:44.258+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:44.259+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:44.259+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:44.260+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:44.261+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:44.262+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:44.262+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:44.263+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:44.263+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:44.264+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:44.265+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:44.265+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:44.266+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:44.267+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:44.267+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:44.268+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:44.269+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:44.270+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:44.270+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:44.271+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:44.272+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:44.272+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.273+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:44.274+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:44.275+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:44.276+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:44.277+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:44.277+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:44.278+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:44.278+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:44.279+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.280+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:44.280+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:44.281+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:44.281+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:44.282+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:44.283+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:44.283+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:44.284+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:44.285+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.285+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:44.286+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:44.287+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:44.288+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:44.288+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:44.289+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:44.289+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:44.290+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:44.291+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.291+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:44.292+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:44.293+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:44.293+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:44.294+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:44.294+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:44.295+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:44.296+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:44.296+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:44.297+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:44.298+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:44.298+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:44.299+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.300+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:44.300+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:44.301+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:44.302+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:44.303+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:44.304+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:44.304+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:44.305+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:44.306+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:44.307+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)
[2025-04-02T09:17:44.307+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)
[2025-04-02T09:17:44.308+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:44.308+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:44.309+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:44.310+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:44.311+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:44.311+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:44.312+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:44.313+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:44.313+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:44.314+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:44.314+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:44.315+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:44.316+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:44.316+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:44.317+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:44.318+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:44.318+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:44.319+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:44.320+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:44.321+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:44.321+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.322+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:44.323+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:44.324+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:44.324+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:44.325+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:44.326+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:44.326+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:44.327+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:44.327+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:44.328+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:44.329+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:44.329+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:44.330+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:44.331+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:44.331+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:44.332+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:44.333+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:44.333+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:44.334+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:44.335+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:44.336+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:44.337+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:44.337+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:44.338+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:44.339+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:44.340+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:44.340+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:44.341+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:44.342+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:44.343+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:44.343+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:44.344+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:44.345+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:44.346+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:44.346+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:44.347+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:44.348+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:44.348+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:44.349+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:44.350+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:44.350+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:44.351+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:44.352+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:44.353+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:44.354+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:44.354+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:44.355+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:44.356+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:44.357+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:44.358+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:44.359+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:44.359+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:44.360+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:44.361+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:44.361+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:44.362+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:44.363+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:44.363+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:44.364+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:44.365+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:44.365+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:44.366+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:44.367+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:44.367+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:44.368+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:44.369+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:44.370+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:44.371+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:44.372+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:44.372+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:44.373+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:44.374+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:44.375+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:44.375+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:44.376+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:44.376+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:44.377+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:44.378+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:44.379+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:44.380+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:44.380+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:44.381+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:44.382+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:44.383+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:44.383+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:44.384+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:44.385+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:44.386+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:44.387+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:44.387+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:44.388+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:44.389+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:44.390+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:44.391+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:44.391+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:44.392+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:44.393+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:44.394+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:44.395+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:44.396+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:44.396+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:44.397+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:44.398+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:44.399+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:44.399+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:44.400+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:44.401+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:44.402+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:44.403+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:44.404+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:44.405+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:44.405+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:44.406+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:44.407+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:44.408+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:44.408+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:44.409+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:44.410+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:44.410+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:44.411+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:44.412+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:44.412+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:44.413+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:44.414+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:44.415+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:44.415+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:44.416+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:44.417+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:44.417+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:44.418+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:44.419+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:44.420+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:44.421+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:44.422+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:44.423+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:44.424+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:44.424+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:44.425+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:44.426+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:44.427+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:44.427+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:44.428+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:44.429+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:44.430+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.430+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:44.431+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:44.432+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:44.433+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:44.433+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:44.434+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:44.435+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:44.437+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:44.437+0000] {subprocess.py:106} INFO - 	... 156 more
[2025-04-02T09:17:44.438+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:44.439+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:44.440+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:44.441+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:44.441+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:44.442+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:44.443+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:44.444+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:44.444+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:44.445+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.446+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:44.448+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:44.448+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:44.449+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:44.450+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:44.451+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:44.452+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:44.453+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:44.453+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.454+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:44.455+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:44.456+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:44.456+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:44.457+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:44.458+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:44.458+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:44.459+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:44.460+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.460+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:44.461+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:44.462+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:44.463+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:44.464+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:44.465+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:44.466+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:44.466+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:44.467+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.469+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:44.470+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:44.471+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:44.472+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:44.473+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:44.474+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:44.475+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:44.475+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:44.476+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:44.477+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:44.478+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:44.478+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:44.479+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.480+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:44.480+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:44.481+0000] {subprocess.py:106} INFO - 25/04/02 09:17:43 WARN HiveMetaStore: Retrying creating default database after error: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:44.482+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:44.482+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:44.483+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:44.484+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:44.484+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:44.485+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:44.486+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:44.487+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:44.488+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.488+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:44.489+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:44.490+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:44.491+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:44.491+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:44.492+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:44.493+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:44.494+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:44.494+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:44.495+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:44.496+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:44.496+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:44.497+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:44.498+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:44.498+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:44.499+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:44.500+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:44.501+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:44.502+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:44.503+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:44.504+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:44.505+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:44.505+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:44.506+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:44.507+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:44.508+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:44.508+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:44.509+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:44.510+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.510+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:44.511+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:44.511+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:44.512+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:44.513+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:44.513+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:44.514+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:44.515+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:44.516+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:44.517+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:44.518+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:44.519+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:44.520+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:44.521+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:44.522+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:44.523+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:44.524+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:44.525+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:44.525+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:44.526+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:44.527+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:44.528+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:44.528+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:44.529+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:44.530+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:44.531+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:44.531+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:44.532+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:44.533+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:44.534+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:44.535+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:44.536+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:44.537+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:44.537+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:44.538+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:44.539+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:44.540+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:44.541+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:44.541+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:44.542+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:44.543+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:44.544+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:44.544+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:44.545+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:44.546+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:44.547+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:44.548+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:44.548+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:44.549+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:44.550+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:44.550+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:44.551+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:44.552+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:44.553+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:44.554+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:44.554+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:44.555+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:44.556+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:44.557+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:44.557+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:44.558+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:44.559+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:44.559+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:44.560+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:44.560+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:44.561+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:44.562+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:44.562+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:44.563+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:44.564+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:44.564+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:44.565+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:44.565+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:44.566+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:44.567+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:44.567+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:44.568+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:44.569+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:44.570+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:44.570+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:44.571+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:44.571+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:44.572+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:44.573+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:44.574+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:44.574+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:44.575+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:44.576+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:44.576+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:44.577+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:44.577+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:44.578+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:44.579+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:44.579+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:44.580+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:44.581+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:44.581+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:44.582+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:44.583+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:44.583+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:44.584+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:44.585+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:44.586+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:44.587+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:44.587+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:44.588+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:44.589+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:44.590+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:44.590+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:44.591+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:44.591+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:44.592+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:44.593+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:44.593+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:44.594+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:44.594+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:44.595+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:44.595+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:44.596+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:44.596+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:44.597+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:44.598+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:44.598+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:44.599+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:44.600+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:44.600+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:44.601+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:44.602+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:44.603+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:44.603+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:44.604+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:44.605+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:44.606+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:44.606+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:44.607+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:44.608+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:44.608+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:44.609+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:44.610+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:44.611+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:44.611+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:44.612+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:44.613+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:44.614+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:44.614+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.615+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:44.615+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:44.616+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:44.616+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:44.617+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:44.618+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:44.619+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:44.619+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:44.620+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.621+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:44.621+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:44.622+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:44.623+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:44.624+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:44.625+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:44.625+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:44.626+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:44.627+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.627+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:44.628+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:44.628+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:44.629+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:44.630+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:44.630+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:44.631+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:44.632+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:44.632+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.633+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:44.634+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:44.635+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:44.636+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:44.637+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:44.637+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:44.638+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:44.639+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:44.640+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:44.641+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:44.642+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:44.642+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:44.643+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.644+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:44.644+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:44.645+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:44.646+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:44.646+0000] {subprocess.py:106} INFO - javax.jdo.JDOFatalDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:44.647+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:44.647+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:44.648+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:44.649+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:44.649+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:44.650+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:44.650+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:44.651+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:44.652+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.653+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:44.654+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:44.654+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:44.655+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:44.656+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:44.656+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:44.657+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:44.658+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:44.659+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:44.659+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:44.660+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:44.661+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:44.661+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:44.662+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:44.662+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:44.663+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:44.664+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:44.664+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:44.665+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:44.665+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:44.666+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:44.667+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:44.668+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:44.669+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:44.669+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:44.670+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:44.671+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:44.672+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:44.672+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.673+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:44.674+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:44.675+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:44.676+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:44.677+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:44.677+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:44.678+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:44.679+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:44.679+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:44.680+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:44.681+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:44.681+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:44.682+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:44.683+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:44.683+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:44.684+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:44.686+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:44.687+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:44.687+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:44.688+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:44.689+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:44.690+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:44.691+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:44.691+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:44.692+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:44.693+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:44.693+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:44.694+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:44.695+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:44.695+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:44.696+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:44.697+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:44.697+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:44.698+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:44.698+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:44.699+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:44.700+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:44.701+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:44.702+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:44.703+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:44.704+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:44.705+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:44.705+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:44.706+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:44.707+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:44.708+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:44.708+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:44.709+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:44.710+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:44.710+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:44.711+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:44.711+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:44.712+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:44.713+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:44.714+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:44.714+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:44.715+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:44.716+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:44.717+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:44.717+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:44.718+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:44.719+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:44.720+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:44.720+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:44.721+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:44.722+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:44.723+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:44.723+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:44.724+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:44.724+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:44.725+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:44.725+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:44.726+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:44.727+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:44.728+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:44.728+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:44.729+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:44.730+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:44.730+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:44.731+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:44.731+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:44.732+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:44.732+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:44.733+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:44.734+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:44.735+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:44.736+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:44.737+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:44.738+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:44.738+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:44.739+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:44.740+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:44.741+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:44.742+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:44.743+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:44.743+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:44.744+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:44.745+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:44.746+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:44.747+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:44.748+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:44.749+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:44.750+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:44.751+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:44.752+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:44.753+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:44.754+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:44.755+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:44.756+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:44.757+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:44.758+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:44.759+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:44.759+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:44.760+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:44.761+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:44.762+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:44.763+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:44.764+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:44.765+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:44.766+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:44.767+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:44.768+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:44.770+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:44.771+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:44.772+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:44.773+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:44.774+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:44.775+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:44.776+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:44.777+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:44.778+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:44.779+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:44.780+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:44.781+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:44.781+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:44.782+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:44.783+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:44.785+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:44.786+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:44.787+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:44.788+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:44.789+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:44.790+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:44.791+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:44.792+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.793+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:44.793+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:44.794+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:44.795+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:44.796+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:44.797+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:44.798+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:44.798+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:44.799+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.800+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:44.802+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:44.803+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:44.804+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:44.805+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:44.806+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:44.807+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:44.808+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:44.809+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.811+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:44.812+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:44.813+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:44.814+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:44.815+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:44.817+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:44.818+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:44.819+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:44.820+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.822+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:44.823+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:44.824+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:44.825+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:44.826+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:44.827+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:44.828+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:44.829+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:44.829+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:44.830+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:44.831+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:44.832+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:44.833+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.835+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:44.836+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:44.837+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:44.838+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:44.840+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:529)
[2025-04-02T09:17:44.841+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:830)
[2025-04-02T09:17:44.842+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:44.843+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:44.844+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:44.845+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:44.846+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:44.847+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:44.847+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:44.848+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.849+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:44.850+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:44.851+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:44.851+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:44.853+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:44.853+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:44.854+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:44.855+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:44.856+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:44.857+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:44.858+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:44.859+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:44.860+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:44.860+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:44.861+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:44.862+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:44.863+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:44.864+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:44.865+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:44.866+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:44.867+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:44.867+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:44.869+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:44.870+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:44.870+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:44.871+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:44.872+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:44.873+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:44.874+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:44.875+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:44.876+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:44.876+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:44.877+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:44.878+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:44.879+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:44.879+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:44.880+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:44.881+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:44.882+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:44.882+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:44.883+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:44.884+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:44.885+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:44.886+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:44.887+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:44.887+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:44.888+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:44.889+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:44.890+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:44.891+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:44.891+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:44.892+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:44.893+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:44.894+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:44.895+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:44.896+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:44.897+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:44.898+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:44.899+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:44.900+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:44.900+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:44.901+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:44.902+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:44.903+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:44.904+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:44.905+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:44.905+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:44.906+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:44.907+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:44.908+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:44.909+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:44.910+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:44.910+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:44.911+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:44.912+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:44.912+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:44.913+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:44.914+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:44.914+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:44.915+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:44.916+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:44.916+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:44.917+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:44.918+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:44.918+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:44.919+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:44.920+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:44.921+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:44.921+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:44.922+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:44.923+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:44.924+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:44.925+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:44.925+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:44.926+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:44.927+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:44.927+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:44.928+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:44.929+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:44.930+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:44.930+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:44.931+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:44.932+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:44.933+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:44.933+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:44.934+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:44.935+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:44.936+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:44.936+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:44.937+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:44.938+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:44.939+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:44.940+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:44.940+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:44.941+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:44.942+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:44.942+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:44.943+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:44.943+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:44.944+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:44.945+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:44.945+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:44.946+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:44.947+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:44.948+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:44.948+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:44.949+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:44.950+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:44.951+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:44.952+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:44.953+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:44.954+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:44.955+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:44.956+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:44.957+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:44.957+0000] {subprocess.py:106} INFO - NestedThrowablesStackTrace:
[2025-04-02T09:17:44.958+0000] {subprocess.py:106} INFO - java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:44.959+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:44.960+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:44.960+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:44.961+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:44.962+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:44.963+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:44.964+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:44.965+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:44.965+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.966+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:44.967+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:44.968+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:44.969+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:44.970+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:44.970+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:44.971+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:44.971+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:44.972+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:44.973+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:44.974+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:44.974+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:44.975+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:44.975+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:44.976+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:44.977+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:44.977+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:44.978+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:44.979+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:44.979+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:44.980+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:44.980+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:44.981+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:44.982+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:44.982+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:44.983+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:44.984+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:44.984+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:44.985+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:44.986+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:44.987+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:44.988+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:44.989+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:44.989+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:44.990+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:44.991+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:44.991+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:44.992+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:44.993+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:44.994+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:44.994+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:44.995+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:44.995+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:44.996+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:44.997+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:44.998+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:44.998+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:44.999+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:45.000+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:45.000+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:45.001+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:45.002+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:45.003+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:45.004+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:45.004+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:45.005+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:45.005+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:45.006+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:45.007+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:45.008+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:45.008+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:45.009+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:45.010+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:45.010+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:45.011+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:45.012+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:45.012+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:45.013+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:45.014+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:45.014+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:45.015+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:45.016+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:45.016+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:45.017+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:45.018+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:45.019+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:45.020+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:45.020+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:45.021+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:45.022+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:45.022+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:45.023+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:45.024+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:45.025+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:45.025+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:45.026+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:45.027+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:45.027+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:45.028+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:45.029+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:45.029+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:45.030+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:45.031+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:45.031+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:45.032+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:45.032+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:45.033+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:45.034+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:45.035+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:45.036+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:45.036+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:45.037+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:45.038+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:45.038+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:45.039+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:45.040+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:45.040+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:45.041+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:45.042+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:45.042+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:45.043+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:45.044+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:45.044+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:45.045+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:45.045+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:45.046+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:45.047+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:45.047+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:45.048+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:45.048+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:45.049+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:45.050+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:45.050+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:45.051+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:45.051+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:45.052+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:45.053+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:45.054+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:45.055+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:45.055+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:45.056+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:45.057+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:45.058+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:45.058+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:45.059+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:45.060+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:45.060+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:45.061+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:45.062+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:45.062+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:45.063+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:45.063+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:45.064+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:45.065+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:45.065+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:45.066+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:45.067+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:45.068+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:45.069+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:45.069+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:45.070+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:45.071+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:45.071+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:45.072+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:45.072+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:45.073+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:45.074+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:45.075+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:45.075+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:45.076+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:45.076+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:45.077+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:45.078+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:45.078+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:45.079+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:45.080+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:45.081+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:45.081+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:45.082+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:45.083+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:45.083+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:45.084+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:45.085+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:45.086+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:45.086+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:45.087+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:45.088+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:45.088+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:45.089+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:45.090+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:45.090+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:45.091+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:45.092+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:45.092+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:45.093+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:45.094+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:45.094+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:45.095+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:45.095+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:45.096+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:45.097+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:45.098+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:45.098+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:45.099+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:45.099+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:45.100+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:45.101+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:45.101+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:45.102+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:45.103+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:45.104+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:45.104+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:45.105+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:45.106+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:45.107+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:45.107+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:45.108+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:45.109+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:45.109+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:45.110+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:45.111+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:45.111+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:45.112+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:45.113+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:45.114+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:45.114+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:45.115+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:45.116+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:45.116+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:45.117+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:45.118+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:45.118+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:45.119+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:45.120+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)
[2025-04-02T09:17:45.120+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)
[2025-04-02T09:17:45.121+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:45.122+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:45.122+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:45.123+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:45.124+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:45.125+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:45.125+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:45.126+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:45.127+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:45.127+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:45.128+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:45.129+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:45.130+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:45.130+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:45.131+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:45.131+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:45.132+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:45.133+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:45.133+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:45.134+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:45.135+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:45.136+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:45.137+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:45.137+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:45.138+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:45.139+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:45.139+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:45.142+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:45.146+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:45.146+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:45.147+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:45.147+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:45.153+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:45.154+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:45.155+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:45.156+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:45.160+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:45.161+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:45.162+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:45.163+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:45.164+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:45.165+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:45.166+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:45.167+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:45.168+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:45.169+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:45.170+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:45.171+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:45.171+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:45.172+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:45.173+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:45.174+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:45.175+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:45.175+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:45.176+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:45.177+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:45.177+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:45.178+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:45.179+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:45.179+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:45.180+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:45.181+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:45.181+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:45.182+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:45.183+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:45.184+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:45.185+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:45.187+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:45.189+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:45.189+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:45.190+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:45.190+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:45.191+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:45.192+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:45.193+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:45.194+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:45.194+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:45.195+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:45.196+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:45.197+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:45.198+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:45.198+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:45.199+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:45.200+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:45.201+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:45.201+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:45.202+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:45.203+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:45.204+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:45.205+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:45.205+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:45.206+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:45.207+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:45.208+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:45.209+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:45.209+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:45.210+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:45.211+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:45.211+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:45.212+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:45.213+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:45.214+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:45.215+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:45.215+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:45.216+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:45.217+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:45.218+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:45.219+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:45.219+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:45.220+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:45.221+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:45.221+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:45.221+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:45.222+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:45.222+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:45.223+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:45.223+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:45.223+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:45.224+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:45.224+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:45.225+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:45.225+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:45.226+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:45.227+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:45.227+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:45.228+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:45.229+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:45.230+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:45.230+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:45.231+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:45.233+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:45.234+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:45.234+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:45.235+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:45.236+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:45.237+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:45.238+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:45.239+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:45.240+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:45.241+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:45.241+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:45.242+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:45.243+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:45.243+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:45.245+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:45.246+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:45.247+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:45.247+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:45.248+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:45.249+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:45.250+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:45.251+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:45.252+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:45.253+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:45.254+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:45.255+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:45.256+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:45.257+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:45.257+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:45.258+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:45.259+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:45.259+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:45.260+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:45.261+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:45.262+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:45.262+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:45.263+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:45.263+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:45.264+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:45.265+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:45.265+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:45.266+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:45.267+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:45.268+0000] {subprocess.py:106} INFO - 	... 156 more
[2025-04-02T09:17:45.269+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:45.269+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:45.270+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:45.271+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:45.271+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:45.272+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:45.273+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:45.273+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:45.274+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:45.275+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:45.276+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:45.276+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:45.277+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:45.278+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:45.278+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:45.279+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:45.280+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:45.280+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:45.281+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:45.281+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:45.282+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:45.283+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:45.284+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:45.284+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:45.285+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:45.286+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:45.287+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:45.287+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:45.288+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:45.289+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:45.290+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:45.290+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:45.291+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:45.291+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:45.292+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:45.293+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:45.293+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:45.294+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:45.294+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:45.295+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:45.296+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:45.296+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:45.297+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:45.297+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:45.298+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:45.299+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:45.299+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:45.300+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:45.301+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:45.302+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:45.302+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:45.303+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:45.304+0000] {subprocess.py:106} INFO - 25/04/02 09:17:44 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
[2025-04-02T09:17:45.304+0000] {subprocess.py:106} INFO - 25/04/02 09:17:44 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
[2025-04-02T09:17:45.305+0000] {subprocess.py:106} INFO - 25/04/02 09:17:44 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
[2025-04-02T09:17:45.306+0000] {subprocess.py:106} INFO - 25/04/02 09:17:44 INFO ObjectStore: ObjectStore, initialize called
[2025-04-02T09:17:45.306+0000] {subprocess.py:106} INFO - 25/04/02 09:17:44 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
[2025-04-02T09:17:45.307+0000] {subprocess.py:106} INFO - 25/04/02 09:17:44 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
[2025-04-02T09:17:45.308+0000] {subprocess.py:106} INFO - 25/04/02 09:17:44 ERROR Schema: Failed initialising database.
[2025-04-02T09:17:45.308+0000] {subprocess.py:106} INFO - Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:45.309+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:45.310+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:45.310+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:45.311+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:45.311+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:45.312+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:45.313+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:45.313+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:45.314+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:45.314+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:45.315+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:45.316+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:45.316+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:45.317+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:45.318+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:45.319+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:45.320+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:45.320+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:45.321+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:45.322+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:45.322+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:45.323+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:45.324+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:45.325+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:45.325+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:45.326+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:45.327+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:45.327+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:45.328+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:45.329+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:45.329+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:45.330+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:45.331+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:45.331+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:45.332+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:45.333+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:45.333+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:45.334+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:45.335+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:45.336+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:45.337+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:45.337+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:45.338+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:45.339+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:45.339+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:45.340+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:45.341+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:45.341+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:45.342+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:45.343+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:45.343+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:45.344+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:45.345+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:45.345+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:45.346+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)
[2025-04-02T09:17:45.347+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:45.348+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:45.348+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:45.349+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:45.349+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:45.350+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:45.351+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:45.352+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:45.353+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:45.353+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:45.354+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:45.355+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:45.355+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:45.356+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:45.357+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:45.358+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:45.358+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:45.359+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:45.360+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:45.360+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:45.361+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:45.362+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:45.362+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:45.363+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:45.363+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:45.364+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:45.365+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:45.365+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:45.366+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:45.367+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:45.367+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:45.368+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:45.369+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:45.370+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:45.370+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:45.371+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:45.372+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:45.372+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:45.373+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:45.374+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:45.375+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:45.375+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:45.376+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:45.377+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:45.377+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:45.378+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:45.378+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:45.379+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:45.380+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:45.381+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:45.381+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:45.382+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:45.383+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:45.383+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:45.384+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:45.385+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:45.386+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:45.386+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:45.387+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:45.388+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:45.389+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:45.389+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:45.390+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:45.390+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:45.391+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:45.391+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:45.392+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:45.393+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:45.393+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:45.394+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:45.394+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:45.395+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:45.395+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:45.396+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:45.397+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:45.397+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:45.398+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:45.398+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:45.399+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:45.400+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:45.400+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:45.401+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:45.402+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:45.403+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:45.404+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:45.406+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:45.407+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:45.408+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:45.409+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:45.410+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:45.411+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:45.412+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:45.413+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:45.414+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:45.415+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:45.416+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:45.417+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:45.418+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:45.419+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:45.420+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:45.421+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:45.421+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:45.422+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:45.424+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:45.425+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:45.426+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:45.426+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:45.427+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:45.428+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:45.429+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:45.430+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:45.431+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:45.432+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:45.433+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:45.434+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:45.436+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:45.437+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:45.438+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:45.439+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:45.440+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:45.441+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:45.442+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:45.443+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:45.444+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:45.445+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:45.446+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:45.447+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:45.448+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:45.449+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:45.450+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:45.451+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:45.452+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:45.453+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:45.454+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:45.455+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:45.456+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:45.457+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:45.458+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:45.458+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:45.460+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:45.461+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:45.462+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:45.463+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:45.463+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:45.464+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:45.465+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:45.467+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:45.468+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:45.469+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:45.471+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:45.472+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:45.473+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:45.475+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:45.476+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:45.476+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:45.477+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:45.478+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:45.479+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:45.480+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:45.481+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:45.482+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:45.483+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:45.484+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:45.485+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:45.486+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:45.488+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:45.488+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:45.490+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:45.491+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:45.492+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:45.494+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:45.495+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:45.496+0000] {subprocess.py:106} INFO - org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:45.496+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:45.497+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:45.498+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:45.499+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:45.500+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:45.501+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:45.502+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:45.503+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:45.504+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:45.504+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:45.505+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:45.506+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:45.507+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:45.508+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:45.509+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:45.510+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:45.511+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:45.512+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:45.513+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:45.513+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:45.514+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:45.515+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:45.516+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:45.517+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:45.518+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:45.518+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:45.520+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:45.520+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:45.521+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:45.522+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:45.523+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:45.524+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:45.525+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:45.526+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:45.527+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:45.528+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:45.529+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:45.530+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:45.531+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:45.532+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:45.533+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:45.534+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:45.535+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:45.536+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:45.537+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:45.539+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:45.540+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:45.541+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:45.542+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:45.543+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:45.544+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:45.545+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:45.546+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:45.547+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:45.548+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)
[2025-04-02T09:17:45.549+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:45.550+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:45.551+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:45.553+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:45.554+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:45.555+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:45.556+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:45.558+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:45.559+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:45.560+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:45.563+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:45.564+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:45.565+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:45.566+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:45.569+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:45.571+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:45.573+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:45.575+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:45.576+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:45.577+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:45.578+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:45.578+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:45.579+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:45.580+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:45.580+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:45.581+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:45.581+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:45.582+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:45.582+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:45.583+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:45.584+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:45.585+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:45.586+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:45.587+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:45.588+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:45.589+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:45.590+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:45.591+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:45.592+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:45.593+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:45.594+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:45.595+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:45.596+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:45.596+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:45.597+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:45.598+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:45.599+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:45.600+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:45.602+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:45.603+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:45.604+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:45.605+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:45.606+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:45.607+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:45.607+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:45.608+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:45.610+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:45.611+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:45.612+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:45.613+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:45.613+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:45.614+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:45.615+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:45.616+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:45.617+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:45.618+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:45.618+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:45.619+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:45.620+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:45.621+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:45.622+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:45.624+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:45.625+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:45.626+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:45.626+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:45.627+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:45.628+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:45.629+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:45.629+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:45.630+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:45.631+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:45.632+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:45.633+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:45.634+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:45.635+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:45.636+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:45.637+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:45.638+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:45.638+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:45.639+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:45.640+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:45.641+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:45.642+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:45.642+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:45.643+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:45.644+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:45.644+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:45.645+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:45.646+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:45.647+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:45.648+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:45.649+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:45.650+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:45.651+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:45.652+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:45.653+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:45.654+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:45.655+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:45.655+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:45.656+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:45.657+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:45.658+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:45.660+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:45.661+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:45.662+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:45.663+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:45.664+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:45.664+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:45.665+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:45.666+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:45.667+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:45.668+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:45.669+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:45.670+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:45.671+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:45.672+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:45.673+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:45.674+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:45.675+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:45.676+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:45.677+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:45.678+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:45.679+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:45.680+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:45.681+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:45.683+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:45.684+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:45.686+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:45.686+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:45.687+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:45.688+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:45.689+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:45.690+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:45.691+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:45.691+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:45.695+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:45.698+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:45.699+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:45.699+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:45.702+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:45.703+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:45.704+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:45.704+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:45.705+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:45.706+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:45.706+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:45.707+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:45.708+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:45.708+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:45.710+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:45.710+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:45.711+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:45.712+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:45.713+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:45.714+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:45.716+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:45.718+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:45.719+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:45.720+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:45.721+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:45.723+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:45.724+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:45.726+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)
[2025-04-02T09:17:45.727+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:45.728+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:45.729+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:45.730+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:45.731+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:45.733+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:45.734+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:45.735+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:45.737+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:45.738+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:45.739+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:45.741+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:45.742+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:45.743+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:45.744+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:45.746+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:45.747+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:45.748+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:45.749+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:45.750+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:45.751+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:45.752+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:45.754+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:45.755+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:45.756+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:45.757+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:45.758+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:45.759+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:45.759+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:45.760+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:45.761+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:45.761+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:45.762+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:45.762+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:45.762+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:45.763+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)
[2025-04-02T09:17:45.763+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:45.764+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:45.764+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:45.765+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:45.765+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:45.766+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:45.766+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:45.767+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:45.768+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:45.769+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:45.769+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:45.770+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:45.771+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:45.772+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:45.772+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:45.773+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:45.774+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:45.775+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:45.776+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:45.776+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:45.777+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:45.778+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:45.779+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:45.780+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:45.781+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:45.782+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:45.783+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:45.784+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:45.786+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:45.786+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:45.787+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:45.789+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:45.790+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:45.791+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:45.792+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:45.793+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:45.793+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:45.794+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:45.795+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:45.795+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:45.796+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:45.797+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:45.798+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:45.799+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:45.799+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:45.800+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:45.805+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:45.806+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:45.807+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:45.808+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:45.809+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:45.810+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:45.811+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:45.811+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:45.812+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:45.813+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:45.814+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:45.815+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:45.816+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:45.816+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:45.817+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:45.818+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:45.819+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:45.820+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:45.821+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:45.822+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:45.822+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:45.823+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:45.824+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:45.825+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:45.825+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:45.826+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:45.827+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:45.828+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:45.829+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:45.830+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:45.830+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:45.831+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:45.832+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:45.833+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:45.834+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:45.835+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:45.836+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:45.837+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:45.838+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:45.839+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:45.839+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:45.840+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:45.841+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:45.842+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:45.842+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:45.843+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:45.844+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:45.844+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:45.845+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:45.846+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:45.847+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:45.847+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:45.848+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:45.849+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:45.850+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:45.850+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:45.851+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:45.852+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:45.853+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:45.854+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:45.855+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:45.856+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:45.857+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:45.857+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:45.858+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:45.859+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:45.859+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:45.860+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:45.861+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:45.861+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:45.862+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:45.863+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:45.864+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:45.864+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:45.865+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:45.866+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:45.866+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:45.867+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:45.868+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:45.869+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:45.870+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:45.871+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:45.872+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:45.873+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:45.874+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:45.874+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:45.875+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:45.876+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:45.876+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:45.877+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:45.878+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:45.879+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:45.879+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:45.880+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:45.881+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:45.881+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:45.882+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:45.883+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:45.884+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:45.885+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:45.886+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:45.886+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:45.887+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:45.887+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:45.888+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:45.889+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:45.890+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:45.891+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:45.892+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:45.893+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:45.894+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:45.895+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:45.896+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:45.897+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:45.898+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:45.898+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:45.899+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:45.900+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:45.901+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:45.902+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:45.903+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:45.904+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:45.905+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:45.906+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:45.907+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:45.908+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:45.908+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:45.909+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)
[2025-04-02T09:17:45.910+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:45.911+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:45.912+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:45.912+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:45.913+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:45.914+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:45.915+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:45.916+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:45.916+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:45.917+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:45.918+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:45.919+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:45.920+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:45.921+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:45.922+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:45.923+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:45.924+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:45.925+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:45.925+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:45.926+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:45.927+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:45.928+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:45.928+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:45.929+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:45.930+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:45.930+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:45.931+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:45.931+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:45.932+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:45.933+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:45.934+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:45.934+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:45.935+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:45.936+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:45.937+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:45.938+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:45.939+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:45.940+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:45.940+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:45.941+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:45.942+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:45.942+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:45.943+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:45.944+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:45.944+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:45.945+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:45.946+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:45.946+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:45.947+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:45.948+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:45.948+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:45.949+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:45.950+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:45.951+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:45.952+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:45.953+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:45.953+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:45.954+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:45.955+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:45.955+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:45.956+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:45.957+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:45.958+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:45.958+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:45.959+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:45.960+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:45.960+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:45.961+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:45.962+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:45.963+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:45.963+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:45.964+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:45.965+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:45.966+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:45.966+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:45.967+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:45.968+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:45.969+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:45.970+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:45.971+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:45.971+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:45.972+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:45.973+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:45.974+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:45.975+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:45.975+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:45.976+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:45.977+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:45.977+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:45.978+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:45.979+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:45.979+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:45.980+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:45.981+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:45.981+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:45.982+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:45.983+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:45.983+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:45.984+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:45.986+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:45.987+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:45.988+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:45.988+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:45.989+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:45.990+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:45.991+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:45.991+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:45.992+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:45.993+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:45.994+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:45.995+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:45.996+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:45.997+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:45.997+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:45.998+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:45.999+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:46.000+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:46.000+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:46.001+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:46.002+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:46.003+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:46.004+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:46.004+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:46.005+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:46.006+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:46.007+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:46.008+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:46.008+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:46.009+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:46.010+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:46.010+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:46.011+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:46.012+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:46.013+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:46.014+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:46.014+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:46.015+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:46.016+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:46.017+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:46.017+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:46.018+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:46.019+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:46.020+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:46.021+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:46.021+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:46.022+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:46.023+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:46.024+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:46.024+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:46.025+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:46.026+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:46.027+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:46.027+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:46.028+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:46.029+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:46.030+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:46.031+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:46.031+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:46.032+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:46.033+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:46.034+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:46.035+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:46.036+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:46.037+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:46.037+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:46.038+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:46.039+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:46.040+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:46.041+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:46.041+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:46.042+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:46.043+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:46.043+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:46.044+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:46.045+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:46.046+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:46.046+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:46.047+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)
[2025-04-02T09:17:46.048+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)
[2025-04-02T09:17:46.048+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:46.049+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:46.050+0000] {subprocess.py:106} INFO - 	... 154 more
[2025-04-02T09:17:46.050+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:46.051+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:46.052+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:46.053+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:46.054+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:46.055+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:46.055+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:46.056+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:46.057+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:46.058+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:46.059+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:46.060+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:46.060+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:46.061+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:46.062+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:46.063+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:46.063+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:46.064+0000] {subprocess.py:106} INFO - 	... 156 more
[2025-04-02T09:17:46.065+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:46.066+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:46.066+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:46.068+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:46.068+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:46.070+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:46.070+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:46.071+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:46.072+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:46.073+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:46.074+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:46.075+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:46.075+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:46.076+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:46.077+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:46.077+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:46.078+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:46.079+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:46.079+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:46.080+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:46.081+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:46.082+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:46.082+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:46.083+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:46.084+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:46.084+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:46.085+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:46.086+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:46.087+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:46.088+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:46.089+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:46.089+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:46.090+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:46.091+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:46.092+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:46.092+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:46.093+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:46.094+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:46.094+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:46.095+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:46.096+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:46.097+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:46.097+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:46.098+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:46.099+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:46.100+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:46.100+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:46.101+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:46.102+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:46.103+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:46.104+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:46.105+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:46.106+0000] {subprocess.py:106} INFO - Nested Throwables StackTrace:
[2025-04-02T09:17:46.106+0000] {subprocess.py:106} INFO - java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:46.107+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:46.108+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:46.109+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:46.110+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:46.110+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:46.111+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:46.112+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:46.113+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:46.113+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:46.114+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:46.115+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:46.116+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:46.116+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:46.117+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:46.118+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:46.119+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:46.119+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:46.120+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:46.121+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:46.122+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:46.122+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:46.123+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:46.124+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:46.125+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:46.125+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:46.126+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:46.127+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:46.127+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:46.128+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:46.129+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:46.129+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:46.130+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:46.131+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:46.132+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:46.132+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:46.133+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:46.134+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:46.134+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:46.135+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:46.136+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:46.137+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:46.137+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:46.138+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:46.139+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:46.140+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:46.140+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:46.141+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:46.142+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:46.143+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:46.143+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:46.144+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:46.145+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:46.146+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:46.146+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:46.147+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)
[2025-04-02T09:17:46.148+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:46.149+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:46.149+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:46.150+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:46.151+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:46.152+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:46.153+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:46.154+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:46.155+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:46.155+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:46.156+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:46.157+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:46.158+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:46.159+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:46.159+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:46.160+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:46.161+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:46.162+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:46.163+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:46.163+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:46.164+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:46.165+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:46.166+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:46.167+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:46.168+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:46.168+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:46.169+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:46.170+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:46.171+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:46.172+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:46.173+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:46.174+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:46.174+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:46.175+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:46.176+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:46.177+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:46.178+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:46.178+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:46.179+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:46.180+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:46.181+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:46.182+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:46.183+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:46.184+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:46.185+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:46.186+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:46.187+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:46.188+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:46.189+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:46.190+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:46.191+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:46.191+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:46.192+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:46.193+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:46.194+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:46.195+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:46.196+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:46.197+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:46.198+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:46.199+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:46.200+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:46.200+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:46.201+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:46.202+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:46.203+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:46.204+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:46.205+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:46.206+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:46.206+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:46.207+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:46.208+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:46.209+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:46.209+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:46.210+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:46.211+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:46.212+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:46.213+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:46.214+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:46.215+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:46.215+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:46.216+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:46.217+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:46.218+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:46.218+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:46.220+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:46.220+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:46.221+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:46.222+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:46.223+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:46.223+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:46.224+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:46.225+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:46.226+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:46.226+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:46.227+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:46.228+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:46.229+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:46.229+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:46.230+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:46.231+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:46.231+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:46.232+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:46.233+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:46.234+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:46.235+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:46.236+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:46.236+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:46.237+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:46.238+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:46.239+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:46.240+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:46.240+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:46.241+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:46.242+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:46.243+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:46.243+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:46.244+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:46.245+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:46.246+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:46.247+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:46.247+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:46.248+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:46.249+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:46.249+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:46.250+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:46.251+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:46.252+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:46.253+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:46.254+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:46.254+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:46.255+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:46.256+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:46.257+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:46.258+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:46.259+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:46.259+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:46.260+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:46.261+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:46.261+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:46.262+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:46.263+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:46.263+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:46.264+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:46.265+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:46.266+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:46.266+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:46.267+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:46.268+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:46.269+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:46.270+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:46.270+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:46.271+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:46.272+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:46.273+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:46.274+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:46.275+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:46.276+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:46.277+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:46.277+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:46.278+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:46.279+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:46.280+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:46.281+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:46.282+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:46.282+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:46.283+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:46.284+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:46.285+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:46.286+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:46.287+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:46.288+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:46.289+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:46.290+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:46.291+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:46.292+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:46.293+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:46.293+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:46.295+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)
[2025-04-02T09:17:46.296+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)
[2025-04-02T09:17:46.297+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:46.298+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:46.299+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:46.299+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:46.300+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:46.302+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:46.303+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:46.304+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:46.304+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:46.306+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:46.307+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:46.308+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:46.309+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:46.309+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:46.310+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:46.311+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:46.311+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:46.312+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:46.313+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:46.313+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:46.314+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:46.315+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:46.316+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:46.317+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:46.319+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:46.320+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:46.321+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:46.322+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:46.323+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:46.324+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:46.324+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:46.325+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:46.326+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:46.327+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:46.328+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:46.329+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:46.330+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:46.331+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)
[2025-04-02T09:17:46.332+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:46.333+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:46.334+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:46.335+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:46.336+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:46.337+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:46.338+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:46.339+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:46.340+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:46.341+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:46.342+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:46.343+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:46.344+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:46.345+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:46.346+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:46.347+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:46.348+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:46.349+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:46.350+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:46.351+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:46.352+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:46.353+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:46.354+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:46.355+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:46.356+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:46.357+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:46.358+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:46.358+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:46.359+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:46.360+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:46.361+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:46.361+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:46.362+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:46.363+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:46.364+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:46.365+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:46.365+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:46.366+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:46.367+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:46.368+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:46.369+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:46.370+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:46.371+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:46.372+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:46.372+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:46.373+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:46.374+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:46.375+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:46.376+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:46.377+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:46.378+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:46.379+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:46.379+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:46.380+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:46.381+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:46.382+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:46.383+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:46.383+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:46.384+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:46.385+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:46.386+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:46.387+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:46.388+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:46.389+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:46.390+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:46.390+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:46.391+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:46.391+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:46.392+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:46.393+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:46.394+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:46.394+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:46.395+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:46.396+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:46.397+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:46.397+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:46.398+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:46.399+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:46.400+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:46.401+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:46.402+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:46.403+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:46.403+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:46.404+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:46.405+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:46.406+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:46.407+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:46.408+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:46.409+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:46.410+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:46.410+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:46.411+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:46.412+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:46.413+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:46.414+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:46.414+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:46.415+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:46.416+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:46.417+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:46.418+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:46.419+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:46.420+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:46.421+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:46.422+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:46.423+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:46.424+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:46.424+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:46.425+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:46.426+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:46.427+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:46.428+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:46.429+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:46.430+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:46.430+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:46.431+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:46.432+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:46.433+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:46.434+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:46.435+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:46.436+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:46.437+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:46.437+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:46.438+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:46.439+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:46.440+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:46.441+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:46.442+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:46.443+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:46.443+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:46.444+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:46.445+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:46.446+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:46.447+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:46.447+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:46.448+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:46.449+0000] {subprocess.py:106} INFO - 	... 156 more
[2025-04-02T09:17:46.450+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:46.451+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:46.452+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:46.453+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:46.454+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:46.455+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:46.456+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:46.457+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:46.458+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:46.459+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:46.459+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:46.460+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:46.461+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:46.462+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:46.463+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:46.464+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:46.464+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:46.465+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:46.466+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:46.467+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:46.467+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:46.468+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:46.469+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:46.470+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:46.471+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:46.472+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:46.472+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:46.473+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:46.474+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:46.475+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:46.476+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:46.477+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:46.478+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:46.478+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:46.479+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:46.480+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:46.481+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:46.482+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:46.482+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:46.483+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:46.484+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:46.485+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:46.486+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:46.487+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:46.487+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:46.488+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:46.489+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:46.490+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:46.491+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:46.492+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:46.493+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:46.493+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:46.494+0000] {subprocess.py:106} INFO - 25/04/02 09:17:45 ERROR Datastore: Exception thrown creating StoreManager. See the nested exception
[2025-04-02T09:17:46.495+0000] {subprocess.py:106} INFO - Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:46.496+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:46.496+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:46.497+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:46.498+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:46.499+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:46.500+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:46.500+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:46.501+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:46.502+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:46.503+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:46.504+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:46.505+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:46.506+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:46.506+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:46.507+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:46.508+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:46.509+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:46.509+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:46.510+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:46.511+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:46.512+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:46.512+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:46.513+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:46.514+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:46.515+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:46.515+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:46.516+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:46.517+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:46.518+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:46.518+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:46.519+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:46.520+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:46.521+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:46.522+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:46.523+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:46.524+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:46.524+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:46.525+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:46.526+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:46.527+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:46.527+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:46.528+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:46.529+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:46.530+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:46.531+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:46.532+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:46.532+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:46.533+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:46.534+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:46.535+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:46.536+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:46.537+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:46.537+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:46.538+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:46.539+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)
[2025-04-02T09:17:46.540+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:46.540+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:46.541+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:46.542+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:46.542+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:46.543+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:46.544+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:46.545+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:46.545+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:46.546+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:46.547+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:46.548+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:46.548+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:46.549+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:46.550+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:46.550+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:46.551+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:46.552+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:46.553+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:46.554+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:46.555+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:46.556+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:46.556+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:46.557+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:46.558+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:46.559+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:46.559+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:46.560+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:46.561+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:46.562+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:46.562+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:46.563+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:46.564+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:46.564+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:46.566+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:46.567+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:46.567+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:46.568+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:46.569+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:46.570+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:46.571+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:46.572+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:46.572+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:46.573+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:46.574+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:46.575+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:46.576+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:46.576+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:46.577+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:46.578+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:46.579+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:46.580+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:46.581+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:46.582+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:46.582+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:46.583+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:46.584+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:46.585+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:46.586+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:46.587+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:46.590+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:46.591+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:46.592+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:46.593+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:46.593+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:46.594+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:46.595+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:46.596+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:46.597+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:46.598+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:46.599+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:46.599+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:46.600+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:46.601+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:46.602+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:46.603+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:46.604+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:46.605+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:46.606+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:46.606+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:46.608+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:46.608+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:46.609+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:46.610+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:46.611+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:46.613+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:46.614+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:46.615+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:46.616+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:46.617+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:46.619+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:46.620+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:46.621+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:46.622+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:46.624+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:46.625+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:46.625+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:46.626+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:46.627+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:46.628+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:46.629+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:46.630+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:46.631+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:46.632+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:46.633+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:46.635+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:46.636+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:46.637+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:46.638+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:46.639+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:46.640+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:46.641+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:46.642+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:46.643+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:46.643+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:46.644+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:46.645+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:46.646+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:46.647+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:46.648+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:46.649+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:46.650+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:46.651+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:46.652+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:46.653+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:46.654+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:46.655+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:46.655+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:46.656+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:46.658+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:46.659+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:46.661+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:46.661+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:46.663+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:46.664+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:46.664+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:46.665+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:46.666+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:46.667+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:46.668+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:46.669+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:46.671+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:46.672+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:46.673+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:46.674+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:46.675+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:46.676+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:46.677+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:46.678+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:46.679+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:46.680+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:46.681+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:46.681+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:46.682+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:46.683+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:46.685+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:46.686+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:46.687+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:46.688+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:46.689+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:46.690+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:46.691+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:46.692+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:46.693+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:46.694+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:46.695+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:46.696+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:46.697+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:46.697+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:46.698+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:46.699+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:46.700+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:46.701+0000] {subprocess.py:106} INFO - org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:46.702+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:46.703+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:46.704+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:46.706+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:46.707+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:46.708+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:46.709+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:46.710+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:46.711+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:46.712+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:46.713+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:46.714+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:46.714+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:46.715+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:46.716+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:46.717+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:46.719+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:46.720+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:46.721+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:46.723+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:46.724+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:46.725+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:46.726+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:46.726+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:46.727+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:46.728+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:46.729+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:46.730+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:46.730+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:46.731+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:46.731+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:46.732+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:46.732+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:46.733+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:46.733+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:46.734+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:46.736+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:46.736+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:46.738+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:46.739+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:46.740+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:46.741+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:46.741+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:46.742+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:46.743+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:46.744+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:46.745+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:46.746+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:46.747+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:46.748+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:46.748+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:46.749+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:46.750+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:46.751+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:46.752+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)
[2025-04-02T09:17:46.753+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:46.755+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:46.756+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:46.757+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:46.758+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:46.759+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:46.759+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:46.760+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:46.761+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:46.762+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:46.763+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:46.764+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:46.765+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:46.766+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:46.767+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:46.768+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:46.769+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:46.770+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:46.771+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:46.772+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:46.773+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:46.774+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:46.775+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:46.775+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:46.776+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:46.777+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:46.778+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:46.779+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:46.779+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:46.780+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:46.781+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:46.782+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:46.782+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:46.783+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:46.784+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:46.785+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:46.786+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:46.787+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:46.788+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:46.789+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:46.789+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:46.790+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:46.791+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:46.792+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:46.793+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:46.793+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:46.794+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:46.795+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:46.796+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:46.796+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:46.797+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:46.798+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:46.799+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:46.799+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:46.800+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:46.801+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:46.802+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:46.803+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:46.804+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:46.805+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:46.805+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:46.806+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:46.807+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:46.808+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:46.809+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:46.810+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:46.811+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:46.811+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:46.812+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:46.813+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:46.814+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:46.815+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:46.816+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:46.817+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:46.818+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:46.819+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:46.820+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:46.821+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:46.822+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:46.823+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:46.825+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:46.826+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:46.827+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:46.827+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:46.828+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:46.829+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:46.830+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:46.831+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:46.832+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:46.833+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:46.834+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:46.836+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:46.837+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:46.839+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:46.840+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:46.841+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:46.842+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:46.843+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:46.844+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:46.844+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:46.845+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:46.846+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:46.847+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:46.848+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:46.848+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:46.849+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:46.850+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:46.851+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:46.852+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:46.853+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:46.854+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:46.855+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:46.856+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:46.858+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:46.859+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:46.860+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:46.861+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:46.862+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:46.863+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:46.864+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:46.865+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:46.866+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:46.867+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:46.868+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:46.869+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:46.870+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:46.871+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:46.872+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:46.873+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:46.873+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:46.874+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:46.875+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:46.876+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:46.878+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:46.880+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:46.882+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:46.883+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:46.884+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:46.884+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:46.885+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:46.886+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:46.887+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:46.888+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:46.888+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:46.889+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:46.890+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:46.892+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:46.893+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:46.895+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:46.896+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:46.897+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:46.898+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:46.899+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:46.900+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:46.901+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:46.902+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:46.904+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:46.904+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:46.905+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:46.907+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:46.908+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:46.909+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:46.910+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:46.910+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:46.911+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:46.912+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:46.914+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:46.915+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:46.916+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:46.917+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:46.918+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:46.918+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:46.920+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)
[2025-04-02T09:17:46.921+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:46.922+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:46.924+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:46.925+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:46.925+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:46.926+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:46.927+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:46.928+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:46.929+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:46.930+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:46.930+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:46.931+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:46.932+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:46.933+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:46.936+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:46.937+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:46.937+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:46.938+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:46.939+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:46.940+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:46.941+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:46.942+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:46.943+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:46.944+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:46.945+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:46.946+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:46.947+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:46.948+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:46.949+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:46.950+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:46.952+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:46.953+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:46.954+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:46.955+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:46.956+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:46.957+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)
[2025-04-02T09:17:46.958+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:46.959+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:46.960+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:46.960+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:46.961+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:46.963+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:46.964+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:46.964+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:46.965+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:46.966+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:46.967+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:46.969+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:46.970+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:46.971+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:46.973+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:46.974+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:46.975+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:46.976+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:46.977+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:46.978+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:46.979+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:46.980+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:46.981+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:46.982+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:46.983+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:46.984+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:46.985+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:46.986+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:46.987+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:46.988+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:46.989+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:46.989+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:46.990+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:46.991+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:46.993+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:46.993+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:46.994+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:46.995+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:46.996+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:46.997+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:46.998+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:47.000+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:47.001+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:47.002+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:47.003+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:47.004+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:47.005+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:47.006+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:47.007+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:47.008+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:47.009+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:47.010+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:47.011+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:47.012+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:47.013+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:47.014+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:47.015+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:47.016+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:47.016+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:47.018+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:47.019+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:47.020+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:47.021+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:47.023+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:47.024+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:47.025+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:47.026+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:47.027+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:47.028+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:47.031+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:47.032+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:47.032+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:47.033+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:47.034+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:47.035+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:47.036+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:47.037+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:47.038+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:47.039+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:47.040+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:47.041+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:47.042+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:47.043+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:47.044+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:47.045+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:47.046+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:47.047+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:47.049+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:47.050+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:47.052+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:47.053+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:47.054+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:47.058+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:47.059+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:47.061+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:47.063+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:47.064+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:47.065+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:47.066+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:47.068+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:47.069+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:47.070+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:47.071+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:47.072+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:47.073+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:47.074+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:47.075+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:47.076+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:47.076+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:47.078+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:47.078+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:47.079+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:47.080+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:47.081+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:47.082+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:47.084+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:47.085+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:47.086+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:47.087+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:47.089+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:47.090+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:47.091+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:47.092+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:47.093+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:47.095+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:47.096+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:47.097+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:47.098+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:47.098+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:47.100+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:47.102+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:47.103+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:47.104+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:47.105+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:47.106+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:47.107+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:47.108+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:47.109+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:47.110+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:47.111+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:47.112+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:47.113+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:47.114+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:47.114+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:47.115+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:47.116+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:47.118+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:47.119+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:47.120+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:47.121+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:47.122+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:47.124+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:47.125+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:47.126+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:47.127+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:47.129+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:47.130+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:47.131+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:47.132+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:47.134+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:47.135+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:47.136+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:47.138+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:47.140+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:47.141+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:47.142+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:47.143+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:47.144+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:47.145+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:47.146+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:47.147+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:47.148+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:47.149+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:47.150+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)
[2025-04-02T09:17:47.150+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:47.152+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:47.153+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:47.154+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:47.155+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:47.156+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:47.157+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:47.158+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:47.159+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:47.159+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:47.160+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:47.161+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:47.161+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:47.162+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:47.163+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:47.164+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:47.165+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:47.165+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:47.166+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:47.167+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:47.168+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:47.169+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:47.170+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:47.171+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:47.171+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:47.172+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:47.173+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:47.174+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:47.174+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:47.175+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:47.176+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:47.177+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:47.177+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:47.178+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:47.179+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:47.180+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:47.180+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:47.181+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:47.182+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:47.182+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:47.183+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:47.184+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:47.185+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:47.185+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:47.186+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:47.187+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:47.188+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:47.189+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:47.190+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:47.191+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:47.191+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:47.192+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:47.193+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:47.194+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:47.194+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:47.195+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:47.196+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:47.197+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:47.198+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:47.198+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:47.199+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:47.200+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:47.201+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:47.202+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:47.203+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:47.204+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:47.204+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:47.205+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:47.206+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:47.207+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:47.208+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:47.209+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:47.210+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:47.210+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:47.211+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:47.212+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:47.213+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:47.214+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:47.214+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:47.215+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:47.216+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:47.217+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:47.218+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:47.219+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:47.220+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:47.221+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:47.222+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:47.223+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:47.223+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:47.224+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:47.225+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:47.225+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:47.226+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:47.227+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:47.228+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:47.228+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:47.229+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:47.230+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:47.231+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:47.231+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:47.232+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:47.232+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:47.233+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:47.234+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:47.235+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:47.236+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:47.236+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:47.237+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:47.238+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:47.239+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:47.240+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:47.241+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:47.241+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:47.242+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:47.243+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:47.244+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:47.244+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:47.245+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:47.246+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:47.247+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:47.247+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:47.248+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:47.249+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:47.250+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:47.250+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:47.251+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:47.252+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:47.253+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:47.254+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:47.255+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:47.255+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:47.256+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:47.257+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:47.258+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:47.259+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:47.259+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:47.260+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:47.261+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:47.262+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:47.262+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:47.263+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:47.264+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:47.265+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:47.266+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:47.266+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:47.267+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:47.268+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:47.269+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:47.270+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:47.271+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:47.271+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:47.272+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:47.273+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:47.274+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:47.274+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:47.275+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:47.276+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:47.277+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:47.278+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:47.279+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:47.279+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:47.280+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:47.281+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:47.282+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:47.282+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:47.283+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:47.284+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:47.284+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:47.286+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:47.286+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:47.287+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:47.288+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:47.289+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:47.290+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:47.291+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:47.291+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:47.292+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:47.293+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)
[2025-04-02T09:17:47.294+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)
[2025-04-02T09:17:47.294+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:47.295+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:47.296+0000] {subprocess.py:106} INFO - 	... 154 more
[2025-04-02T09:17:47.297+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:47.297+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:47.298+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:47.299+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:47.299+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:47.300+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:47.301+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:47.302+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:47.303+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:47.304+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:47.305+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:47.305+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:47.306+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:47.307+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:47.307+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:47.308+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:47.309+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:47.310+0000] {subprocess.py:106} INFO - 	... 156 more
[2025-04-02T09:17:47.310+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:47.311+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:47.312+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:47.312+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:47.313+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:47.314+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:47.314+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:47.315+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:47.316+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:47.317+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:47.317+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:47.319+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:47.320+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:47.320+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:47.321+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:47.322+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:47.323+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:47.324+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:47.325+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:47.326+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:47.326+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:47.327+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:47.328+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:47.329+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:47.329+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:47.330+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:47.331+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:47.332+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:47.332+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:47.333+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:47.334+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:47.336+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:47.337+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:47.338+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:47.339+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:47.339+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:47.340+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:47.341+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:47.342+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:47.343+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:47.343+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:47.344+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:47.345+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:47.346+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:47.346+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:47.347+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:47.348+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:47.349+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:47.349+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:47.350+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:47.351+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:47.352+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:47.353+0000] {subprocess.py:106} INFO - Nested Throwables StackTrace:
[2025-04-02T09:17:47.354+0000] {subprocess.py:106} INFO - java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:47.354+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:47.356+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:47.357+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:47.358+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:47.359+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:47.359+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:47.360+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:47.361+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:47.362+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:47.362+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:47.363+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:47.364+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:47.364+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:47.365+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:47.366+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:47.366+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:47.367+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:47.368+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:47.369+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:47.371+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:47.372+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:47.372+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:47.373+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:47.374+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:47.375+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:47.376+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:47.376+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:47.377+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:47.378+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:47.378+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:47.379+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:47.380+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:47.381+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:47.381+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:47.382+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:47.383+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:47.384+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:47.385+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:47.386+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:47.387+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:47.387+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:47.388+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:47.389+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:47.390+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:47.390+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:47.391+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:47.392+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:47.393+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:47.393+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:47.394+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:47.395+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:47.396+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:47.397+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:47.397+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:47.398+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)
[2025-04-02T09:17:47.399+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:47.399+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:47.400+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:47.401+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:47.402+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:47.403+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:47.404+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:47.404+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:47.405+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:47.406+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:47.406+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:47.407+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:47.407+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:47.408+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:47.409+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:47.409+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:47.410+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:47.410+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:47.411+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:47.412+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:47.412+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:47.413+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:47.414+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:47.414+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:47.415+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:47.416+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:47.416+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:47.417+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:47.418+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:47.419+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:47.420+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:47.420+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:47.421+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:47.422+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:47.423+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:47.423+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:47.424+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:47.424+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:47.425+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:47.426+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:47.427+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:47.427+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:47.428+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:47.429+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:47.429+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:47.430+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:47.430+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:47.431+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:47.432+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:47.432+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:47.433+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:47.433+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:47.434+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:47.435+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:47.436+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:47.437+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:47.438+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:47.438+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:47.439+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:47.440+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:47.440+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:47.441+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:47.442+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:47.442+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:47.443+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:47.444+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:47.444+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:47.445+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:47.446+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:47.446+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:47.447+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:47.448+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:47.448+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:47.449+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:47.450+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:47.450+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:47.451+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:47.452+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:47.453+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:47.454+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:47.454+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:47.455+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:47.455+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:47.456+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:47.457+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:47.457+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:47.458+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:47.459+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:47.459+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:47.460+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:47.460+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:47.461+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:47.462+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:47.462+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:47.463+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:47.464+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:47.465+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:47.465+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:47.466+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:47.467+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:47.468+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:47.469+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:47.470+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:47.470+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:47.471+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:47.472+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:47.472+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:47.473+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:47.474+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:47.474+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:47.475+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:47.476+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:47.477+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:47.477+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:47.478+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:47.479+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:47.479+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:47.480+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:47.481+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:47.481+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:47.482+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:47.483+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:47.483+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:47.484+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:47.485+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:47.486+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:47.486+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:47.487+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:47.488+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:47.488+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:47.489+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:47.490+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:47.491+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:47.491+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:47.492+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:47.493+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:47.493+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:47.494+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:47.495+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:47.495+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:47.496+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:47.497+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:47.498+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:47.499+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:47.499+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:47.500+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:47.501+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:47.502+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:47.503+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:47.503+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:47.504+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:47.505+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:47.506+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:47.507+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:47.507+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:47.508+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:47.509+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:47.509+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:47.510+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:47.511+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:47.511+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:47.512+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:47.512+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:47.513+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:47.514+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:47.515+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:47.515+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:47.516+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:47.517+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:47.518+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:47.519+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:47.520+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:47.521+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:47.522+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:47.523+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:47.523+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:47.524+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:47.525+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)
[2025-04-02T09:17:47.525+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)
[2025-04-02T09:17:47.526+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:47.527+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:47.528+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:47.528+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:47.529+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:47.530+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:47.530+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:47.531+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:47.532+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:47.532+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:47.533+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:47.534+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:47.535+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:47.536+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:47.536+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:47.537+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:47.538+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:47.538+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:47.539+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:47.540+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:47.540+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:47.541+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:47.542+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:47.543+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:47.543+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:47.544+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:47.544+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:47.545+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:47.546+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:47.546+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:47.547+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:47.547+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:47.548+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:47.549+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:47.549+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:47.550+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:47.551+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:47.552+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)
[2025-04-02T09:17:47.553+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:47.553+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:47.554+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:47.554+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:47.555+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:47.556+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:47.557+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:47.557+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:47.558+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:47.558+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:47.559+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:47.560+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:47.561+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:47.561+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:47.565+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:47.566+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:47.567+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:47.568+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:47.569+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:47.570+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:47.570+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:47.571+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:47.572+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:47.572+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:47.573+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:47.574+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:47.575+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:47.575+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:47.576+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:47.577+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:47.577+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:47.578+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:47.579+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:47.579+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:47.580+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:47.580+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:47.581+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:47.582+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:47.582+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:47.583+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:47.584+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:47.584+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:47.585+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:47.586+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:47.587+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:47.587+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:47.588+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:47.589+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:47.589+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:47.590+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:47.591+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:47.591+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:47.592+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:47.593+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:47.593+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:47.594+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:47.595+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:47.595+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:47.596+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:47.596+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:47.597+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:47.598+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:47.598+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:47.599+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:47.600+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:47.601+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:47.601+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:47.602+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:47.603+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:47.603+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:47.604+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:47.605+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:47.606+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:47.606+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:47.607+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:47.608+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:47.608+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:47.609+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:47.610+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:47.610+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:47.611+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:47.612+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:47.612+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:47.613+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:47.614+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:47.614+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:47.615+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:47.616+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:47.617+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:47.618+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:47.619+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:47.619+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:47.620+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:47.621+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:47.622+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:47.623+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:47.624+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:47.625+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:47.625+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:47.626+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:47.627+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:47.627+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:47.628+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:47.628+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:47.629+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:47.630+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:47.630+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:47.631+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:47.632+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:47.632+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:47.633+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:47.633+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:47.634+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:47.635+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:47.636+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:47.637+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:47.638+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:47.638+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:47.639+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:47.640+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:47.640+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:47.641+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:47.642+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:47.642+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:47.643+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:47.644+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:47.645+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:47.645+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:47.646+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:47.646+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:47.647+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:47.648+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:47.648+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:47.649+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:47.650+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:47.651+0000] {subprocess.py:106} INFO - 	... 156 more
[2025-04-02T09:17:47.651+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:47.652+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:47.653+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:47.653+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:47.654+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:47.655+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:47.655+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:47.656+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:47.656+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:47.657+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:47.658+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:47.658+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:47.659+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:47.659+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:47.660+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:47.661+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:47.661+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:47.662+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:47.663+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:47.663+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:47.664+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:47.664+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:47.665+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:47.666+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:47.666+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:47.667+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:47.668+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:47.669+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:47.670+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:47.670+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:47.671+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:47.672+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:47.672+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:47.673+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:47.674+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:47.674+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:47.675+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:47.676+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:47.676+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:47.677+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:47.678+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:47.678+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:47.679+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:47.680+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:47.681+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:47.681+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:47.682+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:47.683+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:47.683+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:47.684+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:47.685+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:47.686+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:49.147+0000] {subprocess.py:106} INFO - 25/04/02 09:17:49 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
[2025-04-02T09:17:49.147+0000] {subprocess.py:106} INFO - 25/04/02 09:17:49 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
[2025-04-02T09:17:49.149+0000] {subprocess.py:106} INFO - 25/04/02 09:17:49 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
[2025-04-02T09:17:49.150+0000] {subprocess.py:106} INFO - 25/04/02 09:17:49 INFO ObjectStore: ObjectStore, initialize called
[2025-04-02T09:17:49.172+0000] {subprocess.py:106} INFO - 25/04/02 09:17:49 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
[2025-04-02T09:17:49.173+0000] {subprocess.py:106} INFO - 25/04/02 09:17:49 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
[2025-04-02T09:17:49.243+0000] {subprocess.py:106} INFO - 25/04/02 09:17:49 ERROR Schema: Failed initialising database.
[2025-04-02T09:17:49.244+0000] {subprocess.py:106} INFO - Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:49.245+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:49.246+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:49.246+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:49.247+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:49.248+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:49.249+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:49.250+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:49.251+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:49.252+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:49.253+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:49.254+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:49.255+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:49.256+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:49.257+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:49.257+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:49.258+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:49.259+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:49.260+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:49.260+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:49.261+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:49.262+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:49.263+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:49.263+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:49.264+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:49.265+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:49.265+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:49.266+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:49.267+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:49.268+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:49.269+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:49.270+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:49.271+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:49.271+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:49.272+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:49.273+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:49.274+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:49.275+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:49.276+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:49.276+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:49.277+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:49.278+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:49.279+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:49.279+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:49.280+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:49.281+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:49.282+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:49.282+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:49.283+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:49.284+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:49.285+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:49.286+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:49.287+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:49.288+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:49.289+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:49.289+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:49.290+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:49.291+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:49.292+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:49.292+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:49.293+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:49.294+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:49.294+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:49.295+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:49.296+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:49.297+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:49.298+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:49.298+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:49.299+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:49.300+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:49.301+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:49.302+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:49.303+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:49.303+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:49.304+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:49.305+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:49.306+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:49.306+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:49.307+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:49.308+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:49.309+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:49.310+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:49.310+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:49.311+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:49.312+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:49.313+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:49.314+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:49.314+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:49.315+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:49.316+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:49.316+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:49.317+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:49.318+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:49.319+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:49.320+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:49.321+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:49.321+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:49.322+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:49.323+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:49.324+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:49.325+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:49.325+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:49.326+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:49.327+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:49.328+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:49.329+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:49.330+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:49.330+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:49.331+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:49.332+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:49.333+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:49.333+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:49.334+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:49.335+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:49.336+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:49.337+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:49.338+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:49.338+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:49.339+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:49.340+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:49.341+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:49.342+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:49.342+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:49.343+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:49.344+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:49.344+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:49.345+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:49.346+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:49.347+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:49.347+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:49.348+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:49.349+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:49.349+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:49.350+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:49.351+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:49.352+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:49.353+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:49.354+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:49.355+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:49.356+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:49.357+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:49.357+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:49.358+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:49.359+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:49.359+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:49.360+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:49.361+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:49.361+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:49.362+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:49.362+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:49.363+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:49.364+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:49.365+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:49.365+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:49.366+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:49.367+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:49.367+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:49.368+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:49.369+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:49.370+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:49.370+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:49.371+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:49.372+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:49.372+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:49.373+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:49.374+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:49.375+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:49.375+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:49.376+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:49.377+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:49.377+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:49.378+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:49.379+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:49.379+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:49.380+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:49.380+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:49.381+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:49.382+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:49.382+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:49.383+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:49.384+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:49.385+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:49.386+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:49.387+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:49.388+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:49.388+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:49.389+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:49.390+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:49.390+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:49.391+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:49.392+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:49.392+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:49.393+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:49.393+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:49.394+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:49.394+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:49.395+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:49.396+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:49.396+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:49.397+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:49.398+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:49.398+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:49.399+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:49.400+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:49.401+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:49.402+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:49.403+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:49.403+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:49.404+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:49.405+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:49.405+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:49.406+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:49.407+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:49.407+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:49.408+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:49.408+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:49.409+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:49.409+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:49.410+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:49.411+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:49.411+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:49.412+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:49.413+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:49.413+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:49.414+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:49.415+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:49.415+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:49.416+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:49.417+0000] {subprocess.py:106} INFO - org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:49.418+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:49.419+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:49.420+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:49.421+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:49.421+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:49.422+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:49.423+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:49.424+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:49.424+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:49.425+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:49.426+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:49.427+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:49.427+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:49.428+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:49.429+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:49.430+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:49.430+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:49.431+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:49.432+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:49.432+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:49.433+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:49.434+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:49.435+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:49.436+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:49.437+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:49.437+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:49.438+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:49.439+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:49.440+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:49.440+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:49.441+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:49.442+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:49.442+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:49.443+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:49.444+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:49.444+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:49.445+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:49.446+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:49.446+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:49.447+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:49.448+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:49.448+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:49.449+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:49.450+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:49.451+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:49.452+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:49.453+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:49.453+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:49.454+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:49.455+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:49.455+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:49.456+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:49.457+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:49.457+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:49.458+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:49.459+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:49.460+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:49.460+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:49.461+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:49.462+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:49.463+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:49.463+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:49.464+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:49.465+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:49.465+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:49.466+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:49.467+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:49.468+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:49.469+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:49.470+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:49.470+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:49.471+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:49.472+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:49.472+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:49.473+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:49.474+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:49.475+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:49.475+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:49.476+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:49.477+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:49.478+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:49.478+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:49.479+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:49.480+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:49.481+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:49.481+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:49.483+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:49.483+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:49.485+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:49.486+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:49.487+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:49.487+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:49.488+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:49.489+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:49.490+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:49.491+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:49.491+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:49.492+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:49.493+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:49.494+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:49.494+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:49.495+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:49.496+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:49.497+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:49.497+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:49.498+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:49.499+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:49.500+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:49.501+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:49.501+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:49.502+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:49.503+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:49.504+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:49.505+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:49.506+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:49.507+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:49.507+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:49.508+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:49.509+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:49.509+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:49.510+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:49.511+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:49.512+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:49.513+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:49.513+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:49.514+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:49.515+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:49.515+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:49.516+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:49.517+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:49.518+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:49.519+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:49.520+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:49.520+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:49.521+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:49.522+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:49.523+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:49.524+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:49.524+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:49.525+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:49.526+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:49.526+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:49.527+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:49.528+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:49.528+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:49.529+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:49.530+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:49.531+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:49.532+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:49.532+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:49.533+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:49.534+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:49.535+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:49.536+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:49.537+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:49.537+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:49.538+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:49.539+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:49.540+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:49.541+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:49.541+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:49.542+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:49.543+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:49.543+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:49.544+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:49.545+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:49.546+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:49.546+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:49.547+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:49.548+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:49.549+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:49.549+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:49.550+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:49.552+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:49.553+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:49.553+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:49.554+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:49.555+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:49.556+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:49.556+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:49.557+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:49.558+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:49.558+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:49.559+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:49.560+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:49.560+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:49.561+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:49.562+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:49.563+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:49.563+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:49.564+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:49.565+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:49.565+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:49.566+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:49.567+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:49.568+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:49.569+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:49.570+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:49.571+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:49.571+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:49.572+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:49.573+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:49.573+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:49.574+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:49.575+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:49.576+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:49.576+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:49.577+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:49.578+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:49.579+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:49.579+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:49.580+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:49.581+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:49.582+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:49.582+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:49.583+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:49.584+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:49.585+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:49.586+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:49.587+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:49.587+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:49.588+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:49.589+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:49.590+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:49.591+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:49.591+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:49.592+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:49.593+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)
[2025-04-02T09:17:49.594+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:49.594+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:49.595+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:49.596+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:49.596+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:49.597+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:49.598+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:49.598+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:49.599+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:49.600+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:49.601+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:49.601+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:49.602+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:49.603+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:49.604+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:49.605+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:49.605+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:49.606+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:49.607+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:49.608+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:49.608+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:49.609+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:49.610+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:49.610+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:49.611+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:49.612+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:49.612+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:49.613+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:49.614+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:49.614+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:49.615+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:49.616+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:49.616+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:49.617+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:49.618+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:49.619+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:49.620+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:49.620+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:49.621+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:49.622+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:49.623+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:49.623+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:49.624+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:49.624+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:49.625+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:49.626+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:49.627+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:49.627+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:49.628+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:49.629+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:49.629+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:49.630+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:49.631+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:49.631+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:49.632+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:49.633+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:49.633+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:49.634+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:49.635+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:49.636+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:49.637+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:49.637+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:49.638+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:49.639+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:49.640+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:49.640+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:49.641+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:49.642+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:49.642+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:49.643+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:49.644+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:49.645+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:49.645+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:49.646+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:49.647+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:49.647+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:49.648+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:49.649+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:49.650+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:49.650+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:49.651+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:49.652+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:49.653+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:49.654+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:49.654+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:49.655+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:49.656+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:49.656+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:49.657+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:49.658+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:49.659+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:49.659+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:49.660+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:49.661+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:49.662+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:49.663+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:49.663+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:49.664+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:49.665+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:49.665+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:49.666+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:49.667+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:49.667+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:49.668+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:49.669+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:49.670+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:49.672+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:49.672+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:49.673+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:49.674+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:49.674+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:49.675+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:49.675+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:49.676+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:49.677+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:49.678+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:49.678+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:49.679+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:49.680+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:49.680+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:49.681+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:49.681+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:49.682+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:49.683+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:49.684+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:49.685+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:49.686+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:49.687+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:49.687+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:49.688+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:49.689+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:49.690+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:49.691+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:49.691+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:49.692+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:49.693+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:49.693+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:49.694+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:49.695+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:49.695+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:49.696+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:49.697+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:49.698+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:49.698+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:49.699+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:49.700+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:49.701+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:49.702+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:49.703+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:49.703+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:49.704+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:49.705+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:49.706+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:49.706+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:49.707+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:49.708+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:49.708+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:49.709+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:49.710+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:49.710+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:49.711+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:49.712+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:49.712+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:49.713+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:49.714+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:49.714+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:49.715+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:49.716+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:49.717+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:49.718+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:49.719+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:49.720+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:49.722+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:49.723+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:49.724+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:49.727+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:49.728+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:49.731+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:49.732+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:49.737+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:49.738+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:49.740+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:49.742+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:49.742+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:49.743+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:49.744+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:49.744+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:49.745+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:49.746+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:49.747+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:49.747+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:49.748+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:49.749+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:49.749+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:49.750+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:49.751+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:49.752+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:49.753+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:49.754+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:49.754+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:49.755+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:49.756+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:49.757+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:49.757+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:49.758+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:49.759+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:49.760+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:49.760+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:49.761+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:49.762+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:49.763+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:49.763+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:49.764+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:49.765+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:49.766+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:49.767+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:49.767+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:49.768+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:49.769+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:49.770+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:49.771+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:49.772+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:49.773+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:49.774+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:49.775+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:49.776+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:49.777+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:49.778+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:49.779+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:49.780+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:49.781+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:49.782+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:49.783+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:49.784+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:49.785+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:49.786+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:49.787+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:49.787+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:49.789+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:49.789+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:49.790+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:49.791+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:49.791+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:49.792+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:49.793+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:49.794+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:49.794+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:49.795+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:49.796+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:49.797+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:49.798+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:49.799+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:49.799+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:49.800+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:49.802+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:49.802+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:49.804+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:49.805+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:49.806+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:49.806+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:49.807+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:49.808+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:49.809+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:49.810+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:49.811+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:49.812+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:49.813+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:49.814+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:49.814+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:49.815+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:49.816+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:49.817+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:49.818+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:49.819+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:49.820+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:49.822+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:49.822+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:49.823+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:49.824+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:49.825+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:49.825+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:49.826+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:49.827+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:49.828+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:49.828+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:49.829+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:49.830+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:49.831+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:49.832+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:49.833+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:49.834+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:49.834+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:49.836+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:49.836+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:49.837+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:49.838+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:49.839+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:49.840+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:49.840+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:49.841+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:49.842+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:49.842+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:49.843+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:49.844+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:49.844+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:49.845+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:49.846+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:49.847+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:49.848+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:49.848+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:49.849+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:49.850+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:49.851+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:49.852+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:49.853+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:49.854+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:49.854+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:49.855+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:49.856+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:49.857+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:49.858+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:49.859+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:49.859+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:49.860+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:49.861+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:49.862+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:49.862+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:49.863+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:49.864+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:49.864+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:49.865+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:49.865+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:49.866+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:49.867+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:49.868+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:49.868+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:49.869+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:49.870+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:49.871+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:49.872+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:49.872+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:49.873+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:49.874+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:49.875+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:49.875+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:49.876+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:49.877+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:49.877+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:49.878+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:49.879+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:49.879+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:49.880+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:49.881+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:49.881+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:49.882+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:49.883+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:49.884+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:49.885+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:49.886+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:49.886+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:49.887+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:49.888+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:49.889+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:49.890+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:49.891+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:49.891+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:49.892+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:49.893+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:49.894+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:49.894+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:49.895+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:49.896+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:49.897+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:49.897+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:49.898+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:49.899+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:49.900+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:49.901+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:49.902+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:49.903+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:49.904+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:49.905+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:49.906+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:49.907+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:49.909+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:49.910+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:49.911+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:49.912+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)
[2025-04-02T09:17:49.912+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)
[2025-04-02T09:17:49.913+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:49.915+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:49.916+0000] {subprocess.py:106} INFO - 	... 154 more
[2025-04-02T09:17:49.917+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:49.918+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:49.919+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:49.919+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:49.920+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:49.921+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:49.922+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:49.923+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:49.923+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:49.924+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:49.925+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:49.926+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:49.927+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:49.928+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:49.928+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:49.929+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:49.930+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:49.931+0000] {subprocess.py:106} INFO - 	... 156 more
[2025-04-02T09:17:49.932+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:49.933+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:49.934+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:49.934+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:49.935+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:49.936+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:49.937+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:49.938+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:49.939+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:49.940+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:49.941+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:49.942+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:49.943+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:49.943+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:49.944+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:49.945+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:49.946+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:49.947+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:49.947+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:49.948+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:49.949+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:49.950+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:49.951+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:49.952+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:49.953+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:49.954+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:49.954+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:49.955+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:49.956+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:49.957+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:49.958+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:49.959+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:49.960+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:49.961+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:49.962+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:49.963+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:49.964+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:49.965+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:49.966+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:49.967+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:49.968+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:49.969+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:49.970+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:49.971+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:49.972+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:49.973+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:49.974+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:49.975+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:49.976+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:49.977+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:49.977+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:49.978+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:49.979+0000] {subprocess.py:106} INFO - Nested Throwables StackTrace:
[2025-04-02T09:17:49.980+0000] {subprocess.py:106} INFO - java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:49.980+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:49.981+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:49.982+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:49.983+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:49.984+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:49.984+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:49.986+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:49.987+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:49.987+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:49.988+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:49.989+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:49.990+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:49.991+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:49.991+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:49.992+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:49.993+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:49.993+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:49.994+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:49.995+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:49.996+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:49.996+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:49.997+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:49.998+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:49.999+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:49.999+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:50.001+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:50.002+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:50.003+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:50.003+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:50.004+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:50.005+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:50.006+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:50.007+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:50.008+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:50.008+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:50.009+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:50.010+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:50.011+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:50.011+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:50.012+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:50.013+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:50.014+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:50.014+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:50.015+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:50.016+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:50.017+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:50.018+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:50.019+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:50.020+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:50.021+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:50.022+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:50.023+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:50.024+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:50.024+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:50.025+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:50.026+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:50.027+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:50.028+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:50.028+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:50.029+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:50.030+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:50.031+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:50.032+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:50.032+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:50.033+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:50.034+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:50.035+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:50.036+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:50.037+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:50.038+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:50.038+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:50.039+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:50.040+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:50.041+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:50.042+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:50.042+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:50.043+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:50.044+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:50.045+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:50.045+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:50.046+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:50.047+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:50.048+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:50.048+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:50.049+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:50.050+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:50.051+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:50.053+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:50.053+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:50.054+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:50.055+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:50.056+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:50.057+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:50.058+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:50.058+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:50.059+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:50.060+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:50.060+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:50.061+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:50.062+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:50.063+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:50.064+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:50.064+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:50.065+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:50.066+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:50.067+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:50.068+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:50.069+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:50.070+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:50.070+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:50.071+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:50.072+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:50.073+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:50.074+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:50.075+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:50.075+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:50.076+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:50.077+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:50.078+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:50.079+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:50.079+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:50.080+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:50.081+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:50.082+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:50.082+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:50.083+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:50.084+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:50.085+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:50.085+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:50.086+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:50.087+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:50.088+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:50.088+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:50.089+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:50.090+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:50.091+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:50.092+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:50.092+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:50.093+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:50.094+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:50.094+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:50.095+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:50.096+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:50.097+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:50.098+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:50.098+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:50.099+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:50.100+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:50.101+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:50.101+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:50.102+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:50.103+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:50.104+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:50.105+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:50.105+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:50.106+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:50.107+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:50.108+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:50.109+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:50.109+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:50.110+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:50.111+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:50.111+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:50.112+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:50.113+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:50.113+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:50.114+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:50.115+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:50.115+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:50.116+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:50.117+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:50.118+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:50.119+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:50.120+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:50.120+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:50.121+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:50.122+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:50.123+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:50.124+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:50.124+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:50.125+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:50.126+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:50.126+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:50.127+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:50.128+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:50.128+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:50.129+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:50.130+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:50.131+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:50.131+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:50.132+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:50.133+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:50.134+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:50.134+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:50.135+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:50.136+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:50.137+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:50.138+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:50.139+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:50.140+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:50.140+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:50.141+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:50.142+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:50.142+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:50.143+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:50.144+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:50.144+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:50.145+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:50.146+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:50.146+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:50.147+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:50.148+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:50.148+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:50.149+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:50.150+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:50.150+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:50.152+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:50.152+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:50.153+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:50.154+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:50.155+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:50.155+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:50.157+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:50.157+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:50.158+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:50.159+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:50.159+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:50.160+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:50.160+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:50.161+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:50.161+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:50.162+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:50.163+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)
[2025-04-02T09:17:50.164+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)
[2025-04-02T09:17:50.164+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:50.165+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:50.166+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:50.166+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:50.167+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:50.168+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:50.169+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:50.170+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:50.171+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:50.172+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:50.172+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:50.173+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:50.174+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:50.174+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:50.175+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:50.176+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:50.177+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:50.177+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:50.178+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:50.179+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:50.179+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:50.180+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:50.181+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:50.182+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:50.182+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:50.183+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:50.184+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:50.185+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:50.186+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:50.187+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:50.187+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:50.188+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:50.189+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:50.190+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:50.190+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:50.191+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:50.192+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:50.193+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:50.193+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:50.194+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:50.195+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:50.195+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:50.196+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:50.197+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:50.197+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:50.198+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:50.199+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:50.200+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:50.201+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:50.201+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:50.202+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:50.203+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:50.204+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:50.205+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:50.205+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:50.206+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:50.207+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:50.208+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:50.208+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:50.209+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:50.210+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:50.210+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:50.211+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:50.212+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:50.213+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:50.213+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:50.214+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:50.215+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:50.216+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:50.216+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:50.217+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:50.218+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:50.219+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:50.220+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:50.220+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:50.221+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:50.222+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:50.222+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:50.223+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:50.224+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:50.224+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:50.225+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:50.226+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:50.227+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:50.227+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:50.228+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:50.229+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:50.230+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:50.230+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:50.231+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:50.232+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:50.232+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:50.233+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:50.234+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:50.235+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:50.236+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:50.236+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:50.237+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:50.238+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:50.239+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:50.240+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:50.241+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:50.242+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:50.242+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:50.244+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:50.245+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:50.245+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:50.246+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:50.247+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:50.248+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:50.249+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:50.250+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:50.251+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:50.251+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:50.253+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:50.254+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:50.255+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:50.256+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:50.257+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:50.258+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:50.259+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:50.260+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:50.260+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:50.261+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:50.262+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:50.263+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:50.263+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:50.264+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:50.265+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:50.266+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:50.267+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:50.268+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:50.269+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:50.269+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:50.270+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:50.271+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:50.272+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:50.273+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:50.273+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:50.274+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:50.275+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:50.276+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:50.277+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:50.277+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:50.278+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:50.279+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:50.280+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:50.280+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:50.281+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:50.282+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:50.283+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:50.283+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:50.284+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:50.285+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:50.286+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:50.287+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:50.287+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:50.288+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:50.289+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:50.290+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:50.291+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:50.291+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:50.292+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:50.293+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:50.294+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:50.294+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:50.295+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:50.296+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:50.297+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:50.297+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:50.298+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:50.299+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:50.300+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:50.301+0000] {subprocess.py:106} INFO - 	... 156 more
[2025-04-02T09:17:50.302+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:50.303+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:50.303+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:50.304+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:50.305+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:50.306+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:50.306+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:50.307+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:50.308+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:50.309+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:50.310+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:50.311+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:50.311+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:50.312+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:50.313+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:50.314+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:50.315+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:50.316+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:50.316+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:50.317+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:50.318+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:50.319+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:50.320+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:50.321+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:50.321+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:50.322+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:50.323+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:50.324+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:50.324+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:50.325+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:50.326+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:50.327+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:50.328+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:50.328+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:50.329+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:50.330+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:50.331+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:50.331+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:50.332+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:50.333+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:50.334+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:50.335+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:50.335+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:50.336+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:50.337+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:50.338+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:50.339+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:50.340+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:50.340+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:50.341+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:50.342+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:50.343+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:50.343+0000] {subprocess.py:106} INFO - 25/04/02 09:17:49 ERROR Datastore: Exception thrown creating StoreManager. See the nested exception
[2025-04-02T09:17:50.344+0000] {subprocess.py:106} INFO - Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:50.345+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:50.346+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:50.347+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:50.347+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:50.348+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:50.349+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:50.350+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:50.351+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:50.352+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:50.353+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:50.353+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:50.354+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:50.355+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:50.356+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:50.356+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:50.357+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:50.358+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:50.358+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:50.359+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:50.360+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:50.360+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:50.361+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:50.362+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:50.362+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:50.363+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:50.364+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:50.365+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:50.365+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:50.366+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:50.367+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:50.368+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:50.369+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:50.369+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:50.370+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:50.371+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:50.371+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:50.372+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:50.373+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:50.374+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:50.374+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:50.375+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:50.376+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:50.376+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:50.377+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:50.378+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:50.378+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:50.379+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:50.380+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:50.380+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:50.381+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:50.382+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:50.383+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:50.384+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:50.385+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:50.386+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:50.386+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:50.387+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:50.388+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:50.389+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:50.390+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:50.390+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:50.391+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:50.392+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:50.393+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:50.394+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:50.394+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:50.395+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:50.396+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:50.396+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:50.397+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:50.398+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:50.398+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:50.399+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:50.400+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:50.400+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:50.401+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:50.402+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:50.403+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:50.404+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:50.404+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:50.405+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:50.405+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:50.406+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:50.407+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:50.408+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:50.408+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:50.409+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:50.410+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:50.410+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:50.411+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:50.412+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:50.412+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:50.413+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:50.414+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:50.414+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:50.415+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:50.416+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:50.417+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:50.418+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:50.418+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:50.419+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:50.420+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:50.421+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:50.422+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:50.423+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:50.423+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:50.424+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:50.425+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:50.425+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:50.426+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:50.427+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:50.427+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:50.428+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:50.429+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:50.429+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:50.430+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:50.431+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:50.431+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:50.432+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:50.433+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:50.434+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:50.435+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:50.436+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:50.437+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:50.437+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:50.438+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:50.439+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:50.440+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:50.441+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:50.441+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:50.442+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:50.443+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:50.444+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:50.444+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:50.445+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:50.446+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:50.447+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:50.447+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:50.448+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:50.449+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:50.450+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:50.451+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:50.451+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:50.452+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:50.453+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:50.454+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:50.455+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:50.455+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:50.456+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:50.457+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:50.458+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:50.459+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:50.459+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:50.460+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:50.461+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:50.461+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:50.462+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:50.463+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:50.463+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:50.464+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:50.465+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:50.466+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:50.466+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:50.467+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:50.468+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:50.469+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:50.469+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:50.470+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:50.471+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:50.473+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:50.474+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:50.475+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:50.476+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:50.478+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:50.479+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:50.480+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:50.481+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:50.482+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:50.483+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:50.484+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:50.486+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:50.487+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:50.487+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:50.489+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:50.490+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:50.491+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:50.492+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:50.493+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:50.493+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:50.495+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:50.495+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:50.496+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:50.497+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:50.498+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:50.499+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:50.499+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:50.500+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:50.501+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:50.502+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:50.503+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:50.503+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:50.504+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:50.505+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:50.506+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:50.506+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:50.508+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:50.508+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:50.509+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:50.510+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:50.511+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:50.512+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:50.514+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:50.516+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:50.517+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:50.519+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:50.520+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:50.521+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:50.522+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:50.523+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:50.524+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:50.525+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:50.526+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:50.527+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:50.527+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:50.528+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:50.529+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:50.529+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:50.530+0000] {subprocess.py:106} INFO - org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:50.531+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:50.531+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:50.532+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:50.533+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:50.534+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:50.535+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:50.536+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:50.537+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:50.537+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:50.538+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:50.539+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:50.540+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:50.541+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:50.541+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:50.542+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:50.543+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:50.544+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:50.544+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:50.545+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:50.546+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:50.546+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:50.547+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:50.548+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:50.549+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:50.549+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:50.550+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:50.551+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:50.553+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:50.554+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:50.555+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:50.555+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:50.556+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:50.557+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:50.558+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:50.558+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:50.559+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:50.560+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:50.561+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:50.562+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:50.563+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:50.563+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:50.564+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:50.565+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:50.566+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:50.566+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:50.567+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:50.568+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:50.569+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:50.570+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:50.570+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:50.571+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:50.572+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:50.573+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:50.573+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:50.574+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:50.575+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:50.576+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:50.576+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:50.577+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:50.578+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:50.578+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:50.579+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:50.580+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:50.581+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:50.582+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:50.582+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:50.583+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:50.584+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:50.584+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:50.585+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:50.586+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:50.587+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:50.587+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:50.588+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:50.589+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:50.590+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:50.591+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:50.592+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:50.593+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:50.593+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:50.594+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:50.595+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:50.596+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:50.597+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:50.598+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:50.598+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:50.599+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:50.600+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:50.601+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:50.602+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:50.602+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:50.603+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:50.604+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:50.605+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:50.606+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:50.607+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:50.607+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:50.608+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:50.609+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:50.610+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:50.610+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:50.611+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:50.612+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:50.612+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:50.613+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:50.614+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:50.614+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:50.615+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:50.616+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:50.617+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:50.617+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:50.618+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:50.619+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:50.620+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:50.621+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:50.621+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:50.622+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:50.623+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:50.624+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:50.624+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:50.625+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:50.626+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:50.627+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:50.628+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:50.628+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:50.629+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:50.630+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:50.630+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:50.631+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:50.632+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:50.632+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:50.633+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:50.634+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:50.635+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:50.636+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:50.637+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:50.637+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:50.638+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:50.639+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:50.640+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:50.640+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:50.641+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:50.641+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:50.642+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:50.643+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:50.644+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:50.644+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:50.645+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:50.646+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:50.647+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:50.648+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:50.648+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:50.649+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:50.650+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:50.651+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:50.652+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:50.653+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:50.653+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:50.654+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:50.655+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:50.656+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:50.656+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:50.657+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:50.658+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:50.659+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:50.659+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:50.660+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:50.661+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:50.661+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:50.662+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:50.662+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:50.663+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:50.664+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:50.664+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:50.665+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:50.666+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:50.666+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:50.667+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:50.668+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:50.669+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:50.670+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:50.671+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:50.672+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:50.673+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:50.674+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:50.675+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:50.675+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:50.676+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:50.677+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:50.678+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:50.678+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:50.679+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:50.680+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:50.681+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:50.681+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:50.682+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:50.683+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:50.684+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:50.684+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:50.685+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:50.686+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:50.687+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:50.688+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:50.689+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:50.689+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:50.690+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:50.691+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:50.692+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:50.693+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:50.693+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:50.694+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:50.695+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:50.696+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:50.696+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:50.697+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:50.697+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:50.698+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:50.699+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:50.700+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:50.701+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:50.702+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:50.702+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:50.703+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:50.704+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:50.705+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:50.706+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:50.706+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:50.707+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)
[2025-04-02T09:17:50.708+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:50.708+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:50.709+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:50.710+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:50.710+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:50.711+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:50.712+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:50.712+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:50.713+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:50.714+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:50.714+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:50.715+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:50.716+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:50.716+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:50.717+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:50.718+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:50.719+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:50.720+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:50.720+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:50.721+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:50.722+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:50.723+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:50.723+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:50.724+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:50.725+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:50.725+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:50.726+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:50.727+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:50.727+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:50.728+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:50.729+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:50.730+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:50.730+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:50.731+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:50.732+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:50.732+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:50.733+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:50.734+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:50.735+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:50.736+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:50.736+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:50.737+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:50.737+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:50.738+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:50.739+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:50.740+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:50.741+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:50.741+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:50.742+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:50.742+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:50.743+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:50.744+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:50.744+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:50.745+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:50.746+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:50.746+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:50.747+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:50.748+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:50.748+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:50.749+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:50.749+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:50.751+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:50.754+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:50.756+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:50.757+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:50.758+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:50.758+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:50.759+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:50.760+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:50.761+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:50.762+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:50.762+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:50.763+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:50.764+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:50.765+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:50.766+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:50.767+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:50.768+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:50.768+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:50.769+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:50.770+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:50.771+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:50.771+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:50.772+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:50.773+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:50.774+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:50.774+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:50.775+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:50.776+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:50.776+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:50.777+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:50.778+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:50.778+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:50.779+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:50.779+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:50.780+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:50.781+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:50.781+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:50.782+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:50.783+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:50.783+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:50.784+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:50.785+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:50.786+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:50.786+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:50.787+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:50.787+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:50.788+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:50.789+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:50.790+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:50.790+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:50.791+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:50.792+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:50.792+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:50.793+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:50.794+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:50.795+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:50.795+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:50.796+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:50.797+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:50.797+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:50.798+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:50.799+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:50.799+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:50.800+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:50.801+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:50.802+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:50.803+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:50.804+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:50.805+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:50.807+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:50.807+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:50.808+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:50.809+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:50.810+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:50.811+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:50.811+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:50.812+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:50.813+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:50.814+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:50.816+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:50.817+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:50.818+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:50.819+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:50.820+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:50.820+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:50.821+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:50.823+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:50.824+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:50.825+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:50.826+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:50.827+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:50.828+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:50.828+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:50.830+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:50.833+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:50.836+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:50.837+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:50.837+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:50.838+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:50.839+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:50.840+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:50.840+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:50.841+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:50.842+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:50.842+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:50.843+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:50.844+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:50.844+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:50.845+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:50.846+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:50.847+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:50.848+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:50.848+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:50.849+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:50.850+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:50.851+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:50.852+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:50.853+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:50.853+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:50.854+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:50.855+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:50.856+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:50.857+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:50.857+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:50.858+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:50.859+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:50.859+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:50.860+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:50.861+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:50.862+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:50.862+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:50.863+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:50.864+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:50.865+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:50.865+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:50.866+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:50.867+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:50.868+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:50.869+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:50.870+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:50.870+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:50.871+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:50.872+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:50.873+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:50.873+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:50.874+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:50.875+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:50.876+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:50.876+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:50.877+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:50.878+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:50.878+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:50.879+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:50.879+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:50.880+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:50.880+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:50.881+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:50.882+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:50.883+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:50.884+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:50.885+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:50.886+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:50.886+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:50.887+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:50.888+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:50.889+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:50.889+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:50.890+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:50.890+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:50.891+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:50.892+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:50.892+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:50.893+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:50.894+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:50.894+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:50.895+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:50.895+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:50.896+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:50.897+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:50.897+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:50.898+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:50.899+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:50.899+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:50.900+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:50.901+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:50.902+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:50.903+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:50.903+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:50.904+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:50.905+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:50.905+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:50.906+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:50.907+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:50.907+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:50.908+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:50.909+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:50.909+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:50.910+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:50.911+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:50.911+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:50.912+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:50.913+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:50.913+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:50.914+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:50.914+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:50.915+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:50.916+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:50.917+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:50.917+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:50.918+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:50.919+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:50.920+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:50.920+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:50.921+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:50.922+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:50.923+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:50.924+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:50.924+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:50.925+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:50.925+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:50.926+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:50.927+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:50.927+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:50.928+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:50.928+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:50.929+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:50.930+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:50.930+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:50.931+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:50.931+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:50.932+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:50.933+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:50.933+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:50.934+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:50.935+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:50.936+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:50.937+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:50.937+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:50.938+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:50.939+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:50.939+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:50.940+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:50.941+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:50.941+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:50.942+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:50.943+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:50.943+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:50.944+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:50.944+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:50.945+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:50.946+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:50.946+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:50.947+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:50.948+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:50.948+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:50.949+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:50.950+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:50.950+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:50.951+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:50.952+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:50.953+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:50.953+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:50.954+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:50.955+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:50.956+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:50.956+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:50.957+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:50.958+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:50.958+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:50.959+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:50.960+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:50.960+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:50.961+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:50.962+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:50.962+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:50.963+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:50.964+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:50.964+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:50.965+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:50.965+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:50.966+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:50.967+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:50.968+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:50.969+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:50.969+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:50.970+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:50.971+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:50.972+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:50.972+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:50.973+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:50.974+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:50.974+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:50.975+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:50.975+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:50.976+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:50.977+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:50.977+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:50.978+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:50.978+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:50.979+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:50.980+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:50.980+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:50.981+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:50.981+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:50.982+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:50.983+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:50.983+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:50.984+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:50.985+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:50.986+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:50.987+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:50.988+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:50.988+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:50.989+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:50.990+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:50.991+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:50.992+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:50.993+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:50.994+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:50.994+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:50.995+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:50.996+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:50.997+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:50.998+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:50.998+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:50.999+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:51.000+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)
[2025-04-02T09:17:51.001+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)
[2025-04-02T09:17:51.002+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:51.003+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:51.004+0000] {subprocess.py:106} INFO - 	... 154 more
[2025-04-02T09:17:51.005+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:51.006+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:51.006+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:51.007+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:51.008+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:51.009+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:51.010+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:51.011+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:51.011+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:51.012+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:51.013+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:51.014+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:51.015+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:51.016+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:51.017+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:51.017+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:51.018+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:51.019+0000] {subprocess.py:106} INFO - 	... 156 more
[2025-04-02T09:17:51.020+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:51.021+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:51.022+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:51.023+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:51.023+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:51.024+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:51.025+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:51.025+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:51.026+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:51.027+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:51.027+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:51.028+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:51.029+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:51.030+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:51.031+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:51.031+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:51.032+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:51.033+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:51.033+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:51.034+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:51.035+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:51.036+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:51.037+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:51.038+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:51.038+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:51.039+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:51.040+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:51.041+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:51.041+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:51.042+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:51.043+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:51.043+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:51.044+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:51.045+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:51.045+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:51.046+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:51.046+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:51.047+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:51.048+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:51.049+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:51.050+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:51.050+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:51.052+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:51.053+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:51.054+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:51.055+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:51.056+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:51.056+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:51.057+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:51.058+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:51.059+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:51.059+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:51.060+0000] {subprocess.py:106} INFO - Nested Throwables StackTrace:
[2025-04-02T09:17:51.061+0000] {subprocess.py:106} INFO - java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:51.062+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:51.062+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:51.063+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:51.064+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:51.064+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:51.065+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:51.066+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:51.066+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:51.067+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:51.068+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:51.069+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:51.070+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:51.070+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:51.071+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:51.072+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:51.073+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:51.073+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:51.074+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:51.075+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:51.075+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:51.076+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:51.077+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:51.077+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:51.078+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:51.078+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:51.079+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:51.080+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:51.080+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:51.081+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:51.082+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:51.082+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:51.083+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:51.084+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:51.084+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:51.085+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:51.086+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:51.087+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:51.087+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:51.088+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:51.089+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:51.089+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:51.090+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:51.091+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:51.091+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:51.092+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:51.093+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:51.094+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:51.094+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:51.095+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:51.096+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:51.096+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:51.097+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:51.098+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:51.098+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:51.099+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:51.100+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:51.100+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:51.101+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:51.102+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:51.103+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:51.103+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:51.104+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:51.105+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:51.105+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:51.106+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:51.107+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:51.107+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:51.108+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:51.109+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:51.110+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:51.110+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:51.111+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:51.112+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:51.112+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:51.113+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:51.114+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:51.114+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:51.115+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:51.116+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:51.116+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:51.117+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:51.118+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:51.119+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:51.119+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:51.120+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:51.120+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:51.121+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:51.122+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:51.122+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:51.123+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:51.123+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:51.124+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:51.125+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:51.125+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:51.126+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:51.127+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:51.127+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:51.128+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:51.129+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:51.129+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:51.130+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:51.131+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:51.131+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:51.132+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:51.133+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:51.133+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:51.134+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:51.135+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:51.136+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:51.137+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:51.137+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:51.138+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:51.139+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:51.139+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:51.140+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:51.141+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:51.141+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:51.142+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:51.143+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:51.143+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:51.144+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:51.145+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:51.145+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:51.146+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:51.147+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:51.147+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:51.148+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:51.148+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:51.149+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:51.150+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:51.150+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:51.151+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:51.152+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:51.152+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:51.153+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:51.154+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:51.154+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:51.155+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:51.155+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:51.156+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:51.157+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:51.157+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:51.158+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:51.158+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:51.159+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:51.160+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:51.160+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:51.161+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:51.162+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:51.162+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:51.163+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:51.164+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:51.164+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:51.165+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:51.165+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:51.166+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:51.167+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:51.168+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:51.169+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:51.169+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:51.170+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:51.170+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:51.171+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:51.172+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:51.172+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:51.173+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:51.174+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:51.174+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:51.175+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:51.175+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:51.176+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:51.177+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:51.177+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:51.178+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:51.179+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:51.179+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:51.180+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:51.180+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:51.181+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:51.182+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:51.182+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:51.183+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:51.184+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:51.185+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:51.185+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:51.186+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:51.187+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:51.188+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:51.188+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:51.189+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:51.190+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:51.190+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:51.191+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:51.191+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:51.192+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:51.193+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:51.193+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:51.194+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:51.194+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:51.195+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:51.196+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:51.196+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:51.197+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:51.197+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:51.198+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:51.198+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:51.199+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:51.200+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:51.200+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:51.201+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:51.202+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:51.203+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:51.203+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:51.204+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:51.204+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:51.205+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:51.206+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:51.206+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:51.207+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:51.207+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:51.208+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:51.209+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:51.209+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:51.210+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:51.210+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:51.211+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:51.211+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:51.212+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:51.213+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:51.213+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:51.214+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:51.214+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:51.215+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)
[2025-04-02T09:17:51.216+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)
[2025-04-02T09:17:51.216+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:51.217+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:51.218+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:51.219+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:51.220+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:51.220+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:51.221+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:51.222+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:51.222+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:51.223+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:51.223+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:51.224+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:51.224+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:51.225+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:51.225+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:51.226+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:51.226+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:51.227+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:51.228+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:51.228+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:51.229+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:51.230+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:51.230+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:51.231+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:51.231+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:51.232+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:51.233+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:51.233+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:51.234+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:51.235+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:51.236+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:51.236+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:51.237+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:51.237+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:51.238+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:51.239+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:51.240+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:51.240+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:51.241+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:51.242+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:51.242+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:51.243+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:51.243+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:51.244+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:51.245+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:51.245+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:51.246+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:51.247+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:51.247+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:51.248+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:51.248+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:51.249+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:51.250+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:51.251+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:51.251+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:51.252+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:51.253+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:51.253+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:51.254+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:51.255+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:51.256+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:51.256+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:51.257+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:51.257+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:51.258+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:51.259+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:51.259+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:51.260+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:51.261+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:51.261+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:51.262+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:51.263+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:51.264+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:51.265+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:51.265+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:51.266+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:51.267+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:51.268+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:51.269+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:51.270+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:51.270+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:51.271+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:51.272+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:51.273+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:51.273+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:51.274+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:51.275+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:51.275+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:51.276+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:51.277+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:51.278+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:51.278+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:51.279+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:51.280+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:51.281+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:51.281+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:51.282+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:51.283+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:51.284+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:51.285+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:51.285+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:51.286+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:51.287+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:51.288+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:51.289+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:51.289+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:51.290+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:51.291+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:51.291+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:51.292+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:51.293+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:51.293+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:51.294+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:51.294+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:51.295+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:51.296+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:51.296+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:51.297+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:51.297+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:51.298+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:51.298+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:51.299+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:51.299+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:51.300+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:51.301+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:51.302+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:51.303+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:51.303+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:51.304+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:51.305+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:51.305+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:51.306+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:51.307+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:51.307+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:51.308+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:51.309+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:51.310+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:51.311+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:51.311+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:51.312+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:51.313+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:51.313+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:51.314+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:51.314+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:51.315+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:51.315+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:51.316+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:51.317+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:51.318+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:51.319+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:51.319+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:51.320+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:51.321+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:51.321+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:51.322+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:51.323+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:51.323+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:51.324+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:51.325+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:51.325+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:51.326+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:51.327+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:51.327+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:51.328+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:51.329+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:51.330+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:51.330+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:51.331+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:51.332+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:51.332+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:51.333+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:51.334+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:51.334+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:51.335+0000] {subprocess.py:106} INFO - 	... 156 more
[2025-04-02T09:17:51.336+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:51.337+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:51.337+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:51.338+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:51.339+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:51.339+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:51.340+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:51.341+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:51.341+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:51.342+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:51.343+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:51.344+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:51.344+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:51.345+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:51.346+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:51.346+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:51.347+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:51.348+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:51.348+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:51.349+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:51.350+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:51.351+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:51.351+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:51.352+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:51.353+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:51.353+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:51.354+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:51.355+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:51.355+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:51.356+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:51.357+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:51.357+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:51.358+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:51.359+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:51.360+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:51.360+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:51.361+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:51.361+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:51.362+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:51.363+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:51.363+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:51.364+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:51.365+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:51.365+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:51.366+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:51.367+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:51.368+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:51.368+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:51.369+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:51.370+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:51.371+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:51.371+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:51.372+0000] {subprocess.py:106} INFO - 25/04/02 09:17:50 WARN HiveMetaStore: Retrying creating default database after error: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:51.373+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:51.374+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:51.374+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:51.375+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:51.376+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:51.376+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:51.377+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:51.377+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:51.378+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:51.379+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:51.380+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:51.380+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:51.381+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:51.382+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:51.383+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:51.384+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:51.385+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:51.385+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:51.386+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:51.387+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:51.387+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:51.388+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:51.389+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:51.390+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:51.390+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:51.391+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:51.392+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:51.392+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:51.393+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:51.394+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:51.394+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:51.395+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:51.395+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:51.396+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:51.397+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:51.397+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:51.398+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:51.399+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:51.399+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:51.400+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:51.401+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:51.402+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:51.403+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:51.403+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:51.404+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:51.405+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:51.406+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:51.406+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:51.407+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:51.407+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:51.408+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:51.409+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:51.409+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:51.410+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:51.411+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:51.411+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:51.412+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:51.412+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:51.413+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:51.414+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:51.414+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:51.415+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:51.415+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:51.416+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:51.416+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:51.417+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:51.418+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:51.419+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:51.419+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:51.420+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:51.421+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:51.421+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:51.422+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:51.423+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:51.423+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:51.424+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:51.425+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:51.425+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:51.426+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:51.427+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:51.427+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:51.428+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:51.428+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:51.429+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:51.430+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:51.430+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:51.431+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:51.431+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:51.432+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:51.432+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:51.433+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:51.434+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:51.435+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:51.436+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:51.436+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:51.437+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:51.438+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:51.439+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:51.440+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:51.440+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:51.441+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:51.442+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:51.443+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:51.443+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:51.444+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:51.444+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:51.445+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:51.446+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:51.447+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:51.448+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:51.449+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:51.450+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:51.450+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:51.451+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:51.452+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:51.453+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:51.453+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:51.454+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:51.454+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:51.455+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:51.456+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:51.456+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:51.457+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:51.458+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:51.458+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:51.459+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:51.460+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:51.460+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:51.461+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:51.461+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:51.462+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:51.463+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:51.463+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:51.464+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:51.465+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:51.465+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:51.466+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:51.467+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:51.468+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:51.468+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:51.469+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:51.470+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:51.470+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:51.471+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:51.472+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:51.473+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:51.473+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:51.474+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:51.474+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:51.475+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:51.475+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:51.476+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:51.477+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:51.477+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:51.478+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:51.478+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:51.479+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:51.479+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:51.480+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:51.480+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:51.481+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:51.482+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:51.482+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:51.483+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:51.484+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:51.485+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:51.486+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:51.486+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:51.487+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:51.487+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:51.488+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:51.489+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:51.489+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:51.490+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:51.491+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:51.491+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:51.492+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:51.492+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:51.493+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:51.494+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:51.494+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:51.495+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:51.496+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:51.496+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:51.497+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:51.498+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:51.498+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:51.499+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:51.499+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:51.500+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:51.501+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:51.502+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:51.503+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:51.503+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:51.504+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:51.505+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:51.505+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:51.506+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:51.507+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:51.507+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:51.508+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:51.509+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:51.509+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:51.510+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:51.511+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:51.511+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:51.512+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:51.513+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:51.513+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:51.514+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:51.515+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:51.515+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:51.516+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:51.517+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:51.518+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:51.519+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:51.519+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:51.520+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:51.521+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:51.521+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:51.522+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:51.523+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:51.523+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:51.524+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:51.525+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:51.525+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:51.526+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:51.526+0000] {subprocess.py:106} INFO - javax.jdo.JDOFatalDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:51.527+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:51.528+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:51.528+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:51.529+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:51.530+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:51.530+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:51.531+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:51.532+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:51.532+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:51.533+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:51.534+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:51.534+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:51.535+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:51.536+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:51.536+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:51.537+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:51.538+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:51.539+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:51.539+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:51.540+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:51.540+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:51.541+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:51.542+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:51.543+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:51.543+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:51.544+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:51.544+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:51.545+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:51.546+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:51.546+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:51.547+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:51.548+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:51.548+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:51.549+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:51.549+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:51.550+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:51.551+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:51.551+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:51.552+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:51.553+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:51.553+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:51.554+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:51.555+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:51.555+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:51.556+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:51.557+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:51.557+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:51.558+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:51.558+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:51.559+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:51.560+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:51.560+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:51.561+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:51.562+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:51.563+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:51.564+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:51.565+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:51.565+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:51.566+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:51.567+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:51.569+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:51.570+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:51.571+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:51.572+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:51.573+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:51.574+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:51.575+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:51.576+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:51.577+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:51.578+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:51.579+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:51.580+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:51.582+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:51.583+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:51.584+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:51.585+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:51.586+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:51.587+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:51.588+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:51.589+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:51.590+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:51.591+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:51.592+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:51.594+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:51.595+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:51.595+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:51.596+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:51.597+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:51.598+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:51.599+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:51.600+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:51.602+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:51.603+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:51.604+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:51.606+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:51.607+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:51.608+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:51.609+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:51.610+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:51.611+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:51.612+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:51.613+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:51.614+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:51.615+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:51.616+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:51.617+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:51.619+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:51.620+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:51.621+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:51.622+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:51.623+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:51.624+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:51.625+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:51.626+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:51.627+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:51.628+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:51.629+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:51.630+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:51.631+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:51.633+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:51.634+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:51.635+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:51.637+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:51.639+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:51.640+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:51.641+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:51.642+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:51.644+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:51.645+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:51.646+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:51.647+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:51.648+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:51.649+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:51.651+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:51.652+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:51.653+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:51.655+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:51.657+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:51.658+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:51.659+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:51.660+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:51.661+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:51.662+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:51.662+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:51.663+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:51.664+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:51.666+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:51.667+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:51.669+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:51.670+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:51.671+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:51.672+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:51.673+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:51.674+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:51.675+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:51.676+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:51.678+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:51.679+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:51.681+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:51.682+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:51.683+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:51.684+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:51.686+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:51.687+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:51.688+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:51.690+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:51.691+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:51.692+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:51.693+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:51.695+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:51.696+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:51.697+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:51.698+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:51.698+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:51.702+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:51.703+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:51.705+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:51.706+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:51.707+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:51.708+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:51.709+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:51.713+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:51.714+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:51.716+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:51.717+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:51.719+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:51.720+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:51.722+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:51.723+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:51.724+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:51.725+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:51.727+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:51.728+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:51.729+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:51.731+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:51.732+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:51.733+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:51.735+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:51.736+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:51.738+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:51.739+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:51.740+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:51.742+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:51.744+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:51.746+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:51.748+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:51.750+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:51.752+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:51.754+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:51.756+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:51.757+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:51.760+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:51.762+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:51.763+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:51.765+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:51.766+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:51.767+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:51.769+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:51.770+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:51.772+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:51.773+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:51.775+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:51.776+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:51.777+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:51.778+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:51.779+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:51.780+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:51.781+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:529)
[2025-04-02T09:17:51.782+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:830)
[2025-04-02T09:17:51.783+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:51.784+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:51.785+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:51.787+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:51.788+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:51.789+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:51.790+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:51.792+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:51.793+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:51.795+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:51.796+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:51.797+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:51.798+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:51.799+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:51.801+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:51.803+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:51.804+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:51.806+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:51.807+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:51.809+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:51.810+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:51.811+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:51.812+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:51.813+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:51.814+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:51.815+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:51.816+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:51.818+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:51.820+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:51.822+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:51.823+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:51.824+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:51.825+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:51.826+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:51.827+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:51.828+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:51.829+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:51.830+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:51.831+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:51.833+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:51.835+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:51.836+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:51.837+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:51.838+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:51.839+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:51.840+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:51.841+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:51.842+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:51.843+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:51.844+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:51.844+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:51.845+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:51.847+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:51.848+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:51.849+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:51.850+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:51.851+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:51.852+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:51.855+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:51.856+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:51.857+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:51.858+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:51.859+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:51.860+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:51.861+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:51.862+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:51.863+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:51.863+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:51.864+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:51.865+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:51.865+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:51.867+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:51.868+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:51.869+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:51.869+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:51.870+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:51.870+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:51.872+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:51.873+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:51.873+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:51.874+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:51.875+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:51.875+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:51.876+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:51.877+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:51.878+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:51.878+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:51.879+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:51.879+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:51.880+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:51.881+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:51.882+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:51.882+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:51.883+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:51.884+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:51.885+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:51.886+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:51.887+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:51.888+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:51.888+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:51.889+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:51.890+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:51.891+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:51.892+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:51.892+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:51.893+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:51.894+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:51.895+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:51.896+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:51.896+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:51.897+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:51.898+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:51.898+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:51.899+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:51.900+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:51.901+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:51.902+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:51.903+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:51.903+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:51.904+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:51.905+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:51.906+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:51.907+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:51.908+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:51.909+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:51.909+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:51.910+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:51.911+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:51.912+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:51.912+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:51.913+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:51.914+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:51.915+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:51.915+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:51.916+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:51.917+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:51.918+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:51.919+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:51.919+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:51.920+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:51.921+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:51.922+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:51.923+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:51.924+0000] {subprocess.py:106} INFO - NestedThrowablesStackTrace:
[2025-04-02T09:17:51.924+0000] {subprocess.py:106} INFO - java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:51.925+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:51.926+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:51.926+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:51.927+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:51.928+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:51.928+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:51.929+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:51.930+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:51.931+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:51.931+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:51.932+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:51.933+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:51.934+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:51.935+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:51.936+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:51.936+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:51.937+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:51.938+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:51.938+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:51.939+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:51.940+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:51.941+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:51.941+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:51.942+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:51.943+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:51.944+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:51.944+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:51.945+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:51.946+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:51.946+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:51.947+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:51.948+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:51.949+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:51.949+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:51.950+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:51.951+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:51.952+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:51.953+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:51.954+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:51.954+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:51.955+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:51.956+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:51.957+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:51.957+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:51.958+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:51.959+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:51.960+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:51.961+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:51.962+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:51.962+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:51.963+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:51.964+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:51.965+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:51.965+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:51.966+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:51.967+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:51.968+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:51.969+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:51.971+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:51.972+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:51.973+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:51.973+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:51.974+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:51.975+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:51.975+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:51.976+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:51.977+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:51.977+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:51.978+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:51.978+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:51.979+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:51.980+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:51.980+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:51.981+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:51.982+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:51.982+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:51.983+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:51.984+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:51.985+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:51.986+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:51.986+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:51.987+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:51.987+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:51.988+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:51.989+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:51.990+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:51.990+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:51.991+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:51.992+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:51.993+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:51.993+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:51.994+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:51.994+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:51.995+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:51.996+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:51.996+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:51.997+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:51.997+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:51.998+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:51.999+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:51.999+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:52.000+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:52.001+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:52.002+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:52.002+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:52.003+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:52.004+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:52.004+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:52.005+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:52.006+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:52.007+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:52.007+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:52.008+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:52.008+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:52.009+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:52.010+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:52.010+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:52.011+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:52.011+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:52.012+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:52.012+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:52.013+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:52.014+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:52.014+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:52.015+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:52.016+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:52.016+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:52.017+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:52.018+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:52.019+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:52.019+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:52.020+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:52.021+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:52.021+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:52.022+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:52.023+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:52.024+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:52.024+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:52.025+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:52.026+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:52.026+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:52.027+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:52.028+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:52.028+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:52.029+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:52.029+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:52.030+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:52.031+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:52.031+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:52.032+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:52.032+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:52.033+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:52.034+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:52.035+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:52.035+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:52.036+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:52.036+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:52.037+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:52.037+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:52.038+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:52.039+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:52.040+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:52.040+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:52.041+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:52.041+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:52.042+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:52.043+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:52.043+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:52.044+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:52.045+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:52.045+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:52.046+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:52.047+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:52.047+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:52.048+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:52.049+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:52.050+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:52.050+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:52.051+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:52.052+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:52.053+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:52.053+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:52.054+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.055+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:52.055+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:52.056+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:52.057+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:52.057+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:52.058+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:52.059+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:52.059+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:52.060+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.061+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:52.061+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:52.062+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:52.063+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:52.063+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:52.064+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:52.065+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:52.065+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:52.066+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.066+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:52.067+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:52.068+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:52.069+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:52.070+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:52.070+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:52.071+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:52.072+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:52.073+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.073+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:52.074+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:52.075+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:52.075+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:52.076+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:52.076+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:52.077+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:52.078+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:52.078+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:52.079+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:52.079+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:52.080+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:52.081+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.081+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:52.082+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:52.083+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:52.083+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:52.084+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:52.085+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:52.086+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:52.087+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:52.087+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:52.088+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)
[2025-04-02T09:17:52.089+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)
[2025-04-02T09:17:52.089+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:52.090+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:52.091+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:52.092+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:52.092+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:52.093+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:52.093+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:52.094+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:52.095+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:52.095+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:52.096+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:52.097+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:52.097+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:52.098+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:52.099+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:52.099+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:52.100+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:52.101+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:52.102+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:52.103+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:52.103+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.104+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:52.105+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:52.105+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:52.106+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:52.107+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:52.108+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:52.108+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:52.109+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:52.110+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:52.110+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:52.111+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:52.112+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:52.112+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:52.113+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:52.114+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:52.114+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:52.115+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:52.116+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:52.116+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:52.117+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:52.118+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:52.119+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:52.119+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:52.120+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:52.121+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:52.121+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:52.122+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:52.123+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:52.124+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:52.124+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:52.125+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:52.126+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:52.126+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:52.127+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:52.127+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:52.128+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:52.129+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:52.129+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:52.130+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:52.130+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:52.131+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:52.131+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:52.132+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:52.133+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:52.134+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:52.135+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:52.136+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:52.136+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:52.137+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:52.137+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:52.138+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:52.139+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:52.140+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:52.140+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:52.141+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:52.141+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:52.142+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:52.143+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:52.143+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:52.144+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:52.145+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:52.145+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:52.146+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:52.147+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:52.147+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:52.148+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:52.148+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:52.149+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:52.150+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:52.151+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:52.152+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:52.152+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:52.153+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:52.153+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:52.154+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:52.155+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:52.156+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:52.156+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:52.157+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:52.157+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:52.158+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:52.159+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:52.159+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:52.160+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:52.161+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:52.162+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:52.162+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:52.163+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:52.163+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:52.164+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:52.165+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:52.165+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:52.166+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:52.167+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:52.168+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:52.169+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:52.169+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:52.170+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:52.171+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:52.171+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:52.172+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:52.173+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:52.174+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:52.174+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:52.175+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:52.175+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:52.176+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:52.177+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:52.177+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:52.178+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:52.179+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:52.179+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:52.180+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:52.180+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:52.181+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:52.182+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:52.182+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:52.183+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:52.184+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:52.185+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:52.185+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:52.186+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:52.187+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:52.187+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:52.188+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:52.189+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:52.190+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:52.190+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:52.191+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:52.191+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:52.192+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:52.193+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:52.193+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:52.194+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:52.195+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:52.195+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:52.196+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:52.197+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:52.197+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:52.198+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:52.199+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:52.199+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:52.200+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:52.200+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.201+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:52.202+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:52.203+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:52.203+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:52.204+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:52.205+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:52.206+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:52.206+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:52.207+0000] {subprocess.py:106} INFO - 	... 156 more
[2025-04-02T09:17:52.208+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:52.208+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:52.209+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:52.210+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:52.211+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:52.211+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:52.212+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:52.212+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:52.213+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:52.214+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.214+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:52.215+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:52.216+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:52.217+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:52.217+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:52.218+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:52.219+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:52.220+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:52.220+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.221+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:52.222+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:52.222+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:52.223+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:52.224+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:52.225+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:52.225+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:52.226+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:52.227+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.227+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:52.228+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:52.229+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:52.230+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:52.230+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:52.231+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:52.232+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:52.232+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:52.233+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.234+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:52.235+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:52.236+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:52.236+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:52.237+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:52.238+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:52.238+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:52.239+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:52.240+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:52.240+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:52.241+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:52.242+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:52.242+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.243+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:52.243+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:52.244+0000] {subprocess.py:106} INFO - 25/04/02 09:17:51 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
[2025-04-02T09:17:52.245+0000] {subprocess.py:106} INFO - 25/04/02 09:17:51 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
[2025-04-02T09:17:52.245+0000] {subprocess.py:106} INFO - 25/04/02 09:17:51 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
[2025-04-02T09:17:52.246+0000] {subprocess.py:106} INFO - 25/04/02 09:17:51 INFO ObjectStore: ObjectStore, initialize called
[2025-04-02T09:17:52.246+0000] {subprocess.py:106} INFO - 25/04/02 09:17:51 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
[2025-04-02T09:17:52.247+0000] {subprocess.py:106} INFO - 25/04/02 09:17:51 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
[2025-04-02T09:17:52.248+0000] {subprocess.py:106} INFO - 25/04/02 09:17:51 ERROR Schema: Failed initialising database.
[2025-04-02T09:17:52.248+0000] {subprocess.py:106} INFO - Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:52.249+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:52.250+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:52.250+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:52.251+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:52.252+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:52.252+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:52.253+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:52.254+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:52.254+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.255+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:52.256+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:52.257+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:52.257+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:52.258+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:52.259+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:52.259+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:52.260+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:52.261+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:52.261+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:52.262+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:52.263+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:52.263+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:52.264+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:52.264+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:52.265+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:52.266+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:52.266+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:52.267+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:52.268+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:52.269+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:52.270+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:52.270+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:52.271+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:52.271+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:52.272+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:52.273+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:52.273+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:52.274+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.275+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:52.276+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:52.276+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:52.277+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:52.277+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:52.278+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:52.278+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:52.279+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:52.280+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:52.280+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:52.281+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:52.282+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:52.282+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:52.283+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:52.284+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:52.285+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:52.285+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)
[2025-04-02T09:17:52.286+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:52.286+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:52.287+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:52.288+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:52.289+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:52.289+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:52.291+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:52.292+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:52.293+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:52.294+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:52.296+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:52.296+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:52.297+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:52.298+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:52.299+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:52.299+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:52.300+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:52.301+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:52.302+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:52.303+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:52.304+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:52.305+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:52.305+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:52.306+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:52.307+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:52.307+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:52.308+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:52.309+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:52.309+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:52.310+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:52.310+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:52.311+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:52.312+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:52.312+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:52.313+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:52.313+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:52.314+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:52.315+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:52.315+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:52.316+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:52.317+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:52.317+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:52.318+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:52.319+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:52.320+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:52.321+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:52.322+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:52.322+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:52.323+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:52.324+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:52.324+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:52.325+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:52.326+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:52.326+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:52.327+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:52.328+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:52.328+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:52.329+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:52.329+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:52.330+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:52.331+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:52.331+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:52.332+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:52.333+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:52.334+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:52.334+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:52.335+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:52.336+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:52.336+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:52.337+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:52.338+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:52.339+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:52.339+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:52.340+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:52.341+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:52.341+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:52.342+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:52.343+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:52.343+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:52.344+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:52.344+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:52.345+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:52.346+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:52.346+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:52.347+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:52.348+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:52.348+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:52.349+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:52.350+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:52.350+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:52.351+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:52.352+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:52.353+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:52.354+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:52.354+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:52.355+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:52.356+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:52.357+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:52.358+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:52.358+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:52.359+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:52.359+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:52.360+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:52.360+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:52.361+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:52.361+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:52.362+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:52.362+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:52.363+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:52.363+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:52.364+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:52.365+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:52.366+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:52.366+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:52.367+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:52.368+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:52.369+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:52.369+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:52.370+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:52.371+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:52.371+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:52.372+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:52.373+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:52.373+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:52.374+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:52.375+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:52.376+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:52.376+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.377+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:52.378+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:52.378+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:52.379+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:52.379+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:52.380+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:52.381+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:52.381+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:52.382+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.383+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:52.383+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:52.384+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:52.385+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:52.386+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:52.386+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:52.387+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:52.388+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:52.389+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.389+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:52.390+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:52.391+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:52.391+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:52.392+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:52.393+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:52.393+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:52.394+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:52.395+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.395+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:52.396+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:52.397+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:52.397+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:52.398+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:52.399+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:52.400+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:52.402+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:52.403+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:52.404+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:52.405+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:52.406+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:52.407+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.407+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:52.408+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:52.408+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:52.409+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:52.410+0000] {subprocess.py:106} INFO - org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:52.410+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:52.411+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:52.411+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:52.412+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:52.413+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:52.413+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:52.414+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:52.415+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:52.415+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.416+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:52.416+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:52.417+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:52.418+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:52.419+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:52.419+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:52.420+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:52.420+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:52.421+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:52.422+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:52.423+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:52.423+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:52.424+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:52.425+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:52.425+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:52.426+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:52.427+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:52.427+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:52.428+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:52.429+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:52.429+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:52.430+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:52.431+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:52.431+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:52.432+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:52.433+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:52.434+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:52.434+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:52.435+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.436+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:52.437+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:52.438+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:52.438+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:52.439+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:52.440+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:52.440+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:52.441+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:52.441+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:52.442+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:52.442+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:52.443+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:52.444+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:52.445+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:52.445+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:52.446+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:52.447+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)
[2025-04-02T09:17:52.448+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:52.448+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:52.449+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:52.450+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:52.452+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:52.453+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:52.454+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:52.454+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:52.455+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:52.456+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:52.457+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:52.458+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:52.459+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:52.460+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:52.461+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:52.462+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:52.462+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:52.463+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:52.464+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:52.465+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:52.466+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:52.467+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:52.468+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:52.469+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:52.470+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:52.471+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:52.472+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:52.473+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:52.474+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:52.475+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:52.476+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:52.477+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:52.478+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:52.478+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:52.479+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:52.480+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:52.481+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:52.482+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:52.483+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:52.484+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:52.485+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:52.486+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:52.487+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:52.488+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:52.489+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:52.490+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:52.491+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:52.492+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:52.493+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:52.494+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:52.494+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:52.495+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:52.496+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:52.497+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:52.498+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:52.499+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:52.500+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:52.502+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:52.503+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:52.504+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:52.505+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:52.506+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:52.507+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:52.508+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:52.508+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:52.509+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:52.510+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:52.511+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:52.511+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:52.512+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:52.513+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:52.513+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:52.514+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:52.515+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:52.515+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:52.516+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:52.518+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:52.519+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:52.524+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:52.525+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:52.526+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:52.527+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:52.528+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:52.529+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:52.531+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:52.532+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:52.532+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:52.533+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:52.534+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:52.535+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:52.535+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:52.536+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:52.536+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:52.537+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:52.538+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:52.539+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:52.540+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:52.540+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:52.541+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:52.542+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:52.542+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:52.543+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:52.544+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:52.545+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:52.545+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:52.546+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:52.546+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:52.547+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:52.548+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:52.548+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:52.549+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:52.550+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:52.550+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:52.552+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:52.552+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:52.553+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:52.554+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:52.554+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:52.555+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:52.556+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:52.556+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:52.557+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:52.558+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:52.558+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:52.559+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:52.560+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:52.561+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:52.561+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.562+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:52.563+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:52.563+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:52.564+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:52.565+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:52.565+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:52.566+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:52.567+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:52.567+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.568+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:52.569+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:52.570+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:52.570+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:52.571+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:52.572+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:52.573+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:52.573+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:52.574+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.575+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:52.576+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:52.576+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:52.577+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:52.577+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:52.578+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:52.579+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:52.579+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:52.580+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.581+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:52.581+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:52.582+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:52.583+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:52.584+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:52.584+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:52.585+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:52.586+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:52.587+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:52.587+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:52.588+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:52.589+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:52.589+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.590+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:52.591+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:52.591+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:52.592+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:52.593+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)
[2025-04-02T09:17:52.593+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:52.594+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:52.595+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:52.595+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:52.596+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:52.596+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:52.597+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:52.598+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:52.598+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:52.599+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:52.600+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:52.601+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:52.601+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:52.602+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:52.603+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:52.603+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:52.604+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:52.605+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:52.606+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.606+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:52.607+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:52.608+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:52.608+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:52.609+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:52.610+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:52.610+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:52.611+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:52.612+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:52.612+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:52.613+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:52.614+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:52.614+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:52.615+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:52.615+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:52.616+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:52.617+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)
[2025-04-02T09:17:52.618+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:52.618+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:52.619+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:52.620+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:52.620+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:52.621+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:52.622+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:52.622+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:52.623+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:52.624+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:52.625+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:52.625+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:52.626+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:52.626+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:52.627+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:52.627+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:52.628+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:52.628+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:52.629+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:52.630+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:52.630+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:52.631+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:52.631+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:52.632+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:52.633+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:52.634+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:52.634+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:52.635+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:52.636+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:52.637+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:52.637+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:52.638+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:52.639+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:52.639+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:52.640+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:52.641+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:52.641+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:52.642+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:52.642+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:52.643+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:52.644+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:52.644+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:52.645+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:52.646+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:52.646+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:52.647+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:52.647+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:52.648+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:52.649+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:52.649+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:52.650+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:52.651+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:52.652+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:52.652+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:52.653+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:52.654+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:52.654+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:52.655+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:52.656+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:52.656+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:52.657+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:52.658+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:52.658+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:52.659+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:52.660+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:52.660+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:52.661+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:52.661+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:52.662+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:52.663+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:52.664+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:52.664+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:52.665+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:52.666+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:52.666+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:52.667+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:52.668+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:52.669+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:52.669+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:52.670+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:52.671+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:52.671+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:52.672+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:52.673+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:52.674+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:52.674+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:52.675+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:52.676+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:52.676+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:52.677+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:52.678+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:52.678+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:52.679+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:52.680+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:52.680+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:52.681+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:52.682+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:52.682+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:52.683+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:52.684+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:52.685+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:52.685+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:52.686+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:52.687+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:52.687+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:52.688+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:52.689+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:52.690+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:52.690+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:52.691+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:52.691+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:52.692+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:52.693+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:52.693+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:52.694+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:52.694+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:52.695+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:52.695+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:52.696+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:52.697+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:52.698+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:52.698+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:52.699+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:52.699+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:52.700+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:52.701+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:52.702+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:52.703+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.704+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:52.704+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:52.705+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:52.706+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:52.706+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:52.707+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:52.708+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:52.708+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:52.709+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:52.710+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:52.710+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:52.711+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:52.712+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:52.712+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:52.713+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:52.714+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:52.714+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:52.715+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:52.715+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:52.716+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:52.717+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:52.718+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:52.719+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:52.719+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:52.720+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:52.721+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:52.722+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:52.723+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:52.724+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.724+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:52.725+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:52.726+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:52.727+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:52.728+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:52.729+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:52.729+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:52.730+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:52.731+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:52.732+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:52.733+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:52.733+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:52.734+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:52.735+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:52.736+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:52.737+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:52.738+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)
[2025-04-02T09:17:52.738+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:52.739+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:52.740+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:52.741+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:52.741+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:52.742+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:52.743+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:52.744+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:52.745+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:52.745+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:52.746+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:52.747+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:52.748+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:52.748+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:52.749+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:52.750+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:52.751+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:52.752+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:52.753+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:52.754+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:52.754+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:52.755+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:52.756+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:52.757+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:52.757+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:52.758+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:52.759+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:52.760+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:52.760+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:52.761+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:52.762+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:52.763+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:52.763+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:52.764+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:52.765+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:52.765+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:52.766+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:52.767+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:52.768+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:52.769+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:52.769+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:52.770+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:52.771+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:52.772+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:52.772+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:52.773+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:52.774+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:52.774+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:52.775+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:52.776+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:52.776+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:52.777+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:52.778+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:52.778+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:52.779+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:52.780+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:52.780+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:52.781+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:52.782+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:52.783+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:52.784+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:52.785+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:52.786+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:52.787+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:52.788+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:52.788+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:52.789+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:52.790+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:52.791+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:52.792+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:52.792+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:52.793+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:52.794+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:52.794+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:52.795+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:52.796+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:52.796+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:52.797+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:52.798+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:52.799+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:52.799+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:52.800+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:52.801+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:52.802+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:52.803+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:52.804+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:52.805+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:52.806+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:52.807+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:52.807+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:52.808+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:52.808+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:52.809+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:52.810+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:52.810+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:52.811+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:52.812+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:52.812+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:52.813+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:52.814+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:52.814+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:52.815+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:52.816+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:52.816+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:52.817+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:52.818+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:52.819+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:52.820+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:52.820+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:52.821+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:52.822+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:52.823+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:52.824+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:52.825+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:52.826+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:52.826+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:52.827+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:52.828+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:52.829+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:52.829+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:52.830+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:52.831+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:52.832+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:52.832+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:52.833+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:52.834+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:52.835+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:52.836+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.837+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:52.838+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:52.839+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:52.840+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:52.840+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:52.841+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:52.842+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:52.843+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:52.843+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.844+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:52.844+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:52.845+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:52.846+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:52.847+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:52.848+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:52.849+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:52.849+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:52.850+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.851+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:52.852+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:52.853+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:52.854+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:52.855+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:52.856+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:52.857+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:52.857+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:52.858+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.858+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:52.859+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:52.860+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:52.860+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:52.861+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:52.862+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:52.863+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:52.864+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:52.864+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:52.865+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:52.867+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:52.868+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:52.869+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.870+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:52.870+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:52.871+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:52.872+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:52.873+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:52.874+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:52.874+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:52.875+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:52.877+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:52.877+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)
[2025-04-02T09:17:52.879+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)
[2025-04-02T09:17:52.880+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:52.882+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:52.882+0000] {subprocess.py:106} INFO - 	... 154 more
[2025-04-02T09:17:52.883+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:52.884+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:52.885+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:52.886+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:52.888+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:52.892+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:52.893+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:52.894+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:52.895+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.895+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:52.896+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:52.897+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:52.898+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:52.899+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:52.899+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:52.900+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:52.902+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:52.903+0000] {subprocess.py:106} INFO - 	... 156 more
[2025-04-02T09:17:52.904+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:52.904+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:52.905+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:52.906+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:52.907+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:52.910+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:52.912+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:52.913+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:52.913+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:52.915+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.916+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:52.917+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:52.917+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:52.918+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:52.919+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:52.920+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:52.920+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:52.921+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:52.922+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.923+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:52.923+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:52.924+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:52.925+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:52.926+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:52.927+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:52.928+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:52.928+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:52.929+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.930+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:52.931+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:52.931+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:52.932+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:52.933+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:52.934+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:52.935+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:52.936+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:52.937+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.937+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:52.938+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:52.939+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:52.940+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:52.940+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:52.941+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:52.941+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:52.942+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:52.943+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:52.943+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:52.944+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:52.944+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:52.945+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.945+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:52.946+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:52.947+0000] {subprocess.py:106} INFO - Nested Throwables StackTrace:
[2025-04-02T09:17:52.947+0000] {subprocess.py:106} INFO - java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:52.948+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:52.949+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:52.949+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:52.950+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:52.951+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:52.952+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:52.953+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:52.953+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:52.954+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.955+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:52.955+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:52.956+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:52.957+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:52.957+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:52.958+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:52.958+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:52.959+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:52.960+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:52.960+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:52.961+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:52.962+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:52.962+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:52.963+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:52.963+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:52.964+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:52.965+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:52.965+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:52.966+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:52.967+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:52.967+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:52.968+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:52.969+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:52.970+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:52.970+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:52.971+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:52.972+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:52.973+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:52.973+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:52.974+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:52.974+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:52.975+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:52.976+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:52.977+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:52.977+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:52.978+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:52.979+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:52.979+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:52.980+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:52.981+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:52.982+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:52.982+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:52.983+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:52.984+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:52.985+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:52.986+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)
[2025-04-02T09:17:52.986+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:52.987+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:52.988+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:52.989+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:52.990+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:52.990+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:52.991+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:52.991+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:52.992+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:52.993+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:52.994+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:52.994+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:52.995+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:52.995+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:52.996+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:52.997+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:52.997+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:52.998+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:52.998+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:52.999+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:53.000+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:53.000+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:53.001+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:53.002+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:53.003+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:53.003+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:53.004+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:53.005+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:53.005+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:53.006+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:53.007+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:53.007+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:53.008+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:53.009+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:53.010+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:53.010+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:53.011+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:53.012+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:53.013+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:53.014+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:53.014+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:53.015+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:53.016+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:53.017+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:53.018+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:53.019+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:53.019+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:53.020+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:53.020+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:53.021+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:53.022+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:53.023+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:53.023+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:53.024+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:53.024+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:53.025+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:53.026+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:53.026+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:53.027+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:53.028+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:53.028+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:53.029+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:53.030+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:53.030+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:53.031+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:53.032+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:53.032+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:53.033+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:53.034+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:53.035+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:53.035+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:53.036+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:53.037+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:53.037+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:53.038+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:53.039+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:53.039+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:53.040+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:53.041+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:53.041+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:53.042+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:53.043+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:53.043+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:53.044+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:53.044+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:53.045+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:53.046+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:53.046+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:53.047+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:53.048+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:53.048+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:53.049+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:53.050+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:53.051+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:53.051+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:53.052+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:53.053+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:53.054+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:53.055+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:53.055+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:53.056+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:53.057+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:53.057+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:53.058+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:53.058+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:53.059+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:53.059+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:53.060+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:53.061+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:53.061+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:53.062+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:53.063+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:53.063+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:53.064+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:53.065+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:53.065+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:53.066+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:53.067+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:53.068+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:53.069+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:53.069+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:53.070+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:53.071+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:53.071+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:53.072+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:53.073+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:53.073+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:53.074+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:53.075+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:53.075+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:53.076+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:53.077+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:53.077+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:53.078+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:53.078+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:53.079+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:53.079+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:53.080+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:53.080+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:53.081+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:53.082+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:53.082+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:53.083+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:53.084+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:53.084+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:53.085+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:53.086+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:53.087+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:53.087+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:53.088+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:53.088+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:53.089+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:53.090+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:53.090+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:53.091+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:53.091+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:53.092+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:53.092+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:53.093+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:53.094+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:53.094+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:53.095+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:53.096+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:53.096+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:53.097+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:53.098+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:53.098+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:53.099+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:53.100+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:53.101+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:53.101+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:53.102+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:53.103+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:53.103+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:53.104+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:53.104+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:53.105+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:53.106+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)
[2025-04-02T09:17:53.106+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)
[2025-04-02T09:17:53.107+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:53.107+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:53.108+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:53.109+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:53.109+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:53.110+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:53.110+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:53.111+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:53.112+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:53.112+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:53.113+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:53.114+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:53.114+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:53.115+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:53.116+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:53.116+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:53.117+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:53.118+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:53.119+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:53.119+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:53.120+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:53.120+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:53.121+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:53.122+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:53.123+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:53.123+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:53.124+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:53.125+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:53.125+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:53.126+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:53.127+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:53.127+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:53.128+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:53.129+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:53.129+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:53.130+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:53.131+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:53.131+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)
[2025-04-02T09:17:53.132+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:53.132+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:53.133+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:53.134+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:53.135+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:53.136+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:53.136+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:53.137+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:53.137+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:53.138+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:53.139+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:53.139+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:53.140+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:53.141+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:53.141+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:53.142+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:53.142+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:53.143+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:53.144+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:53.144+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:53.145+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:53.146+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:53.146+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:53.147+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:53.147+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:53.148+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:53.149+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:53.149+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:53.150+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:53.151+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:53.152+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:53.153+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:53.153+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:53.154+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:53.154+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:53.155+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:53.155+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:53.156+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:53.157+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:53.158+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:53.158+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:53.159+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:53.160+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:53.160+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:53.161+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:53.162+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:53.162+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:53.163+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:53.163+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:53.164+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:53.165+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:53.165+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:53.166+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:53.166+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:53.167+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:53.168+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:53.169+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:53.169+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:53.170+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:53.171+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:53.171+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:53.172+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:53.173+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:53.173+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:53.174+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:53.175+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:53.175+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:53.176+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:53.177+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:53.178+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:53.178+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:53.179+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:53.180+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:53.180+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:53.181+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:53.181+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:53.182+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:53.183+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:53.183+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:53.184+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:53.185+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:53.186+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:53.186+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:53.187+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:53.188+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:53.189+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:53.190+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:53.190+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:53.191+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:53.191+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:53.192+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:53.193+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:53.193+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:53.194+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:53.195+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:53.195+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:53.196+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:53.197+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:53.197+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:53.198+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:53.198+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:53.199+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:53.200+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:53.200+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:53.201+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:53.202+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:53.203+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:53.204+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:53.204+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:53.205+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:53.206+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:53.206+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:53.207+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:53.207+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:53.208+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:53.209+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:53.209+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:53.210+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:53.210+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:53.211+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:53.212+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:53.212+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:53.213+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:53.214+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:53.214+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:53.215+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:53.216+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:53.216+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:53.217+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:53.218+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:53.219+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:53.219+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:53.220+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:53.220+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:53.221+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:53.222+0000] {subprocess.py:106} INFO - 	... 156 more
[2025-04-02T09:17:53.222+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:53.223+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:53.224+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:53.224+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:53.225+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:53.226+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:53.226+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:53.227+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:53.228+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:53.228+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:53.229+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:53.229+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:53.230+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:53.231+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:53.232+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:53.232+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:53.233+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:53.234+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:53.234+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:53.235+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:53.236+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:53.236+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:53.237+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:53.238+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:53.238+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:53.239+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:53.240+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:53.240+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:53.241+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:53.242+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:53.242+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:53.243+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:53.244+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:53.244+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:53.245+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:53.245+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:53.246+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:53.247+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:53.247+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:53.248+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:53.248+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:53.249+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:53.250+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:53.251+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:53.251+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:53.252+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:53.253+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:53.254+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:53.254+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:53.255+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:53.256+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:53.256+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:53.257+0000] {subprocess.py:106} INFO - 25/04/02 09:17:52 ERROR Datastore: Exception thrown creating StoreManager. See the nested exception
[2025-04-02T09:17:53.258+0000] {subprocess.py:106} INFO - Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:53.258+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:53.259+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:53.260+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:53.260+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:53.261+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:53.261+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:53.262+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:53.263+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:53.263+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:53.264+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:53.265+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:53.265+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:53.266+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:53.267+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:53.268+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:53.269+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:53.269+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:53.270+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:53.270+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:53.271+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:53.272+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:53.272+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:53.273+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:53.274+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:53.274+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:53.275+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:53.276+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:53.276+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:53.277+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:53.277+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:53.278+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:53.279+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:53.279+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:53.280+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:53.280+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:53.281+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:53.282+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:53.282+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:53.283+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:53.283+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:53.284+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:53.285+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:53.286+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:53.286+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:53.287+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:53.287+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:53.288+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:53.289+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:53.290+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:53.290+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:53.291+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:53.292+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:53.293+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:53.293+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:53.294+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)
[2025-04-02T09:17:53.295+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:53.295+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:53.296+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:53.297+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:53.297+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:53.298+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:53.298+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:53.299+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:53.300+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:53.301+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:53.301+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:53.302+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:53.304+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:53.305+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:53.306+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:53.307+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:53.308+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:53.308+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:53.309+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:53.310+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:53.311+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:53.312+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:53.312+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:53.313+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:53.314+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:53.315+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:53.316+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:53.317+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:53.317+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:53.319+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:53.319+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:53.320+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:53.321+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:53.322+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:53.323+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:53.323+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:53.324+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:53.325+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:53.325+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:53.326+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:53.327+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:53.328+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:53.328+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:53.329+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:53.329+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:53.330+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:53.331+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:53.332+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:53.333+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:53.334+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:53.335+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:53.335+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:53.336+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:53.337+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:53.338+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:53.339+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:53.340+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:53.340+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:53.341+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:53.342+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:53.343+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:53.343+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:53.344+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:53.345+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:53.345+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:53.346+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:53.347+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:53.348+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:53.348+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:53.349+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:53.350+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:53.351+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:53.352+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:53.353+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:53.354+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:53.354+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:53.355+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:53.356+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:53.357+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:53.357+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:53.358+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:53.358+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:53.359+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:53.360+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:53.360+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:53.361+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:53.362+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:53.363+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:53.363+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:53.364+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:53.365+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:53.365+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:53.366+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:53.367+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:53.368+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:53.369+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:53.369+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:53.370+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:53.371+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:53.372+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:53.373+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:53.374+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:53.374+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:53.375+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:53.376+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:53.376+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:53.377+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:53.378+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:53.378+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:53.379+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:53.379+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:53.380+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:53.381+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:53.381+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:53.382+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:53.383+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:53.384+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:53.385+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:53.386+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:53.386+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:53.387+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:53.388+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:53.389+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:53.389+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:53.390+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:53.391+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:53.391+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:53.392+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:53.392+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:53.393+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:53.394+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:53.394+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:53.395+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:53.396+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:53.396+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:53.397+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:53.397+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:53.398+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:53.399+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:53.399+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:53.400+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:53.401+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:53.401+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:53.402+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:53.403+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:53.404+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:53.404+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:53.405+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:53.406+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:53.406+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:53.407+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:53.407+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:53.408+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:53.408+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:53.409+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:53.410+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:53.410+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:53.411+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:53.412+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:53.412+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:53.413+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:53.413+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:53.414+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:53.415+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:53.415+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:53.416+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:53.417+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:53.418+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:53.418+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:53.419+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:53.419+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:53.420+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:53.421+0000] {subprocess.py:106} INFO - org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:53.422+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:53.422+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:53.423+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:53.423+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:53.424+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:53.425+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:53.425+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:53.426+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:53.426+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:53.427+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:53.428+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:53.428+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:53.429+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:53.430+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:53.430+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:53.431+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:53.432+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:53.432+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:53.433+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:53.434+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:53.435+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:53.436+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:53.436+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:53.437+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:53.438+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:53.438+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:53.439+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:53.440+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:53.440+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:53.441+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:53.442+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:53.442+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:53.443+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:53.444+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:53.444+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:53.445+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:53.446+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:53.446+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:53.447+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:53.447+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:53.448+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:53.448+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:53.449+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:53.450+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:53.451+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:53.452+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:53.452+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:53.453+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:53.454+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:53.454+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:53.455+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:53.456+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:53.456+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:53.457+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:53.457+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)
[2025-04-02T09:17:53.458+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:53.458+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:53.459+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:53.459+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:53.460+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:53.461+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:53.461+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:53.462+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:53.462+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:53.463+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:53.463+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:53.464+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:53.465+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:53.465+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:53.466+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:53.467+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:53.468+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:53.468+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:53.469+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:53.469+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:53.470+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:53.470+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:53.471+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:53.471+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:53.472+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:53.473+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:53.473+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:53.474+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:53.474+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:53.475+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:53.476+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:53.476+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:53.477+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:53.478+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:53.479+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:53.479+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:53.480+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:53.481+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:53.481+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:53.482+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:53.484+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:53.485+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:53.486+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:53.486+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:53.487+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:53.488+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:53.489+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:53.490+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:53.490+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:53.491+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:53.492+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:53.493+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:53.494+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:53.495+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:53.496+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:53.496+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:53.497+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:53.498+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:53.499+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:53.500+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:53.501+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:53.502+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:53.504+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:53.505+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:53.505+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:53.506+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:53.507+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:53.508+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:53.508+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:53.509+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:53.510+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:53.511+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:53.512+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:53.512+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:53.513+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:53.514+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:53.515+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:53.515+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:53.516+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:53.517+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:53.518+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:53.519+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:53.520+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:53.521+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:53.522+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:53.523+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:53.524+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:53.524+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:53.525+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:53.526+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:53.527+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:53.528+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:53.529+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:53.530+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:53.531+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:53.532+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:53.534+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:53.535+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:53.536+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:53.538+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:53.539+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:53.540+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:53.541+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:53.542+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:53.543+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:53.544+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:53.545+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:53.546+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:53.547+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:53.547+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:53.548+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:53.549+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:53.550+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:53.551+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:53.552+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:53.553+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:53.557+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:53.558+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:53.559+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:53.560+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:53.560+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:53.561+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:53.562+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:53.563+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:53.564+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:53.565+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:53.566+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:53.567+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:53.568+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:53.568+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:53.569+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:53.570+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:53.571+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:53.572+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:53.574+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:53.575+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:53.576+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:53.577+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:53.577+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:53.578+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:53.579+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:53.580+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:53.580+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:53.581+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:53.582+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:53.582+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:53.583+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:53.584+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:53.585+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:53.586+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:53.587+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:53.588+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:53.588+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:53.589+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:53.590+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:53.591+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:53.592+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:53.593+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:53.594+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:53.594+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:53.595+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:53.596+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:53.596+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:53.597+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:53.598+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:53.599+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:53.599+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:53.601+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:53.601+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:53.602+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:53.603+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:53.604+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:53.605+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)
[2025-04-02T09:17:53.606+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:53.607+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:53.608+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:53.609+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:53.609+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:53.610+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:53.611+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:53.612+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:53.612+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:53.613+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:53.614+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:53.615+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:53.616+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:53.616+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:53.617+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:53.618+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:53.619+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:53.620+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:53.620+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:53.621+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:53.622+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:53.625+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:53.625+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:53.626+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:53.627+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:53.628+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:53.629+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:53.629+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:53.632+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:53.633+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:53.634+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:53.635+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:53.636+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:53.637+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:53.639+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:53.640+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)
[2025-04-02T09:17:53.641+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:53.642+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:53.642+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:53.643+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:53.644+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:53.645+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:53.646+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:53.646+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:53.647+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:53.648+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:53.649+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:53.649+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:53.651+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:53.652+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:53.653+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:53.654+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:53.655+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:53.656+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:53.656+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:53.657+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:53.658+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:53.659+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:53.660+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:53.661+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:53.661+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:53.662+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:53.663+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:53.664+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:53.665+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:53.666+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:53.667+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:53.668+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:53.669+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:53.670+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:53.671+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:53.672+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:53.673+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:53.674+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:53.675+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:53.676+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:53.677+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:53.678+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:53.679+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:53.679+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:53.680+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:53.681+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:53.683+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:53.684+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:53.686+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:53.687+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:53.688+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:53.689+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:53.689+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:53.690+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:53.691+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:53.692+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:53.693+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:53.694+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:53.695+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:53.696+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:53.697+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:53.697+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:53.698+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:53.699+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:53.700+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:53.701+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:53.702+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:53.703+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:53.704+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:53.705+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:53.706+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:53.707+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:53.710+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:53.711+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:53.711+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:53.712+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:53.713+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:53.714+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:53.714+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:53.715+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:53.716+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:53.717+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:53.718+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:53.719+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:53.720+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:53.721+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:53.722+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:53.723+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:53.724+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:53.725+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:53.726+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:53.727+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:53.728+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:53.729+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:53.733+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:53.734+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:53.736+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:53.737+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:53.738+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:53.739+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:53.740+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:53.742+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:53.743+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:53.744+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:53.745+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:53.746+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:53.748+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:53.749+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:53.750+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:53.752+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:53.753+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:53.754+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:53.755+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:53.756+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:53.757+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:53.758+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:53.758+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:53.759+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:53.760+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:53.761+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:53.762+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:53.762+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:53.763+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:53.764+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:53.765+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:53.766+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:53.766+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:53.769+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:53.770+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:53.772+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:53.774+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:53.775+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:53.777+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:53.778+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:53.780+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:53.781+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:53.782+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:53.783+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:53.787+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:53.789+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:53.790+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:53.791+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:53.792+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:53.793+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:53.795+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:53.796+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:53.797+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:53.798+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:53.799+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:53.800+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:53.802+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:53.803+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:53.804+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:53.807+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:53.808+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:53.809+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:53.810+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:53.812+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:53.813+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:53.814+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:53.815+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:53.816+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:53.817+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:53.819+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:53.820+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:53.821+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:53.822+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:53.823+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:53.824+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:53.825+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:53.827+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:53.828+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:53.829+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:53.830+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)
[2025-04-02T09:17:53.831+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:53.832+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:53.833+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:53.835+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:53.836+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:53.837+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:53.838+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:53.839+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:53.840+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:53.841+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:53.842+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:53.843+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:53.844+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:53.845+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:53.846+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:53.847+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:53.849+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:53.850+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:53.852+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:53.853+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:53.856+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:53.857+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:53.859+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:53.860+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:53.861+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:53.862+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:53.863+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:53.865+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:53.867+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:53.868+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:53.870+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:53.872+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:53.874+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:53.874+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:53.875+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:53.876+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:53.877+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:53.878+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:53.879+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:53.880+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:53.880+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:53.881+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:53.883+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:53.884+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:53.886+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:53.887+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:53.889+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:53.890+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:53.891+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:53.892+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:53.893+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:53.894+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:53.895+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:53.896+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:53.897+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:53.898+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:53.898+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:53.899+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:53.900+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:53.901+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:53.902+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:53.903+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:53.904+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:53.905+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:53.906+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:53.907+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:53.907+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:53.908+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:53.909+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:53.910+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:53.911+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:53.911+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:53.912+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:53.913+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:53.914+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:53.915+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:53.916+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:53.917+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:53.918+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:53.919+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:53.920+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:53.920+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:53.921+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:53.922+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:53.923+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:53.924+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:53.925+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:53.927+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:53.928+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:53.928+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:53.929+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:53.930+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:53.930+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:53.931+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:53.932+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:53.933+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:53.935+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:53.936+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:53.937+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:53.938+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:53.939+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:53.940+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:53.941+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:53.941+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:53.942+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:53.944+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:53.945+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:53.946+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:53.948+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:53.949+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:53.951+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:53.952+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:53.954+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:53.955+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:53.957+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:53.958+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:53.959+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:53.960+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:53.961+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:53.962+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:53.965+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:53.966+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:53.968+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:53.969+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:53.970+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:53.972+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:53.973+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:53.974+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:53.975+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:53.976+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:53.977+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:53.977+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:53.978+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:53.979+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:53.980+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:53.981+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:53.982+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:53.983+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:53.984+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:53.986+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:53.987+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:53.988+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:53.989+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:53.990+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:53.992+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:53.993+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:53.994+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:53.995+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:53.996+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:53.997+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:53.998+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:53.998+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:54.000+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:54.001+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:54.002+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:54.003+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:54.005+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:54.006+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:54.007+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:54.008+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:54.009+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:54.010+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:54.011+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:54.012+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:54.013+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:54.014+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:54.015+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:54.018+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:54.019+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:54.019+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:54.020+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:54.021+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:54.022+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:54.023+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:54.024+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:54.025+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:54.026+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:54.027+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)
[2025-04-02T09:17:54.027+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)
[2025-04-02T09:17:54.028+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:54.029+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:54.030+0000] {subprocess.py:106} INFO - 	... 154 more
[2025-04-02T09:17:54.031+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:54.032+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:54.033+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:54.034+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:54.035+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:54.036+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:54.037+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:54.038+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:54.039+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:54.040+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:54.041+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:54.041+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:54.042+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:54.043+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:54.043+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:54.044+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:54.045+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:54.046+0000] {subprocess.py:106} INFO - 	... 156 more
[2025-04-02T09:17:54.046+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:54.047+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:54.048+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:54.049+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:54.051+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:54.052+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:54.052+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:54.053+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:54.054+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:54.055+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:54.056+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:54.056+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:54.057+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:54.058+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:54.059+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:54.060+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:54.061+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:54.062+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:54.063+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:54.063+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:54.064+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:54.065+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:54.066+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:54.067+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:54.068+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:54.069+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:54.069+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:54.070+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:54.071+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:54.072+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:54.073+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:54.074+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:54.075+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:54.076+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:54.076+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:54.077+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:54.079+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:54.080+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:54.081+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:54.082+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:54.083+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:54.084+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:54.086+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:54.087+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:54.088+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:54.089+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:54.090+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:54.091+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:54.093+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:54.094+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:54.095+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:54.096+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:54.096+0000] {subprocess.py:106} INFO - Nested Throwables StackTrace:
[2025-04-02T09:17:54.097+0000] {subprocess.py:106} INFO - java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:54.098+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:54.099+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:54.100+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:54.101+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:54.102+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:54.103+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:54.104+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:54.105+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:54.106+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:54.107+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:54.107+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:54.109+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:54.109+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:54.110+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:54.111+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:54.112+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:54.113+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:54.114+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:54.115+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:54.119+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:54.120+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:54.121+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:54.122+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:54.123+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:54.124+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:54.125+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:54.126+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:54.126+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:54.127+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:54.128+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:54.129+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:54.129+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:54.130+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:54.131+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:54.132+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:54.133+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:54.133+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:54.134+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:54.135+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:54.136+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:54.137+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:54.138+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:54.139+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:54.140+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:54.141+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:54.142+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:54.143+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:54.144+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:54.145+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:54.146+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:54.147+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:54.147+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:54.148+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:54.149+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:54.150+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)
[2025-04-02T09:17:54.152+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:54.153+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:54.154+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:54.154+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:54.155+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:54.156+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:54.157+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:54.158+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:54.158+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:54.159+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:54.160+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:54.161+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:54.161+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:54.162+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:54.163+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:54.163+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:54.164+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:54.165+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:54.166+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:54.167+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:54.168+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:54.170+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:54.171+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:54.172+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:54.173+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:54.174+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:54.174+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:54.175+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:54.176+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:54.177+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:54.178+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:54.178+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:54.179+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:54.180+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:54.181+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:54.182+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:54.184+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:54.185+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:54.186+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:54.186+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:54.187+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:54.189+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:54.190+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:54.192+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:54.192+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:54.193+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:54.194+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:54.197+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:54.198+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:54.199+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:54.200+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:54.201+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:54.202+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:54.203+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:54.204+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:54.206+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:54.207+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:54.209+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:54.210+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:54.211+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:54.213+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:54.214+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:54.215+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:54.217+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:54.218+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:54.219+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:54.221+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:54.222+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:54.224+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:54.224+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:54.225+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:54.226+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:54.227+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:54.228+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:54.228+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:54.230+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:54.231+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:54.232+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:54.232+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:54.233+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:54.234+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:54.236+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:54.237+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:54.238+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:54.239+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:54.240+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:54.241+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:54.241+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:54.242+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:54.244+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:54.244+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:54.245+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:54.246+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:54.247+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:54.248+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:54.250+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:54.253+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:54.254+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:54.255+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:54.256+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:54.257+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:54.258+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:54.259+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:54.260+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:54.261+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:54.262+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:54.262+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:54.263+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:54.264+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:54.265+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:54.265+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:54.266+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:54.267+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:54.268+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:54.269+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:54.270+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:54.271+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:54.272+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:54.273+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:54.274+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:54.275+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:54.276+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:54.277+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:54.277+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:54.278+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:54.279+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:54.280+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:54.280+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:54.281+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:54.282+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:54.282+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:54.283+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:54.284+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:54.285+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:54.285+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:54.286+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:54.287+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:54.288+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:54.289+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:54.290+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:54.292+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:54.293+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:54.294+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:54.295+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:54.295+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:54.296+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:54.297+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:54.297+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:54.298+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:54.298+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:54.299+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:54.300+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:54.300+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:54.301+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:54.302+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:54.303+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:54.304+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:54.305+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:54.306+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:54.306+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:54.307+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:54.307+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:54.308+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:54.309+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:54.309+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:54.310+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:54.310+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:54.311+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:54.312+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:54.312+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:54.313+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:54.314+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:54.314+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:54.315+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:54.316+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:54.316+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:54.317+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:54.318+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)
[2025-04-02T09:17:54.319+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)
[2025-04-02T09:17:54.319+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:54.320+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:54.321+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:54.322+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:54.323+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:54.323+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:54.324+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:54.326+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:54.327+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:54.329+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:54.330+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:54.330+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:54.331+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:54.332+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:54.333+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:54.333+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:54.334+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:54.336+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:54.337+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:54.337+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:54.338+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:54.339+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:54.339+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:54.340+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:54.341+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:54.341+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:54.342+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:54.343+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:54.343+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:54.344+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:54.344+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:54.345+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:54.346+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:54.346+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:54.347+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:54.348+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:54.348+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:54.349+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)
[2025-04-02T09:17:54.350+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:54.351+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:54.352+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:54.353+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:54.353+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:54.354+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:54.355+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:54.355+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:54.357+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:54.357+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:54.358+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:54.358+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:54.359+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:54.360+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:54.360+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:54.361+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:54.362+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:54.362+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:54.363+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:54.364+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:54.364+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:54.365+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:54.365+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:54.366+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:54.367+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:54.368+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:54.369+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:54.370+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:54.371+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:54.371+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:54.372+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:54.373+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:54.374+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:54.374+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:54.375+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:54.376+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:54.377+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:54.377+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:54.378+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:54.379+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:54.379+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:54.380+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:54.380+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:54.381+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:54.382+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:54.383+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:54.384+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:54.384+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:54.385+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:54.386+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:54.387+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:54.387+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:54.388+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:54.389+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:54.390+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:54.390+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:54.391+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:54.391+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:54.392+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:54.393+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:54.394+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:54.394+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:54.395+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:54.396+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:54.396+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:54.397+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:54.397+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:54.398+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:54.399+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:54.400+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:54.401+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:54.402+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:54.403+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:54.403+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:54.404+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:54.405+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:54.406+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:54.407+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:54.408+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:54.408+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:54.409+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:54.410+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:54.411+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:54.411+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:54.412+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:54.412+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:54.413+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:54.414+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:54.414+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:54.415+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:54.416+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:54.416+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:54.417+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:54.418+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:54.419+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:54.420+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:54.420+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:54.421+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:54.422+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:54.423+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:54.424+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:54.424+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:54.425+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:54.426+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:54.427+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:54.428+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:54.428+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:54.429+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:54.430+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:54.431+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:54.431+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:54.432+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:54.433+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:54.434+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:54.435+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:54.436+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:54.437+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:54.438+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:54.439+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:54.439+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:54.440+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:54.441+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:54.441+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:54.442+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:54.443+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:54.443+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:54.444+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:54.445+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:54.445+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:54.446+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:54.447+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:54.447+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:54.448+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:54.449+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:54.450+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:54.450+0000] {subprocess.py:106} INFO - 	... 156 more
[2025-04-02T09:17:54.452+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:54.452+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:54.453+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:54.454+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:54.454+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:54.455+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:54.456+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:54.457+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:54.458+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:54.458+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:54.459+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:54.460+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:54.460+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:54.461+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:54.462+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:54.463+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:54.463+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:54.464+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:54.465+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:54.465+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:54.466+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:54.467+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:54.468+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:54.469+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:54.469+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:54.470+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:54.471+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:54.472+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:54.473+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:54.473+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:54.474+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:54.474+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:54.475+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:54.476+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:54.477+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:54.477+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:54.478+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:54.479+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:54.479+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:54.480+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:54.481+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:54.481+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:54.482+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:54.483+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:54.484+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:54.485+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:54.486+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:54.486+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:54.487+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:54.488+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:54.489+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:54.490+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:55.440+0000] {subprocess.py:106} INFO - 25/04/02 09:17:55 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors
[2025-04-02T09:17:55.831+0000] {subprocess.py:106} INFO - 25/04/02 09:17:55 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
[2025-04-02T09:17:55.832+0000] {subprocess.py:106} INFO - 25/04/02 09:17:55 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
[2025-04-02T09:17:55.834+0000] {subprocess.py:106} INFO - 25/04/02 09:17:55 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
[2025-04-02T09:17:55.835+0000] {subprocess.py:106} INFO - 25/04/02 09:17:55 INFO ObjectStore: ObjectStore, initialize called
[2025-04-02T09:17:55.855+0000] {subprocess.py:106} INFO - 25/04/02 09:17:55 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
[2025-04-02T09:17:55.857+0000] {subprocess.py:106} INFO - 25/04/02 09:17:55 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
[2025-04-02T09:17:55.946+0000] {subprocess.py:106} INFO - 25/04/02 09:17:55 ERROR Schema: Failed initialising database.
[2025-04-02T09:17:55.947+0000] {subprocess.py:106} INFO - Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:55.948+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:55.949+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:55.950+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:55.952+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:55.952+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:55.953+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:55.954+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:55.955+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:55.956+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:55.957+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:55.958+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:55.959+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:55.960+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:55.961+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:55.962+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:55.962+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:55.963+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:55.964+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:55.965+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:55.966+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:55.967+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:55.968+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:55.969+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:55.970+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:55.971+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:55.972+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:55.973+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:55.974+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:55.975+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:55.976+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:55.977+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:55.978+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:55.979+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:55.979+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:55.980+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:55.981+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:55.982+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:55.983+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:55.984+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:55.986+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:55.987+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:55.988+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:55.989+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:55.990+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:55.991+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:55.992+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:55.993+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:55.994+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:55.995+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:55.996+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:55.997+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:55.997+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:55.999+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:56.000+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:56.001+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:56.002+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:56.003+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:56.004+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:56.005+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:56.006+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:56.007+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:56.007+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:56.008+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:56.009+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:56.010+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:56.011+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:56.012+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:56.013+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:56.014+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:56.014+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:56.015+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:56.016+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:56.018+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:56.020+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:56.021+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:56.022+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:56.023+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:56.025+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:56.026+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:56.026+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:56.027+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:56.028+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:56.029+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:56.030+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:56.031+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:56.032+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:56.034+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:56.035+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:56.035+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:56.036+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:56.037+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:56.038+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:56.038+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:56.039+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:56.040+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:56.041+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:56.041+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:56.042+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:56.043+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:56.044+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:56.045+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:56.045+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:56.046+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:56.047+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:56.048+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:56.048+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:56.049+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:56.050+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:56.051+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:56.052+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:56.052+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:56.053+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:56.054+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:56.055+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:56.056+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:56.057+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:56.057+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:56.058+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:56.059+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:56.060+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:56.060+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:56.061+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:56.062+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:56.062+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:56.063+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:56.064+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:56.064+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:56.066+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:56.068+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:56.069+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:56.072+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:56.073+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:56.074+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:56.076+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:56.077+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:56.078+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:56.079+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:56.080+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:56.082+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:56.084+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:56.085+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:56.086+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:56.087+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:56.087+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:56.088+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:56.090+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:56.090+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:56.091+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:56.092+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:56.093+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:56.094+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:56.095+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:56.096+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:56.097+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:56.098+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:56.098+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:56.099+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:56.100+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:56.101+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:56.102+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:56.103+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:56.103+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:56.104+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:56.105+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:56.106+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:56.107+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:56.107+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:56.108+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:56.109+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:56.110+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:56.110+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:56.111+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:56.112+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:56.113+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:56.114+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:56.114+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:56.115+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:56.116+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:56.118+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:56.118+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:56.119+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:56.120+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:56.121+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:56.123+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:56.124+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:56.124+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:56.125+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:56.126+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:56.127+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:56.128+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:56.128+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:56.129+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:56.130+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:56.131+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:56.131+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:56.132+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:56.133+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:56.134+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:56.135+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:56.136+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:56.137+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:56.137+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:56.142+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:56.142+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:56.143+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:56.144+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:56.145+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:56.146+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:56.147+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:56.147+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:56.148+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:56.149+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:56.150+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:56.151+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:56.152+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:56.153+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:56.154+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:56.155+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:56.156+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:56.157+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:56.157+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:56.158+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:56.159+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:56.160+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:56.160+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:56.161+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:56.162+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:56.163+0000] {subprocess.py:106} INFO - org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:56.163+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:56.164+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:56.165+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:56.166+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:56.167+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:56.168+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:56.169+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:56.170+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:56.170+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:56.171+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:56.172+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:56.173+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:56.174+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:56.175+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:56.176+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:56.177+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:56.177+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:56.178+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:56.179+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:56.180+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:56.180+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:56.181+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:56.182+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:56.182+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:56.183+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:56.184+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:56.185+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:56.186+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:56.187+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:56.188+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:56.188+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:56.189+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:56.190+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:56.191+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:56.192+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:56.193+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:56.194+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:56.195+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:56.196+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:56.197+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:56.199+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:56.200+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:56.201+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:56.202+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:56.203+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:56.203+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:56.204+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:56.205+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:56.206+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:56.207+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:56.208+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:56.209+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:56.210+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:56.210+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:56.211+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:56.212+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:56.213+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:56.214+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:56.214+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:56.215+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:56.216+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:56.218+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:56.219+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:56.220+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:56.221+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:56.222+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:56.223+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:56.224+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:56.225+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:56.226+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:56.226+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:56.227+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:56.228+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:56.229+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:56.230+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:56.231+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:56.232+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:56.233+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:56.234+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:56.235+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:56.236+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:56.238+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:56.239+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:56.240+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:56.241+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:56.242+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:56.243+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:56.243+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:56.244+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:56.245+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:56.246+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:56.247+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:56.249+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:56.250+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:56.251+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:56.252+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:56.253+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:56.254+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:56.256+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:56.257+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:56.257+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:56.258+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:56.259+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:56.260+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:56.261+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:56.261+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:56.262+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:56.263+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:56.264+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:56.264+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:56.265+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:56.266+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:56.266+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:56.267+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:56.268+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:56.269+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:56.270+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:56.271+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:56.272+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:56.273+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:56.273+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:56.274+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:56.276+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:56.276+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:56.277+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:56.278+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:56.279+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:56.280+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:56.280+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:56.281+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:56.282+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:56.283+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:56.284+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:56.285+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:56.286+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:56.287+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:56.288+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:56.289+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:56.290+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:56.291+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:56.292+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:56.293+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:56.294+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:56.295+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:56.296+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:56.298+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:56.299+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:56.300+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:56.301+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:56.302+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:56.303+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:56.303+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:56.304+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:56.305+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:56.306+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:56.307+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:56.308+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:56.308+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:56.309+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:56.310+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:56.311+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:56.311+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:56.312+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:56.313+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:56.314+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:56.315+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:56.315+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:56.316+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:56.317+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:56.318+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:56.319+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:56.320+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:56.321+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:56.322+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:56.323+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:56.324+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:56.324+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:56.328+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:56.331+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:56.332+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:56.333+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:56.334+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:56.335+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:56.336+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:56.337+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:56.338+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:56.339+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:56.340+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:56.343+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:56.343+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:56.344+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:56.345+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:56.346+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:56.346+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:56.347+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:56.348+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:56.349+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:56.350+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:56.351+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:56.352+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:56.353+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:56.354+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:56.355+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:56.356+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:56.357+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:56.358+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:56.359+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:56.360+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:56.362+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:56.364+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:56.365+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:56.367+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:56.368+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:56.370+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:56.371+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:56.372+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:56.373+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:56.374+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:56.375+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:56.376+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:56.377+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:56.378+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:56.379+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:56.380+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:56.381+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:56.382+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:56.383+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:56.384+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)
[2025-04-02T09:17:56.385+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:56.386+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:56.388+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:56.389+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:56.390+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:56.391+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:56.392+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:56.393+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:56.394+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:56.395+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:56.396+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:56.397+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:56.398+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:56.399+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:56.400+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:56.402+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:56.403+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:56.403+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:56.404+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:56.405+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:56.407+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:56.408+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:56.409+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:56.410+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:56.411+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:56.413+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:56.414+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:56.415+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:56.416+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:56.417+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:56.419+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:56.420+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:56.421+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:56.422+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:56.423+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:56.424+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:56.424+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:56.426+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:56.427+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:56.428+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:56.429+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:56.430+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:56.431+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:56.431+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:56.432+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:56.433+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:56.435+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:56.436+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:56.437+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:56.439+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:56.440+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:56.440+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:56.441+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:56.442+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:56.443+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:56.444+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:56.445+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:56.446+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:56.447+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:56.448+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:56.449+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:56.450+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:56.451+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:56.452+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:56.453+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:56.454+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:56.455+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:56.456+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:56.457+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:56.458+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:56.459+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:56.459+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:56.460+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:56.461+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:56.462+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:56.463+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:56.464+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:56.464+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:56.465+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:56.466+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:56.467+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:56.468+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:56.469+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:56.470+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:56.471+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:56.472+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:56.473+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:56.474+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:56.474+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:56.475+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:56.476+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:56.477+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:56.478+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:56.479+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:56.480+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:56.481+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:56.482+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:56.483+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:56.483+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:56.484+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:56.486+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:56.487+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:56.488+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:56.489+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:56.490+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:56.491+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:56.492+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:56.493+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:56.494+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:56.494+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:56.495+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:56.497+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:56.498+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:56.498+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:56.500+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:56.501+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:56.502+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:56.503+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:56.503+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:56.504+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:56.505+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:56.506+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:56.507+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:56.508+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:56.508+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:56.509+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:56.510+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:56.511+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:56.511+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:56.512+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:56.513+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:56.514+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:56.514+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:56.515+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:56.516+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:56.517+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:56.518+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:56.519+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:56.520+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:56.521+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:56.522+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:56.523+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:56.524+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:56.525+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:56.526+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:56.526+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:56.527+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:56.528+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:56.529+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:56.530+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:56.530+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:56.531+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:56.532+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:56.533+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:56.534+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:56.535+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:56.535+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:56.536+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:56.537+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:56.538+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:56.539+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:56.540+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:56.541+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:56.542+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:56.542+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:56.543+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:56.544+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:56.545+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:56.546+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:56.547+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:56.548+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:56.548+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:56.549+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:56.550+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:56.551+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:56.552+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:56.553+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:56.554+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:56.555+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:56.556+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:56.557+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:56.558+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:56.559+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:56.560+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:56.560+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:56.562+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:56.563+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:56.564+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:56.564+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:56.565+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:56.567+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:56.568+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:56.569+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:56.570+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:56.570+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:56.572+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:56.572+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:56.573+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:56.574+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:56.575+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:56.576+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:56.577+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:56.578+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:56.579+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:56.579+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:56.580+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:56.581+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:56.582+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:56.583+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:56.584+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:56.585+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:56.586+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:56.587+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:56.588+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:56.589+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:56.590+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:56.590+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:56.591+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:56.592+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:56.593+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:56.594+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:56.595+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:56.595+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:56.596+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:56.597+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:56.597+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:56.598+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:56.599+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:56.600+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:56.602+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:56.603+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:56.603+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:56.604+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:56.605+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:56.606+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:56.607+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:56.608+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:56.608+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:56.609+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:56.610+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:56.611+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:56.612+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:56.612+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:56.613+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:56.614+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:56.615+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:56.615+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:56.616+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:56.618+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:56.619+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:56.619+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:56.621+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:56.622+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:56.623+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:56.624+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:56.624+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:56.625+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:56.626+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:56.627+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:56.628+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:56.628+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:56.629+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:56.630+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:56.631+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:56.631+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:56.632+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:56.633+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:56.634+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:56.635+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:56.636+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:56.636+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:56.637+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:56.638+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:56.639+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:56.640+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:56.641+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:56.642+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:56.643+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:56.644+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:56.644+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:56.645+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:56.646+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:56.647+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:56.648+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:56.648+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:56.649+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:56.650+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:56.651+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:56.652+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:56.653+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:56.654+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:56.655+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:56.656+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:56.657+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:56.658+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:56.658+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:56.659+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:56.660+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:56.661+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:56.661+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:56.662+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:56.663+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:56.664+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:56.664+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:56.665+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:56.666+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:56.667+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:56.668+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:56.669+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:56.670+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:56.670+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:56.671+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:56.672+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:56.673+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:56.674+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:56.674+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:56.675+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:56.676+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:56.677+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:56.678+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:56.678+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:56.679+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:56.680+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:56.681+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:56.681+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:56.682+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:56.683+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:56.684+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:56.686+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:56.687+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:56.688+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:56.690+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:56.691+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:56.692+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:56.692+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:56.693+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:56.694+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:56.695+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:56.696+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:56.697+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:56.698+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:56.698+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:56.699+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:56.701+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:56.702+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:56.703+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:56.704+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:56.705+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:56.706+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:56.707+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:56.709+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:56.710+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:56.711+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:56.711+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:56.712+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:56.713+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:56.714+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:56.715+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:56.716+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:56.718+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:56.719+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:56.720+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:56.721+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:56.722+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:56.722+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:56.723+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:56.724+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:56.725+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:56.726+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:56.727+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:56.727+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:56.728+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:56.729+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:56.730+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:56.730+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:56.731+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:56.733+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:56.734+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:56.735+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:56.736+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:56.736+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:56.737+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:56.738+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:56.739+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:56.740+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:56.741+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:56.741+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:56.742+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)
[2025-04-02T09:17:56.743+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)
[2025-04-02T09:17:56.744+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:56.745+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:56.746+0000] {subprocess.py:106} INFO - 	... 154 more
[2025-04-02T09:17:56.746+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:56.747+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:56.748+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:56.749+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:56.750+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:56.751+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:56.752+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:56.753+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:56.753+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:56.754+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:56.755+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:56.756+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:56.757+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:56.758+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:56.759+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:56.760+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:56.761+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:56.762+0000] {subprocess.py:106} INFO - 	... 156 more
[2025-04-02T09:17:56.763+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:56.763+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:56.764+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:56.765+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:56.766+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:56.767+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:56.768+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:56.768+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:56.769+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:56.770+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:56.771+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:56.774+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:56.774+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:56.775+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:56.776+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:56.777+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:56.778+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:56.779+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:56.780+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:56.781+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:56.781+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:56.782+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:56.783+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:56.784+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:56.785+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:56.786+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:56.787+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:56.787+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:56.788+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:56.789+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:56.790+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:56.791+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:56.791+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:56.792+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:56.793+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:56.793+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:56.794+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:56.795+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:56.795+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:56.796+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:56.797+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:56.798+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:56.798+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:56.799+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:56.800+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:56.801+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:56.802+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:56.803+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:56.804+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:56.805+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:56.806+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:56.807+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:56.808+0000] {subprocess.py:106} INFO - Nested Throwables StackTrace:
[2025-04-02T09:17:56.809+0000] {subprocess.py:106} INFO - java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:56.809+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:56.810+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:56.811+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:56.812+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:56.813+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:56.813+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:56.814+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:56.815+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:56.816+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:56.817+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:56.818+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:56.818+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:56.819+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:56.820+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:56.822+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:56.823+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:56.824+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:56.825+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:56.825+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:56.826+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:56.827+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:56.828+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:56.829+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:56.830+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:56.831+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:56.832+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:56.833+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:56.834+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:56.835+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:56.836+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:56.837+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:56.838+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:56.839+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:56.840+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:56.842+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:56.843+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:56.844+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:56.845+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:56.846+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:56.847+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:56.848+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:56.849+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:56.850+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:56.851+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:56.852+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:56.853+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:56.854+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:56.856+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:56.857+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:56.858+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:56.859+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:56.860+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:56.862+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:56.863+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:56.864+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:56.866+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:56.868+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:56.869+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:56.870+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:56.871+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:56.872+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:56.873+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:56.875+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:56.876+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:56.877+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:56.878+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:56.879+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:56.880+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:56.881+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:56.881+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:56.883+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:56.884+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:56.885+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:56.887+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:56.889+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:56.890+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:56.891+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:56.892+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:56.893+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:56.895+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:56.897+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:56.898+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:56.900+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:56.901+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:56.903+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:56.904+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:56.906+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:56.907+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:56.908+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:56.909+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:56.910+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:56.911+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:56.913+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:56.914+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:56.915+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:56.917+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:56.918+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:56.919+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:56.920+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:56.921+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:56.922+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:56.924+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:56.925+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:56.927+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:56.928+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:56.929+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:56.930+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:56.931+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:56.932+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:56.932+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:56.933+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:56.934+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:56.935+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:56.936+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:56.937+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:56.939+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:56.941+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:56.943+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:56.944+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:56.945+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:56.946+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:56.947+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:56.949+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:56.952+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:56.953+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:56.955+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:56.957+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:56.958+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:56.959+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:56.960+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:56.962+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:56.963+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:56.964+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:56.966+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:56.968+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:56.969+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:56.970+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:56.972+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:56.973+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:56.974+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:56.975+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:56.976+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:56.977+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:56.978+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:56.979+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:56.981+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:56.982+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:56.983+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:56.984+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:56.986+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:56.987+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:56.989+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:56.991+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:56.992+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:56.993+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:56.994+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:56.996+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:56.997+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:56.997+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:56.999+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:57.000+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:57.001+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:57.002+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:57.003+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:57.004+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:57.005+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:57.007+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:57.009+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:57.010+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:57.011+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:57.013+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:57.014+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:57.015+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:57.016+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:57.017+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:57.019+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:57.020+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:57.021+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:57.023+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:57.024+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:57.025+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:57.026+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:57.027+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:57.028+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:57.029+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:57.030+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:57.031+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:57.033+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:57.035+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:57.036+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:57.037+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:57.039+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:57.040+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:57.042+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:57.043+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:57.045+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:57.046+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:57.048+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:57.049+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:57.050+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:57.052+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:57.053+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:57.055+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:57.056+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:57.057+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:57.058+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:57.059+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:57.060+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:57.061+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:57.063+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:57.064+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:57.065+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:57.066+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:57.068+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:57.069+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:57.070+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:57.071+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:57.072+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:57.074+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:57.078+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:57.079+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:57.080+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:57.081+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:57.082+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:57.084+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:57.085+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:57.086+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:57.088+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:57.089+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:57.090+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:57.091+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:57.092+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:57.093+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)
[2025-04-02T09:17:57.094+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)
[2025-04-02T09:17:57.095+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:57.096+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:57.097+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:57.097+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:57.098+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:57.100+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:57.101+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:57.103+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:57.104+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:57.105+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:57.106+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:57.108+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:57.109+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:57.110+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:57.111+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:57.112+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:57.114+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:57.115+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:57.116+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:57.118+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:57.119+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:57.120+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:57.121+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:57.123+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:57.124+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:57.125+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:57.126+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:57.128+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:57.129+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:57.130+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:57.131+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:57.134+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:57.135+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:57.143+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:57.144+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:57.146+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:57.148+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:57.149+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:57.150+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:57.152+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:57.153+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:57.154+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:57.155+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:57.157+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:57.158+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:57.158+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:57.159+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:57.160+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:57.161+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:57.161+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:57.162+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:57.163+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:57.164+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:57.165+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:57.165+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:57.166+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:57.168+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:57.169+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:57.170+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:57.171+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:57.172+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:57.173+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:57.174+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:57.175+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:57.175+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:57.176+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:57.177+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:57.178+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:57.179+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:57.180+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:57.180+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:57.181+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:57.182+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:57.183+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:57.184+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:57.185+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:57.186+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:57.187+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:57.187+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:57.188+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:57.189+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:57.190+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:57.191+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:57.192+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:57.193+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:57.194+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:57.195+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:57.195+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:57.196+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:57.197+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:57.198+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:57.199+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:57.200+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:57.201+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:57.202+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:57.203+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:57.204+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:57.205+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:57.206+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:57.207+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:57.208+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:57.209+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:57.210+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:57.211+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:57.211+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:57.212+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:57.213+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:57.214+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:57.214+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:57.216+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:57.217+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:57.218+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:57.218+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:57.219+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:57.220+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:57.221+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:57.222+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:57.223+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:57.223+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:57.224+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:57.225+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:57.225+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:57.226+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:57.227+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:57.228+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:57.229+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:57.229+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:57.230+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:57.231+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:57.232+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:57.232+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:57.233+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:57.234+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:57.235+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:57.236+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:57.237+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:57.238+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:57.239+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:57.240+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:57.240+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:57.241+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:57.242+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:57.243+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:57.244+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:57.245+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:57.246+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:57.247+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:57.248+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:57.249+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:57.251+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:57.252+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:57.253+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:57.254+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:57.255+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:57.256+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:57.257+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:57.258+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:57.259+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:57.259+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:57.260+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:57.261+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:57.262+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:57.263+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:57.264+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:57.264+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:57.265+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:57.266+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:57.267+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:57.268+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:57.269+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:57.270+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:57.270+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:57.271+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:57.272+0000] {subprocess.py:106} INFO - 	... 156 more
[2025-04-02T09:17:57.273+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:57.274+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:57.275+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:57.276+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:57.276+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:57.277+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:57.278+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:57.279+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:57.279+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:57.280+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:57.281+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:57.281+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:57.283+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:57.284+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:57.284+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:57.285+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:57.286+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:57.287+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:57.288+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:57.289+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:57.290+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:57.291+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:57.291+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:57.292+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:57.293+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:57.294+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:57.295+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:57.296+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:57.297+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:57.298+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:57.298+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:57.299+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:57.301+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:57.302+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:57.302+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:57.304+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:57.305+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:57.306+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:57.307+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:57.307+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:57.308+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:57.309+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:57.310+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:57.311+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:57.312+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:57.313+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:57.314+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:57.315+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:57.316+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:57.318+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:57.319+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:57.320+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:57.321+0000] {subprocess.py:106} INFO - 25/04/02 09:17:56 ERROR Datastore: Exception thrown creating StoreManager. See the nested exception
[2025-04-02T09:17:57.322+0000] {subprocess.py:106} INFO - Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:57.323+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:57.325+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:57.326+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:57.327+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:57.329+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:57.329+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:57.330+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:57.332+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:57.333+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:57.334+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:57.335+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:57.336+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:57.337+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:57.338+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:57.339+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:57.340+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:57.341+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:57.342+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:57.342+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:57.343+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:57.344+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:57.346+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:57.347+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:57.348+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:57.349+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:57.350+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:57.351+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:57.352+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:57.353+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:57.354+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:57.355+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:57.356+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:57.357+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:57.358+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:57.359+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:57.360+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:57.361+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:57.362+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:57.363+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:57.364+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:57.365+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:57.366+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:57.367+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:57.368+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:57.369+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:57.370+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:57.371+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:57.373+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:57.373+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:57.375+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:57.377+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:57.378+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:57.379+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:57.383+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:57.384+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:57.387+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:57.388+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:57.389+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:57.390+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:57.391+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:57.392+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:57.393+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:57.394+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:57.395+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:57.396+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:57.398+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:57.399+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:57.400+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:57.401+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:57.404+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:57.405+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:57.406+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:57.407+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:57.407+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:57.408+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:57.409+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:57.410+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:57.411+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:57.412+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:57.413+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:57.414+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:57.415+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:57.416+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:57.416+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:57.418+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:57.419+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:57.420+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:57.421+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:57.422+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:57.423+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:57.424+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:57.425+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:57.426+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:57.427+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:57.428+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:57.428+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:57.429+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:57.430+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:57.431+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:57.432+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:57.433+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:57.434+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:57.435+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:57.436+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:57.437+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:57.439+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:57.440+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:57.440+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:57.441+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:57.442+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:57.443+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:57.444+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:57.444+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:57.445+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:57.446+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:57.447+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:57.448+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:57.449+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:57.450+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:57.451+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:57.452+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:57.453+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:57.454+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:57.455+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:57.455+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:57.459+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:57.459+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:57.460+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:57.461+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:57.462+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:57.462+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:57.463+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:57.464+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:57.465+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:57.466+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:57.467+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:57.468+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:57.469+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:57.469+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:57.470+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:57.471+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:57.472+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:57.473+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:57.474+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:57.475+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:57.476+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:57.477+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:57.477+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:57.478+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:57.479+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:57.480+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:57.481+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:57.484+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:57.485+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:57.486+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:57.487+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:57.488+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:57.490+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:57.491+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:57.492+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:57.493+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:57.494+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:57.494+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:57.497+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:57.498+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:57.499+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:57.499+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:57.500+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:57.502+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:57.502+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:57.503+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:57.504+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:57.505+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:57.506+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:57.509+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:57.510+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:57.511+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:57.512+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:57.513+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:57.514+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:57.516+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:57.516+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:57.517+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:57.518+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:57.519+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:57.520+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:57.522+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:57.523+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:57.524+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:57.524+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:57.525+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:57.526+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:57.527+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:57.528+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:57.529+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:57.530+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:57.531+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:57.532+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:57.533+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:57.534+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:57.535+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:57.536+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:57.537+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:57.538+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:57.539+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:57.540+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:57.541+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:57.542+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:57.543+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:57.544+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:57.545+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:57.546+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:57.547+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:57.548+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:57.549+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:57.550+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:57.551+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:57.552+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:57.553+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:57.554+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:57.555+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:57.556+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:57.557+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:57.558+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:57.559+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:57.560+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:57.561+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:57.561+0000] {subprocess.py:106} INFO - org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:57.562+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:57.563+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:57.564+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:57.565+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:57.566+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:57.567+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:57.568+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:57.568+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:57.569+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:57.570+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:57.571+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:57.571+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:57.572+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:57.573+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:57.574+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:57.575+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:57.575+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:57.576+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:57.577+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:57.577+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:57.578+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:57.579+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:57.579+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:57.581+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:57.583+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:57.584+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:57.586+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:57.587+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:57.588+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:57.589+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:57.590+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:57.591+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:57.592+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:57.593+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:57.594+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:57.595+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:57.596+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:57.597+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:57.598+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:57.599+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:57.600+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:57.601+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:57.602+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:57.603+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:57.604+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:57.605+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:57.606+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:57.608+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:57.609+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:57.609+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:57.610+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:57.611+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:57.612+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:57.613+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:57.614+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:57.615+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:57.616+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:57.617+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:57.618+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:57.619+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:57.620+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:57.621+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:57.622+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:57.623+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:57.624+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:57.625+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:57.626+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:57.627+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:57.628+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:57.628+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:57.629+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:57.630+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:57.631+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:57.632+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:57.633+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:57.635+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:57.636+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:57.637+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:57.638+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:57.639+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:57.640+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:57.641+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:57.642+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:57.643+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:57.644+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:57.645+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:57.646+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:57.646+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:57.647+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:57.648+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:57.650+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:57.651+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:57.652+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:57.653+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:57.654+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:57.655+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:57.656+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:57.656+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:57.657+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:57.658+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:57.659+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:57.660+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:57.660+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:57.661+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:57.662+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:57.663+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:57.664+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:57.665+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:57.665+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:57.667+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:57.667+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:57.668+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:57.669+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:57.670+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:57.671+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:57.672+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:57.673+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:57.674+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:57.674+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:57.675+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:57.676+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:57.677+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:57.677+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:57.678+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:57.679+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:57.679+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:57.680+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:57.681+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:57.682+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:57.683+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:57.684+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:57.685+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:57.686+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:57.687+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:57.689+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:57.690+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:57.690+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:57.691+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:57.692+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:57.693+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:57.694+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:57.695+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:57.696+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:57.697+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:57.697+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:57.698+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:57.699+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:57.700+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:57.701+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:57.702+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:57.703+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:57.703+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:57.704+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:57.705+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:57.706+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:57.707+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:57.708+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:57.709+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:57.710+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:57.711+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:57.712+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:57.712+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:57.713+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:57.714+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:57.715+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:57.715+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:57.716+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:57.717+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:57.718+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:57.719+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:57.720+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:57.721+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:57.722+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:57.723+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:57.724+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:57.725+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:57.726+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:57.727+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:57.728+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:57.728+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:57.729+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:57.730+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:57.731+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:57.732+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:57.733+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:57.734+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:57.735+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:57.736+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:57.737+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:57.738+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:57.739+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:57.740+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:57.741+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:57.742+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:57.743+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:57.744+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:57.745+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:57.745+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:57.746+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:57.747+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:57.748+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:57.749+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:57.750+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:57.751+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:57.752+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:57.753+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:57.754+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:57.755+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:57.756+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:57.756+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:57.757+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:57.758+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:57.759+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:57.760+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:57.760+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:57.761+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:57.762+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:57.763+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:57.764+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:57.765+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:57.766+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:57.767+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:57.767+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:57.768+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:57.769+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:57.770+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:57.771+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:57.771+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)
[2025-04-02T09:17:57.772+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:57.773+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:57.774+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:57.775+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:57.776+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:57.776+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:57.777+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:57.778+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:57.779+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:57.780+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:57.780+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:57.781+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:57.782+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:57.783+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:57.784+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:57.785+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:57.786+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:57.787+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:57.787+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:57.788+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:57.789+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:57.790+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:57.791+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:57.792+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:57.793+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:57.794+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:57.794+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:57.795+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:57.796+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:57.797+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:57.798+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:57.799+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:57.800+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:57.801+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:57.802+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:57.803+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:57.803+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:57.804+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:57.805+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:57.806+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:57.807+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:57.808+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:57.809+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:57.810+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:57.811+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:57.812+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:57.813+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:57.814+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:57.815+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:57.816+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:57.817+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:57.818+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:57.819+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:57.820+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:57.820+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:57.821+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:57.822+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:57.823+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:57.824+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:57.825+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:57.825+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:57.826+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:57.827+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:57.828+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:57.829+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:57.829+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:57.830+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:57.831+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:57.832+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:57.833+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:57.834+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:57.835+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:57.836+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:57.837+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:57.838+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:57.839+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:57.840+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:57.841+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:57.843+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:57.844+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:57.845+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:57.845+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:57.846+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:57.847+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:57.848+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:57.848+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:57.849+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:57.850+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:57.851+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:57.853+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:57.853+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:57.854+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:57.855+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:57.856+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:57.857+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:57.857+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:57.858+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:57.859+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:57.860+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:57.861+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:57.862+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:57.863+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:57.863+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:57.864+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:57.865+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:57.866+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:57.867+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:57.868+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:57.869+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:57.870+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:57.870+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:57.871+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:57.872+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:57.873+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:57.874+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:57.875+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:57.876+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:57.877+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:57.878+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:57.878+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:57.879+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:57.880+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:57.880+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:57.881+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:57.883+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:57.884+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:57.885+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:57.886+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:57.887+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:57.888+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:57.889+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:57.890+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:57.890+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:57.891+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:57.892+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:57.893+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:57.894+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:57.895+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:57.895+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:57.896+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:57.897+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:57.898+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:57.898+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:57.899+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:57.901+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:57.901+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:57.902+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:57.903+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:57.904+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:57.905+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:57.906+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:57.907+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:57.907+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:57.908+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:57.909+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:57.910+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:57.911+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:57.911+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:57.912+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:57.913+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:57.914+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:57.915+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:57.916+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:57.917+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:57.918+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:57.919+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:57.920+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:57.921+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:57.922+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:57.922+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:57.923+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:57.924+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:57.925+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:57.926+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:57.926+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:57.927+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:57.928+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:57.929+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:57.930+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:57.930+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:57.931+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:57.932+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:57.933+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:57.934+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:57.935+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:57.936+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:57.937+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:57.937+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:57.938+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:57.939+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:57.940+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:57.941+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:57.942+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:57.943+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:57.944+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:57.944+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:57.945+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:57.946+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:57.947+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:57.947+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:57.948+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:57.949+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:57.950+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:57.951+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:57.952+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:57.953+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:57.954+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:57.955+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:57.956+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:57.957+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:57.957+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:57.958+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:57.959+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:57.960+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:57.961+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:57.962+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:57.963+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:57.964+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:57.966+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:57.968+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:57.969+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:57.970+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:57.971+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:57.972+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:57.973+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:57.974+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:57.976+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:57.976+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:57.977+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:57.978+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:57.979+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:57.980+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:57.981+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:57.982+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:57.983+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:57.984+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:57.985+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:57.987+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:57.988+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:57.989+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:57.990+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:57.991+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:57.993+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:57.994+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:57.995+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:57.996+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:57.997+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:57.998+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:57.999+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:58.000+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:58.001+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:58.003+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:58.004+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:58.005+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:58.006+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:58.007+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:58.008+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:58.009+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:58.010+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:58.011+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:58.013+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:58.015+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:58.020+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:58.023+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:58.025+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:58.026+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:58.028+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:58.029+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:58.031+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:58.032+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:58.034+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:58.035+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:58.037+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:58.039+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:58.040+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:58.042+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:58.043+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:58.044+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:58.046+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:58.047+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:58.048+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:58.050+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:58.053+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:58.054+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:58.055+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:58.057+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:58.058+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:58.059+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:58.061+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:58.062+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:58.063+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:58.065+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:58.066+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:58.068+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:58.070+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:58.071+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:58.073+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:58.075+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:58.076+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:58.078+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:58.079+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:58.080+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:58.082+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:58.084+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:58.086+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:58.091+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:58.092+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:58.093+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:58.094+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:58.095+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:58.097+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:58.098+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:58.100+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:58.101+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:58.102+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:58.103+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:58.104+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:58.105+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:58.106+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:58.107+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:58.108+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:58.110+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:58.111+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:58.113+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:58.114+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:58.115+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:58.116+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:58.118+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:58.120+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:58.123+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:58.126+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:58.128+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:58.130+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:58.131+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:58.132+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:58.133+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:58.134+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:58.136+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:58.138+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:58.140+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:58.141+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:58.142+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:58.143+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:58.144+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:58.146+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:58.147+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:58.149+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:58.150+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:58.152+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:58.153+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:58.154+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:58.156+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:58.157+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:58.159+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:58.160+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:58.161+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:58.162+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:58.163+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:58.165+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:58.166+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:58.167+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:58.168+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:58.169+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:58.170+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:58.171+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:58.172+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:58.173+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:58.174+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:58.175+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:58.178+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:58.179+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:58.180+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:58.181+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:58.182+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:58.184+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:58.185+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:58.186+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:58.187+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:58.188+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:58.189+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:58.190+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:58.191+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:58.191+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:58.192+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:58.193+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:58.194+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:58.195+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:58.196+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)
[2025-04-02T09:17:58.197+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)
[2025-04-02T09:17:58.198+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:58.201+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:58.202+0000] {subprocess.py:106} INFO - 	... 154 more
[2025-04-02T09:17:58.203+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:58.205+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:58.206+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:58.207+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:58.208+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:58.209+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:58.210+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:58.211+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:58.212+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:58.213+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:58.214+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:58.215+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:58.216+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:58.217+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:58.219+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:58.220+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:58.222+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:58.223+0000] {subprocess.py:106} INFO - 	... 156 more
[2025-04-02T09:17:58.224+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:58.225+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:58.226+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:58.227+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:58.228+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:58.229+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:58.230+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:58.231+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:58.232+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:58.233+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:58.234+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:58.235+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:58.236+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:58.237+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:58.238+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:58.239+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:58.240+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:58.241+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:58.242+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:58.244+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:58.248+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:58.248+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:58.249+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:58.250+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:58.251+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:58.252+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:58.253+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:58.254+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:58.256+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:58.257+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:58.258+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:58.259+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:58.259+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:58.260+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:58.261+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:58.262+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:58.263+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:58.264+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:58.265+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:58.266+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:58.267+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:58.268+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:58.269+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:58.270+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:58.272+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:58.273+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:58.273+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:58.274+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:58.275+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:58.276+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:58.277+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:58.278+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:58.279+0000] {subprocess.py:106} INFO - Nested Throwables StackTrace:
[2025-04-02T09:17:58.280+0000] {subprocess.py:106} INFO - java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:58.281+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:58.282+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:58.283+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:58.284+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:58.285+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:58.286+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:58.287+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:58.288+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:58.290+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:58.291+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:58.292+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:58.293+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:58.294+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:58.295+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:58.296+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:58.297+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:58.297+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:58.298+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:58.299+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:58.300+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:58.301+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:58.302+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:58.303+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:58.304+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:58.305+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:58.306+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:58.307+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:58.308+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:58.309+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:58.310+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:58.311+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:58.312+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:58.313+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:58.313+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:58.314+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:58.315+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:58.316+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:58.317+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:58.318+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:58.319+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:58.320+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:58.321+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:58.322+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:58.323+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:58.324+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:58.325+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:58.326+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:58.327+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:58.327+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:58.328+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:58.329+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:58.330+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:58.331+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:58.331+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:58.332+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:58.333+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:58.335+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:58.336+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:58.337+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:58.338+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:58.339+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:58.340+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:58.341+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:58.342+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:58.343+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:58.344+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:58.345+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:58.346+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:58.346+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:58.347+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:58.348+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:58.350+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:58.351+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:58.352+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:58.353+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:58.355+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:58.356+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:58.357+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:58.358+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:58.359+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:58.360+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:58.362+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:58.363+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:58.365+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:58.367+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:58.368+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:58.371+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:58.372+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:58.374+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:58.376+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:58.377+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:58.378+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:58.379+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:58.380+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:58.381+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:58.383+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:58.384+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:58.385+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:58.387+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:58.389+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:58.390+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:58.393+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:58.394+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:58.396+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:58.398+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:58.399+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:58.400+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:58.401+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:58.402+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:58.404+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:58.406+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:58.408+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:58.411+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:58.412+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:58.414+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:58.415+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:58.421+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:58.423+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:58.424+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:58.426+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:58.428+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:58.429+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:58.430+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:58.431+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:58.433+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:58.434+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:58.435+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:58.436+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:58.438+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:58.439+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:58.440+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:58.444+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:58.445+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:58.447+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:58.448+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:58.449+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:58.451+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:58.452+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:58.454+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:58.455+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:58.456+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:58.457+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:58.459+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:58.460+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:58.461+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:58.462+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:58.463+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:58.465+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:58.466+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:58.468+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:58.470+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:58.471+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:58.472+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:58.473+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:58.474+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:58.475+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:58.477+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:58.478+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:58.479+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:58.480+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:58.482+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:58.483+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:58.486+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:58.488+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:58.490+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:58.491+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:58.492+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:58.494+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:58.495+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:58.496+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:58.497+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:58.498+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:58.499+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:58.501+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:58.503+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:58.505+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:58.506+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:58.507+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:58.509+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:58.510+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:58.512+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:58.513+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:58.515+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:58.518+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:58.521+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:58.524+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:58.527+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:58.530+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:58.536+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:58.540+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:58.543+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:58.544+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:58.546+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:58.548+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:58.549+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:58.551+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:58.554+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:58.556+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:58.557+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:58.559+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:58.560+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:58.561+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:58.562+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:58.563+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:58.564+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:58.566+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:58.567+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:58.569+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:58.570+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:58.572+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:58.573+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:58.574+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:58.574+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:58.575+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:58.576+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:58.578+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:58.579+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:58.580+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:58.581+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:58.582+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:58.583+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:58.584+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:58.585+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:58.586+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:58.588+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:58.589+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:58.591+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:58.592+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:58.594+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:58.595+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:58.596+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:58.596+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:58.598+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)
[2025-04-02T09:17:58.599+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)
[2025-04-02T09:17:58.600+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:58.602+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:58.603+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:58.604+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:58.605+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:58.606+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:58.607+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:58.608+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:58.610+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:58.611+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:58.612+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:58.613+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:58.613+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:58.614+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:58.615+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:58.617+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:58.619+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:58.620+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:58.621+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:58.622+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:58.623+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:58.624+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:58.626+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:58.627+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:58.628+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:58.629+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:58.630+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:58.632+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:58.633+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:58.634+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:58.635+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:58.636+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:58.637+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:58.638+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:58.640+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:58.640+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:58.642+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:58.643+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:58.644+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:58.645+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:58.647+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:58.648+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:58.648+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:58.649+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:58.651+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:58.652+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:58.653+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:58.654+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:58.655+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:58.657+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:58.658+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:58.659+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:58.660+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:58.661+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:58.662+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:58.663+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:58.664+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:58.665+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:58.666+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:58.668+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:58.669+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:58.670+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:58.671+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:58.672+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:58.673+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:58.674+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:58.675+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:58.675+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:58.676+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:58.677+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:58.677+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:58.678+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:58.679+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:58.679+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:58.680+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:58.681+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:58.682+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:58.683+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:58.684+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:58.686+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:58.687+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:58.688+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:58.689+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:58.690+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:58.691+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:58.692+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:58.693+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:58.694+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:58.694+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:58.695+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:58.696+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:58.697+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:58.698+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:58.700+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:58.702+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:58.703+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:58.703+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:58.705+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:58.706+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:58.707+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:58.708+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:58.709+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:58.710+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:58.711+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:58.712+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:58.713+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:58.714+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:58.715+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:58.716+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:58.718+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:58.719+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:58.720+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:58.721+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:58.722+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:58.723+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:58.724+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:58.725+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:58.725+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:58.726+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:58.727+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:58.728+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:58.729+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:58.730+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:58.732+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:58.734+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:58.736+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:58.737+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:58.739+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:58.740+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:58.741+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:58.742+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:58.743+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:58.744+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:58.745+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:58.746+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:58.747+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:58.748+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:58.750+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:58.751+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:58.752+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:58.754+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:58.755+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:58.756+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:58.757+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:58.758+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:58.759+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:58.761+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:58.762+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:58.763+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:58.764+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:58.765+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:58.766+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:58.768+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:58.768+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:58.770+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:58.771+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:58.772+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:58.773+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:58.774+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:58.775+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:58.776+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:58.777+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:58.778+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:58.779+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:58.779+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:58.780+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:58.782+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:58.783+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:58.784+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:58.786+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:58.787+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:58.788+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:58.789+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:58.790+0000] {subprocess.py:106} INFO - 	... 156 more
[2025-04-02T09:17:58.791+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:58.792+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:58.792+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:58.795+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:58.796+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:58.797+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:58.798+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:58.799+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:58.800+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:58.801+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:58.803+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:58.804+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:58.805+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:58.806+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:58.807+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:58.808+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:58.809+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:58.809+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:58.811+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:58.812+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:58.813+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:58.813+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:58.814+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:58.815+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:58.816+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:58.817+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:58.818+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:58.819+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:58.820+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:58.821+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:58.822+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:58.823+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:58.824+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:58.825+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:58.825+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:58.826+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:58.827+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:58.828+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:58.829+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:58.830+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:58.831+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:58.831+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:58.832+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:58.833+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:58.834+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:58.835+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:58.836+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:58.836+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:58.837+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:58.838+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:58.839+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:58.840+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:58.840+0000] {subprocess.py:106} INFO - 25/04/02 09:17:57 WARN HiveMetaStore: Retrying creating default database after error: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:58.841+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:58.842+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:58.843+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:58.844+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:58.844+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:58.845+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:58.846+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:58.846+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:58.847+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:58.848+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:58.849+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:58.850+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:58.851+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:58.852+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:58.853+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:58.854+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:58.855+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:58.856+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:58.857+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:58.858+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:58.859+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:58.860+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:58.860+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:58.861+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:58.863+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:58.864+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:58.864+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:58.865+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:58.866+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:58.867+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:58.868+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:58.869+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:58.870+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:58.871+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:58.871+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:58.872+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:58.873+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:58.874+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:58.875+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:58.876+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:58.877+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:58.878+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:58.879+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:58.880+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:58.880+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:58.881+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:58.882+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:58.883+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:58.884+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:58.885+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:58.887+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:58.888+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:58.889+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:58.890+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:58.891+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:58.893+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:58.893+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:58.894+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:58.895+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:58.896+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:58.897+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:58.898+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:58.899+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:58.899+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:58.901+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:58.902+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:58.903+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:58.903+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:58.904+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:58.905+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:58.906+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:58.907+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:58.908+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:58.909+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:58.910+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:58.910+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:58.911+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:58.912+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:58.913+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:58.914+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:58.915+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:58.916+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:58.917+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:58.918+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:58.919+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:58.920+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:58.920+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:58.921+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:58.922+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:58.923+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:58.924+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:58.925+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:58.926+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:58.927+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:58.928+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:58.929+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:58.930+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:58.931+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:58.932+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:58.934+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:58.935+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:58.936+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:58.937+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:58.938+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:58.939+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:58.940+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:58.941+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:58.942+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:58.943+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:58.944+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:58.945+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:58.946+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:58.947+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:58.949+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:58.950+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:58.951+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:58.952+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:58.952+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:58.953+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:58.954+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:58.955+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:58.956+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:58.957+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:58.958+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:58.959+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:58.960+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:58.961+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:58.961+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:58.963+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:58.964+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:58.965+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:58.966+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:58.967+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:58.968+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:58.969+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:58.970+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:58.971+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:58.971+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:58.972+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:58.973+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:58.974+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:58.975+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:58.976+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:58.977+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:58.977+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:58.979+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:58.980+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:58.981+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:58.982+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:58.983+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:58.984+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:58.985+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:58.985+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:58.986+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:58.987+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:58.988+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:58.988+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:58.989+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:58.990+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:58.991+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:58.992+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:58.993+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:58.994+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:58.994+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:58.995+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:58.996+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:58.997+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:58.998+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:58.999+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:59.001+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:59.002+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:59.003+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:59.004+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:59.005+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:59.005+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:59.006+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:59.007+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:59.008+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:59.009+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:59.010+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:59.011+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:59.011+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:59.012+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:59.014+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:59.015+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:59.016+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:59.017+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:59.018+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:59.019+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:59.020+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:59.021+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:59.022+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:59.023+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:59.024+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:59.026+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:59.027+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:59.028+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:59.028+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:59.029+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:59.030+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:59.031+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:59.032+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:59.032+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:59.033+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:59.034+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:59.035+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:59.036+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:59.038+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:59.039+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:59.039+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:59.040+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:59.041+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:59.042+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:59.043+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:59.044+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:59.045+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:59.046+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:59.046+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:59.047+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:59.048+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:59.049+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:59.050+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:59.051+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:59.052+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:59.053+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:59.053+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:59.055+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:59.056+0000] {subprocess.py:106} INFO - javax.jdo.JDOFatalDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:59.057+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:59.058+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:59.059+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:59.059+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:59.060+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:59.061+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:59.062+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:59.063+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:59.064+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:59.064+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:59.065+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:59.066+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:59.067+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:59.068+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:59.069+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:59.070+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:59.071+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:59.072+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:59.073+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:59.074+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:59.074+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:59.075+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:59.076+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:59.077+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:59.078+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:59.078+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:59.079+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:59.080+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:59.081+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:59.082+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:59.083+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:59.084+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:59.085+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:59.086+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:59.087+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:59.087+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:59.088+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:59.089+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:59.089+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:59.090+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:59.091+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:59.092+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:59.092+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:59.093+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:59.094+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:59.094+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:59.096+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:59.096+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:59.097+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:59.098+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:59.098+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:59.099+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:59.100+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:59.101+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:59.102+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:59.103+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:59.104+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:59.105+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:59.106+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:59.106+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:59.107+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:59.108+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:59.109+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:59.109+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:59.110+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:59.111+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:59.112+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:59.112+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:59.113+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:59.114+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:59.115+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:59.116+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:59.117+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:59.118+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:59.119+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:59.120+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:59.120+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:59.121+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:59.122+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:59.123+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:59.124+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:59.125+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:59.126+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:59.127+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:59.128+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:59.128+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:59.129+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:59.130+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:59.131+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:59.132+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:59.133+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:59.134+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:59.135+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:59.136+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:59.137+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:59.138+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:59.139+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:59.140+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:59.141+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:59.141+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:59.142+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:59.143+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:59.144+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:59.145+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:59.145+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:59.146+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:59.147+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:59.147+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:59.148+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:59.149+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:59.150+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:59.151+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:59.152+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:59.153+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:59.155+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:59.156+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:59.158+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:59.159+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:59.161+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:59.163+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:59.164+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:59.166+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:59.169+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:59.170+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:59.171+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:59.173+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:59.174+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:59.175+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:59.176+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:59.177+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:59.178+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:59.179+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:59.180+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:59.181+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:59.181+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:59.182+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:59.184+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:59.185+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:59.185+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:59.186+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:59.188+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:59.189+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:59.190+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:59.191+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:59.191+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:59.192+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:59.193+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:59.195+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:59.195+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:59.196+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:59.197+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:59.198+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:59.199+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:59.200+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:59.201+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:59.202+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:59.204+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:59.205+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:59.206+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:59.208+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:59.209+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:59.210+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:59.212+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:59.213+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:59.214+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:59.215+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:59.217+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:59.218+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:59.220+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:59.221+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:59.222+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:59.223+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:59.224+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:59.225+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:59.227+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:59.228+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:59.230+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:59.232+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:59.233+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:59.235+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:59.236+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:59.238+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:59.240+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:59.241+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:59.243+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:59.245+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:59.246+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:59.247+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:59.248+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:59.250+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:59.251+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:59.253+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:59.254+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:59.255+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:59.256+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:59.257+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:59.258+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:59.259+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:59.261+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:59.262+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:59.263+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:59.264+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:59.265+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:59.267+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:59.268+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:59.270+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:59.271+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:59.273+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:59.274+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:59.276+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:59.277+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:59.278+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:59.279+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:59.280+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:59.281+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:59.282+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:59.283+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:59.284+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:59.285+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:59.287+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:59.288+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:59.289+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:59.290+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:59.291+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:59.292+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:59.293+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:59.294+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:59.295+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:529)
[2025-04-02T09:17:59.296+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:830)
[2025-04-02T09:17:59.297+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:59.298+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:59.299+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:59.301+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:59.302+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:59.303+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:59.306+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:59.307+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:59.309+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:59.310+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:59.310+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:59.311+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:59.312+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:59.314+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:59.315+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:59.316+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:59.317+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:59.319+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:59.320+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:59.321+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:59.323+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:59.324+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:59.325+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:59.325+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:59.326+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:59.327+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:59.328+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:59.329+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:59.330+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:59.332+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:59.335+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:59.336+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:59.337+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:59.339+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:59.340+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:59.342+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:59.343+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:59.344+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:59.345+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:59.346+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:59.347+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:59.348+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:59.350+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:59.351+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:59.352+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:59.354+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:59.355+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:59.357+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:59.358+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:59.359+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:59.360+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:59.360+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:59.363+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:59.364+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:59.365+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:59.367+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:59.368+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:59.369+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:59.371+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:59.372+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:59.373+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:59.374+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:59.375+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:59.376+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:59.377+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:59.378+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:59.379+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:59.381+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:59.382+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:59.384+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:59.385+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:59.386+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:59.387+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:59.388+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:59.390+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:59.391+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:59.392+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:59.393+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:59.394+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:59.396+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:59.397+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:59.398+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:59.399+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:59.400+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:59.401+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:59.402+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:59.404+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:59.405+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:59.406+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:59.406+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:59.408+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:59.409+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:59.410+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:59.411+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:59.412+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:59.413+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:59.414+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:59.415+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:59.416+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:59.417+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:59.419+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:59.419+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:59.421+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:59.422+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:59.422+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:59.423+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:59.424+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:59.425+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:59.426+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:59.427+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:59.428+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:59.429+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:59.430+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:59.432+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:59.433+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:59.435+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:59.436+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:59.437+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:59.438+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:59.440+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:59.441+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:59.442+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:59.443+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:59.444+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:59.445+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:59.446+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:59.447+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:59.448+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:59.450+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:59.451+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:59.452+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:59.453+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:59.454+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:59.455+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:59.456+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:59.457+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:59.458+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:59.459+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:59.460+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:59.461+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:59.462+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:59.463+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:59.464+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:59.465+0000] {subprocess.py:106} INFO - NestedThrowablesStackTrace:
[2025-04-02T09:17:59.466+0000] {subprocess.py:106} INFO - java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:17:59.467+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:59.468+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:59.469+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:59.470+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:59.471+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:59.472+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:59.473+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:59.474+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:59.475+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:59.476+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:59.477+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:59.478+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:59.479+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:59.480+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:59.481+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:59.481+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:59.482+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:59.483+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:59.485+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:59.486+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:59.487+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:59.488+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:59.489+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:59.490+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:59.492+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:59.493+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:59.494+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:59.495+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:59.496+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:59.496+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:59.497+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:59.498+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:59.500+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:59.501+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:59.503+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:59.504+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:59.505+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:59.506+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:59.508+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:59.509+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:59.510+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:59.511+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:59.512+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:59.513+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:59.514+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:59.515+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:59.516+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:59.518+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:59.519+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:59.520+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:59.521+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:59.522+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:59.524+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:59.524+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:59.525+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:59.526+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:59.527+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:59.528+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:59.529+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:59.530+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:59.531+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:59.532+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:59.533+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:59.534+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:59.538+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:59.539+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:59.540+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:59.541+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:59.542+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:59.543+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:59.544+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:59.545+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:59.545+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:59.546+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:59.547+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:59.548+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:59.549+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:59.550+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:59.551+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:59.553+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:59.554+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:59.555+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:59.556+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:59.557+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:59.558+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:59.560+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:59.563+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:59.564+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:59.565+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:59.566+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:59.567+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:59.568+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:59.569+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:59.571+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:59.572+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:59.573+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:59.574+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:59.575+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:59.576+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:59.577+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:59.578+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:59.579+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:59.580+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:59.581+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:59.582+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:59.583+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:59.585+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:59.586+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:59.587+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:59.588+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:59.590+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:59.591+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:59.591+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:59.593+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:59.594+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:59.595+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:59.596+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:59.597+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:59.598+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:59.599+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:59.601+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:59.601+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:59.603+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:59.604+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:59.605+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:59.606+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:59.607+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:59.608+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:59.609+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:59.610+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:59.611+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:59.612+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:59.613+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:59.614+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:59.614+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:59.615+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:59.617+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:59.618+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:59.619+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:59.620+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:59.621+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:59.622+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:59.623+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:59.624+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:59.626+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:59.627+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:59.628+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:59.628+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:59.629+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:59.630+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:59.632+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:59.634+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:59.636+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:59.637+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:59.638+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:59.639+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:59.640+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:59.642+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:59.642+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:59.643+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:59.644+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:59.645+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:59.646+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:59.647+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:59.648+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:59.649+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:59.650+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:59.651+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:59.652+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:59.654+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:59.655+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:59.656+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:59.658+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:59.659+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:59.660+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:59.661+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:59.662+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:59.663+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:59.664+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:59.666+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:59.668+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:59.669+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:59.670+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:59.671+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:59.673+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:59.674+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:59.675+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:59.676+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:59.677+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:59.678+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:59.679+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:59.680+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:59.681+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:59.682+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:59.686+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:59.687+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:59.687+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:59.688+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:59.690+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:59.690+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:59.692+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:59.693+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:59.693+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:59.694+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:59.695+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:59.696+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:59.696+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:59.697+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:59.698+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:59.699+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:59.701+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:59.702+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:59.703+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:59.705+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:59.706+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:59.707+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:59.708+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:59.709+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:59.710+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:59.712+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:59.713+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:59.714+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:59.715+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:59.715+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:59.717+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:59.719+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:17:59.720+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:17:59.721+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:59.722+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:59.723+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:59.724+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:59.725+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:59.726+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)
[2025-04-02T09:17:59.727+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)
[2025-04-02T09:17:59.728+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:17:59.728+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:17:59.729+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:17:59.730+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:59.731+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:59.732+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:59.734+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:59.736+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:59.737+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:17:59.738+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:17:59.740+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:17:59.741+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:17:59.742+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:17:59.744+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:17:59.745+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:17:59.747+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:59.748+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:59.749+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:59.750+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:59.751+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:17:59.752+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:59.753+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:17:59.755+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:17:59.756+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:17:59.757+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:17:59.758+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:17:59.759+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:17:59.760+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:17:59.761+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:17:59.763+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:17:59.765+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:17:59.766+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:17:59.767+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:17:59.769+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:17:59.771+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:17:59.773+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:17:59.774+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:17:59.775+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:17:59.776+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:17:59.777+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:59.778+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:59.780+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:59.782+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:59.783+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:17:59.784+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:17:59.786+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:17:59.787+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:17:59.789+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:17:59.790+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:17:59.791+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:17:59.793+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:17:59.794+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:17:59.796+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:17:59.797+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:17:59.798+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:17:59.800+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:17:59.802+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:17:59.803+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:17:59.804+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:17:59.805+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:17:59.806+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:17:59.808+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:17:59.809+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:17:59.810+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:17:59.811+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:17:59.812+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:17:59.815+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:59.816+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:17:59.817+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:17:59.818+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:17:59.820+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:17:59.821+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:17:59.822+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:59.823+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:17:59.824+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:17:59.825+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:17:59.826+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:17:59.827+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:17:59.828+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:17:59.829+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:17:59.830+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:17:59.831+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:17:59.832+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:17:59.834+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:17:59.835+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:17:59.837+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:17:59.838+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:17:59.840+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:17:59.842+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:17:59.843+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:17:59.844+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:17:59.845+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:17:59.846+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:17:59.847+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:59.849+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:59.851+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:59.852+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:59.853+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:17:59.855+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:17:59.856+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:17:59.857+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:17:59.859+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:17:59.860+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:17:59.861+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:17:59.862+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:17:59.863+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:17:59.864+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:17:59.865+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:17:59.867+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:17:59.869+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:17:59.870+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:17:59.871+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:17:59.872+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:17:59.873+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:17:59.874+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:17:59.876+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:17:59.876+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:17:59.877+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:17:59.878+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:17:59.879+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:17:59.880+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:17:59.881+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:17:59.882+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:17:59.883+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:17:59.884+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:17:59.885+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:17:59.886+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:17:59.887+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:17:59.888+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:17:59.889+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:17:59.890+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:17:59.891+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:17:59.892+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:59.894+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:17:59.895+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:17:59.896+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:17:59.897+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:17:59.898+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:17:59.899+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:59.900+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:17:59.901+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:17:59.902+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:17:59.904+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:17:59.905+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:17:59.906+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:17:59.907+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:17:59.910+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:17:59.912+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:17:59.913+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:17:59.915+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:17:59.917+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:17:59.918+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:17:59.920+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:17:59.921+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:17:59.922+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:17:59.923+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:17:59.924+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:59.925+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:59.926+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:17:59.928+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:17:59.929+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:17:59.930+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:17:59.931+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:59.932+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:17:59.933+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:59.934+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:17:59.935+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:59.936+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:17:59.938+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:17:59.939+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:17:59.940+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:17:59.942+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:17:59.943+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:17:59.944+0000] {subprocess.py:106} INFO - 	... 156 more
[2025-04-02T09:17:59.944+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:17:59.946+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:59.946+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:17:59.947+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:17:59.948+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:17:59.949+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:59.950+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:17:59.951+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:59.952+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:17:59.953+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:59.954+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:17:59.955+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:17:59.956+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:59.956+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:59.957+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:59.958+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:59.959+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:59.959+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:17:59.960+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:59.961+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:17:59.962+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:17:59.963+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:59.964+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:59.965+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:59.966+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:59.967+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:59.968+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:17:59.969+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:59.970+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:17:59.971+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:17:59.972+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:59.972+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:59.974+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:17:59.974+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:17:59.975+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:17:59.976+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:17:59.977+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:59.978+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:17:59.979+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:17:59.979+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:17:59.980+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:17:59.981+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:17:59.982+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:17:59.983+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:17:59.984+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:17:59.985+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:59.986+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:17:59.987+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:59.988+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:17:59.990+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:17:59.991+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:17:59.992+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:17:59.993+0000] {subprocess.py:106} INFO - 25/04/02 09:17:59 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
[2025-04-02T09:17:59.994+0000] {subprocess.py:106} INFO - 25/04/02 09:17:59 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
[2025-04-02T09:17:59.995+0000] {subprocess.py:106} INFO - 25/04/02 09:17:59 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
[2025-04-02T09:17:59.995+0000] {subprocess.py:106} INFO - 25/04/02 09:17:59 INFO ObjectStore: ObjectStore, initialize called
[2025-04-02T09:17:59.998+0000] {subprocess.py:106} INFO - 25/04/02 09:17:59 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
[2025-04-02T09:17:59.999+0000] {subprocess.py:106} INFO - 25/04/02 09:17:59 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
[2025-04-02T09:18:00.001+0000] {subprocess.py:106} INFO - 25/04/02 09:17:59 ERROR Schema: Failed initialising database.
[2025-04-02T09:18:00.002+0000] {subprocess.py:106} INFO - Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:18:00.004+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:00.005+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:00.006+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:00.007+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:18:00.008+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:18:00.009+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:18:00.010+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:00.012+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:00.013+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:00.014+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:18:00.016+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:00.017+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:00.019+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:18:00.021+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:18:00.022+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:18:00.023+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:18:00.024+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:18:00.025+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:18:00.026+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:18:00.028+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:18:00.028+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:00.030+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:00.031+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:00.032+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:00.032+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:00.034+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:18:00.035+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:18:00.037+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:18:00.038+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:18:00.040+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:18:00.041+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:18:00.042+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:18:00.043+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:00.044+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:00.045+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:00.046+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:00.047+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:18:00.048+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:00.049+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:18:00.050+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:18:00.051+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:18:00.052+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:18:00.053+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:18:00.054+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:18:00.055+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:18:00.057+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:18:00.058+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:18:00.059+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:18:00.060+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:18:00.061+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:18:00.062+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:18:00.064+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:18:00.065+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:18:00.066+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:18:00.068+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)
[2025-04-02T09:18:00.070+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:18:00.072+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:00.073+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:00.074+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:00.075+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:00.076+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:18:00.078+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:18:00.079+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:18:00.080+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:18:00.081+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:18:00.082+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:18:00.083+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:18:00.085+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:00.086+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:00.088+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:00.089+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:00.091+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:00.092+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:18:00.093+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:18:00.095+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:18:00.096+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:18:00.096+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:18:00.097+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:18:00.099+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:18:00.100+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:18:00.102+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:18:00.103+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:18:00.104+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:18:00.106+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:00.107+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:18:00.108+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:18:00.109+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:18:00.110+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:18:00.111+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:18:00.112+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:00.113+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:00.114+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:18:00.114+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:00.115+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:18:00.116+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:18:00.118+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:18:00.119+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:18:00.120+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:18:00.122+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:18:00.124+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:18:00.125+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:18:00.126+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:18:00.127+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:18:00.129+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:18:00.130+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:18:00.131+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:18:00.133+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:18:00.134+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:18:00.135+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:18:00.137+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:18:00.138+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:00.140+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:00.142+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:00.143+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:00.144+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:18:00.145+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:18:00.146+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:18:00.146+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:18:00.147+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:18:00.148+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:00.150+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:00.151+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:00.152+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:00.153+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:18:00.154+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:18:00.156+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:18:00.157+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:18:00.158+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:18:00.159+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:18:00.161+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:18:00.162+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:18:00.162+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:18:00.163+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:18:00.165+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:18:00.166+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:18:00.167+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:18:00.168+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:18:00.169+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:18:00.170+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:18:00.172+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:18:00.173+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:18:00.174+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:18:00.175+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:18:00.176+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:18:00.177+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:18:00.178+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:18:00.179+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:18:00.180+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:18:00.182+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:18:00.183+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:00.184+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:18:00.185+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:18:00.186+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:18:00.187+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:18:00.189+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:18:00.191+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:00.192+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:18:00.193+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:18:00.194+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:00.195+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:18:00.196+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:18:00.197+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:00.198+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:00.199+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:00.200+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:00.201+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:18:00.202+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:18:00.203+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:18:00.204+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:18:00.205+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:18:00.206+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:18:00.208+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:18:00.209+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:18:00.210+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:00.212+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:00.213+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:18:00.215+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:18:00.216+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:18:00.218+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:00.219+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:00.220+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:00.221+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:18:00.222+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:00.223+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:00.224+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:18:00.225+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:00.226+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:00.228+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:00.229+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:00.230+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:00.231+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:18:00.232+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:00.233+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:18:00.235+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:18:00.236+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:00.237+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:00.239+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:00.240+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:00.242+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:00.243+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:18:00.245+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:00.246+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:18:00.247+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:18:00.248+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:00.250+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:00.251+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:00.252+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:00.253+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:00.254+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:18:00.255+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:00.256+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:18:00.257+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:18:00.258+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:18:00.259+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:00.260+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:00.261+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:18:00.265+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:18:00.266+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:18:00.268+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:00.269+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:00.270+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:00.271+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:00.272+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:00.273+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:18:00.274+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:18:00.276+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:18:00.277+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:18:00.278+0000] {subprocess.py:106} INFO - org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:18:00.279+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:00.280+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:00.281+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:00.281+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:18:00.282+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:18:00.283+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:18:00.285+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:00.286+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:00.287+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:00.287+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:18:00.289+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:00.289+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:00.290+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:18:00.291+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:18:00.292+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:18:00.293+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:18:00.294+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:18:00.295+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:18:00.296+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:18:00.297+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:18:00.297+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:00.298+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:00.299+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:00.300+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:00.301+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:00.302+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:18:00.303+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:18:00.304+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:18:00.305+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:18:00.306+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:18:00.307+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:18:00.308+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:18:00.309+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:00.310+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:00.311+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:00.311+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:00.312+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:18:00.313+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:00.314+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:18:00.315+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:18:00.316+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:18:00.317+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:18:00.318+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:18:00.319+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:18:00.320+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:18:00.322+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:18:00.323+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:18:00.324+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:18:00.325+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:18:00.326+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:18:00.327+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:18:00.327+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:18:00.329+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:18:00.330+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:18:00.331+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)
[2025-04-02T09:18:00.332+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:18:00.333+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:00.334+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:00.335+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:00.336+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:00.337+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:18:00.338+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:18:00.339+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:18:00.340+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:18:00.341+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:18:00.342+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:18:00.343+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:18:00.344+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:00.345+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:00.346+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:00.347+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:00.348+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:00.349+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:18:00.350+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:18:00.351+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:18:00.352+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:18:00.353+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:18:00.354+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:18:00.355+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:18:00.356+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:18:00.357+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:18:00.358+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:18:00.359+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:18:00.360+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:00.361+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:18:00.362+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:18:00.362+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:18:00.363+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:18:00.364+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:18:00.365+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:00.366+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:00.367+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:18:00.368+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:00.369+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:18:00.370+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:18:00.371+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:18:00.372+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:18:00.374+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:18:00.375+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:18:00.376+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:18:00.377+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:18:00.377+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:18:00.378+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:18:00.379+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:18:00.380+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:18:00.381+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:18:00.382+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:18:00.383+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:18:00.384+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:18:00.385+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:18:00.387+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:00.388+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:00.389+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:00.390+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:00.391+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:18:00.392+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:18:00.393+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:18:00.395+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:18:00.396+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:18:00.396+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:00.398+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:00.399+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:00.400+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:00.402+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:18:00.403+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:18:00.405+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:18:00.406+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:18:00.407+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:18:00.408+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:18:00.410+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:18:00.411+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:18:00.412+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:18:00.413+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:18:00.415+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:18:00.416+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:18:00.417+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:18:00.418+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:18:00.420+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:18:00.421+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:18:00.422+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:18:00.423+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:18:00.424+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:18:00.425+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:18:00.426+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:18:00.427+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:18:00.428+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:18:00.429+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:18:00.430+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:18:00.432+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:18:00.433+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:00.434+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:18:00.436+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:18:00.437+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:18:00.438+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:18:00.439+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:18:00.440+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:00.440+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:18:00.441+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:18:00.442+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:00.443+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:18:00.444+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:18:00.445+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:00.446+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:00.449+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:00.450+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:00.452+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:18:00.454+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:18:00.455+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:18:00.456+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:18:00.457+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:18:00.459+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:18:00.459+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:18:00.460+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:18:00.461+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:00.462+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:00.463+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:18:00.464+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:18:00.464+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:18:00.466+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:00.468+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:00.470+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:00.471+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:18:00.473+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:00.474+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:00.476+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:18:00.477+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:00.478+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:00.479+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:00.480+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:00.481+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:00.482+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:18:00.484+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:00.485+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:18:00.487+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:18:00.488+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:00.490+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:00.491+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:00.491+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:00.492+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:00.493+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:18:00.495+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:00.496+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:18:00.497+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:18:00.498+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:00.499+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:00.500+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:00.501+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:00.502+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:00.503+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:18:00.504+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:00.508+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:18:00.509+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:18:00.510+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:18:00.512+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:00.513+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:00.514+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:18:00.515+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:18:00.516+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:18:00.517+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:00.518+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:00.521+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:00.523+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:00.525+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:00.526+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:18:00.527+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:18:00.530+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:18:00.531+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:18:00.533+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)
[2025-04-02T09:18:00.534+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:18:00.538+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:00.539+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:00.541+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:00.543+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:00.544+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:00.546+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:18:00.549+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:18:00.551+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:18:00.552+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:18:00.553+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:18:00.555+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:18:00.556+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:18:00.557+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:00.558+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:00.560+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:00.561+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:00.562+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:18:00.563+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:00.565+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:18:00.567+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:18:00.572+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:18:00.574+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:18:00.575+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:18:00.577+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:18:00.578+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:18:00.580+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:18:00.581+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:18:00.583+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:18:00.584+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:18:00.586+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:18:00.587+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:18:00.588+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:18:00.589+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:18:00.590+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:18:00.592+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)
[2025-04-02T09:18:00.593+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:18:00.594+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:00.595+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:00.596+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:00.597+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:00.599+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:18:00.600+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:18:00.601+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:18:00.602+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:18:00.604+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:18:00.605+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:18:00.605+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:18:00.606+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:00.607+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:00.608+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:00.609+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:00.611+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:00.612+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:18:00.612+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:18:00.613+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:18:00.614+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:18:00.616+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:18:00.617+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:18:00.618+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:18:00.620+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:18:00.621+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:18:00.622+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:18:00.623+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:18:00.624+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:00.625+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:18:00.626+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:18:00.628+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:18:00.630+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:18:00.631+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:18:00.633+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:00.634+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:00.636+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:18:00.637+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:00.638+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:18:00.640+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:18:00.642+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:18:00.643+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:18:00.645+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:18:00.647+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:18:00.648+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:18:00.649+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:18:00.651+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:18:00.653+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:18:00.655+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:18:00.657+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:18:00.658+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:18:00.659+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:18:00.660+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:18:00.661+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:18:00.662+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:18:00.662+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:00.664+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:00.665+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:00.666+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:00.667+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:18:00.668+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:18:00.669+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:18:00.670+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:18:00.671+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:18:00.672+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:00.673+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:00.674+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:00.675+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:00.676+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:18:00.677+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:18:00.677+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:18:00.678+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:18:00.679+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:18:00.680+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:18:00.681+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:18:00.682+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:18:00.683+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:18:00.684+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:18:00.686+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:18:00.687+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:18:00.690+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:18:00.691+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:18:00.692+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:18:00.693+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:18:00.694+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:18:00.695+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:18:00.696+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:18:00.697+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:18:00.698+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:18:00.700+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:18:00.701+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:18:00.704+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:18:00.705+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:18:00.706+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:18:00.707+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:00.708+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:18:00.709+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:18:00.710+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:18:00.711+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:18:00.712+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:18:00.713+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:00.714+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:18:00.715+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:18:00.716+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:00.717+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:18:00.719+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:18:00.720+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:00.721+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:00.722+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:00.723+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:00.724+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:18:00.725+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:18:00.726+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:18:00.727+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:18:00.727+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:18:00.728+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:18:00.729+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:18:00.730+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:18:00.731+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:18:00.732+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:00.732+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:00.734+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:00.735+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:18:00.736+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:18:00.737+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:18:00.738+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:00.739+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:00.740+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:00.741+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:18:00.742+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:00.743+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:00.744+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:18:00.745+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:18:00.746+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:18:00.747+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:18:00.748+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:18:00.749+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:18:00.750+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:18:00.751+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:18:00.752+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:00.753+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:00.754+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:00.756+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:00.757+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:00.758+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:18:00.760+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:18:00.761+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:18:00.762+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:18:00.763+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:18:00.764+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:18:00.765+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:18:00.767+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:00.768+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:00.769+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:00.770+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:00.772+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:18:00.775+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:00.776+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:18:00.777+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:18:00.778+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:18:00.779+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:18:00.780+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:18:00.781+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:18:00.782+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:18:00.784+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:18:00.785+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:18:00.787+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:18:00.788+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:18:00.790+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:18:00.791+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:18:00.792+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:18:00.793+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:18:00.795+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:18:00.796+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)
[2025-04-02T09:18:00.798+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:18:00.799+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:00.800+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:00.801+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:00.802+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:00.803+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:18:00.804+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:18:00.805+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:18:00.806+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:18:00.807+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:18:00.808+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:18:00.809+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:18:00.810+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:00.811+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:00.813+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:00.814+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:00.815+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:00.816+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:18:00.817+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:18:00.818+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:18:00.819+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:18:00.820+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:18:00.821+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:18:00.822+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:18:00.824+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:18:00.825+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:18:00.826+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:18:00.826+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:18:00.827+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:00.828+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:18:00.829+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:18:00.830+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:18:00.831+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:18:00.833+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:18:00.834+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:00.835+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:00.836+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:18:00.838+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:00.838+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:18:00.840+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:18:00.841+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:18:00.844+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:18:00.845+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:18:00.847+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:18:00.849+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:18:00.850+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:18:00.851+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:18:00.852+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:18:00.853+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:18:00.854+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:18:00.855+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:18:00.856+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:18:00.856+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:18:00.857+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:18:00.858+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:18:00.859+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:00.860+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:00.861+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:00.862+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:00.862+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:18:00.863+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:18:00.864+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:18:00.865+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:18:00.866+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:18:00.867+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:00.868+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:00.869+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:00.870+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:00.872+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:18:00.872+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:18:00.874+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:18:00.875+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:18:00.876+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:18:00.877+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:18:00.878+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:18:00.879+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:18:00.880+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:18:00.881+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:18:00.881+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:18:00.882+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:18:00.883+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:18:00.884+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:18:00.885+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:18:00.886+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:18:00.887+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:18:00.888+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:18:00.889+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:18:00.890+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:18:00.891+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:18:00.892+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:18:00.893+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:18:00.894+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:18:00.895+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:18:00.896+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:18:00.896+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:00.897+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:18:00.898+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:18:00.900+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:18:00.901+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:18:00.902+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:18:00.904+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:00.905+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:18:00.906+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:18:00.908+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:00.909+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:18:00.910+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:18:00.912+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:00.913+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:00.914+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:00.915+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:00.917+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:18:00.918+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:18:00.919+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:18:00.920+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:18:00.922+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:18:00.924+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:18:00.925+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:18:00.925+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:18:00.927+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:00.929+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:00.930+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:18:00.931+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:18:00.932+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:18:00.933+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:00.934+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:00.935+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:00.936+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:18:00.938+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:00.939+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:00.940+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:18:00.941+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:00.942+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:00.943+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:00.944+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:00.945+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:00.946+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:18:00.947+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:00.948+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:18:00.952+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:18:00.954+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:00.955+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:00.957+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:00.959+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:00.960+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:00.961+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:18:00.963+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:00.964+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:18:00.965+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:18:00.969+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:00.971+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:00.973+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:00.974+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:00.975+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:00.978+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:18:00.979+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:00.981+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:18:00.982+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:18:00.985+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:18:00.988+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:00.989+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:00.991+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:18:00.992+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:18:00.993+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:18:00.995+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:00.997+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:00.998+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:00.999+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:01.001+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:01.003+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:18:01.004+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:18:01.006+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:18:01.007+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:18:01.009+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:01.010+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:01.011+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:01.012+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:01.013+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:01.013+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)
[2025-04-02T09:18:01.014+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)
[2025-04-02T09:18:01.015+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:18:01.017+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:18:01.019+0000] {subprocess.py:106} INFO - 	... 154 more
[2025-04-02T09:18:01.020+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:01.022+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:01.023+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:01.024+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:18:01.026+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:18:01.027+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:18:01.028+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:01.030+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:01.031+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:01.032+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:18:01.033+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:01.035+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:01.036+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:18:01.037+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:18:01.041+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:18:01.042+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:18:01.044+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:18:01.045+0000] {subprocess.py:106} INFO - 	... 156 more
[2025-04-02T09:18:01.046+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:01.048+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:01.049+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:18:01.050+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:18:01.052+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:18:01.053+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:01.054+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:01.056+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:01.056+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:18:01.058+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:01.059+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:01.061+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:18:01.063+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:01.064+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:01.065+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:01.065+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:01.067+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:01.068+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:18:01.070+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:01.071+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:18:01.073+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:18:01.074+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:01.075+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:01.076+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:01.077+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:01.078+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:01.079+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:18:01.081+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:01.082+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:18:01.084+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:18:01.085+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:01.087+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:01.088+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:01.090+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:01.093+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:01.094+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:18:01.095+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:01.095+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:18:01.097+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:18:01.098+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:18:01.099+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:01.103+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:01.106+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:18:01.109+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:18:01.110+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:18:01.111+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:01.113+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:01.115+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:01.116+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:01.117+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:01.119+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:18:01.120+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:18:01.122+0000] {subprocess.py:106} INFO - Nested Throwables StackTrace:
[2025-04-02T09:18:01.124+0000] {subprocess.py:106} INFO - java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:18:01.126+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:01.128+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:01.130+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:01.132+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:18:01.134+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:18:01.137+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:18:01.139+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:01.141+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:01.143+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:01.145+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:18:01.146+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:01.148+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:01.149+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:18:01.151+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:18:01.155+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:18:01.158+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:18:01.160+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:18:01.162+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:18:01.164+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:18:01.165+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:18:01.167+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:01.170+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:01.172+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:01.174+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:01.177+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:01.178+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:18:01.180+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:18:01.182+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:18:01.185+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:18:01.187+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:18:01.189+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:18:01.193+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:18:01.195+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:01.197+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:01.199+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:01.202+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:01.205+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:18:01.207+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:01.208+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:18:01.209+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:18:01.210+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:18:01.211+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:18:01.212+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:18:01.213+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:18:01.215+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:18:01.217+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:18:01.218+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:18:01.219+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:18:01.221+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:18:01.223+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:18:01.225+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:18:01.226+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:18:01.228+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:18:01.230+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:18:01.231+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)
[2025-04-02T09:18:01.232+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:18:01.233+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:01.234+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:01.236+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:01.237+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:01.238+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:18:01.239+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:18:01.241+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:18:01.243+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:18:01.245+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:18:01.246+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:18:01.248+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:18:01.249+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:01.251+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:01.252+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:01.253+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:01.255+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:01.256+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:18:01.257+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:18:01.259+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:18:01.260+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:18:01.262+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:18:01.264+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:18:01.265+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:18:01.267+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:18:01.269+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:18:01.271+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:18:01.272+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:18:01.274+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:01.275+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:18:01.276+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:18:01.277+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:18:01.279+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:18:01.280+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:18:01.281+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:01.283+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:01.284+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:18:01.286+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:01.289+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:18:01.290+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:18:01.291+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:18:01.292+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:18:01.293+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:18:01.295+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:18:01.296+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:18:01.297+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:18:01.299+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:18:01.301+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:18:01.304+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:18:01.305+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:18:01.306+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:18:01.309+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:18:01.310+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:18:01.311+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:18:01.313+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:18:01.314+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:01.316+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:01.317+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:01.318+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:01.322+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:18:01.323+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:18:01.324+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:18:01.325+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:18:01.326+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:18:01.328+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:01.330+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:01.334+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:01.336+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:01.338+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:18:01.339+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:18:01.340+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:18:01.342+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:18:01.345+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:18:01.347+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:18:01.351+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:18:01.352+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:18:01.354+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:18:01.355+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:18:01.356+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:18:01.358+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:18:01.361+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:18:01.366+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:18:01.369+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:18:01.372+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:18:01.375+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:18:01.382+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:18:01.385+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:18:01.389+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:18:01.390+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:18:01.393+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:18:01.399+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:18:01.401+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:18:01.402+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:18:01.404+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:18:01.405+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:01.407+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:18:01.409+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:18:01.411+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:18:01.413+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:18:01.414+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:18:01.415+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:01.418+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:18:01.422+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:18:01.423+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:01.425+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:18:01.426+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:18:01.427+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:01.430+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:01.431+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:01.433+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:01.435+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:18:01.438+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:18:01.439+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:18:01.440+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:18:01.441+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:18:01.443+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:18:01.445+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:18:01.446+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:18:01.448+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:01.449+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:01.451+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:18:01.452+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:18:01.454+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:18:01.455+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:01.457+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:01.458+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:01.460+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:18:01.462+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:01.463+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:01.464+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:18:01.465+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:01.466+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:01.468+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:01.469+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:01.471+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:01.473+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:18:01.474+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:01.475+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:18:01.477+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:18:01.478+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:01.479+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:01.481+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:01.482+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:01.485+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:01.487+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:18:01.489+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:01.491+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:18:01.493+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:18:01.495+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:01.497+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:01.500+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:01.502+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:01.505+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:01.507+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:18:01.509+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:01.510+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:18:01.511+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:18:01.513+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:18:01.514+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:01.518+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:01.520+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:18:01.524+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:18:01.526+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:18:01.528+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:01.530+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:01.533+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:01.535+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:01.537+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:01.540+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:18:01.544+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:18:01.546+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:18:01.548+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:18:01.551+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:01.553+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:01.557+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:01.558+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:01.560+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:01.562+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)
[2025-04-02T09:18:01.563+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)
[2025-04-02T09:18:01.565+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:18:01.568+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:18:01.569+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:18:01.572+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:01.573+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:01.575+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:01.576+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:01.578+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:01.580+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:18:01.582+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:18:01.587+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:18:01.589+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:18:01.590+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:18:01.592+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:18:01.593+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:18:01.595+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:01.596+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:01.598+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:01.601+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:01.603+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:18:01.606+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:01.607+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:18:01.608+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:18:01.609+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:18:01.611+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:18:01.612+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:18:01.614+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:18:01.615+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:18:01.616+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:18:01.618+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:18:01.619+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:18:01.620+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:18:01.621+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:18:01.622+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:18:01.623+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:18:01.625+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:18:01.626+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:18:01.628+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)
[2025-04-02T09:18:01.629+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:18:01.631+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:01.632+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:01.633+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:01.634+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:01.635+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:18:01.636+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:18:01.637+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:18:01.638+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:18:01.640+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:18:01.641+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:18:01.643+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:18:01.644+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:01.645+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:01.647+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:01.651+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:01.652+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:01.655+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:18:01.656+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:18:01.657+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:18:01.660+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:18:01.661+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:18:01.663+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:18:01.664+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:18:01.666+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:18:01.667+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:18:01.669+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:18:01.670+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:18:01.671+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:01.673+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:18:01.674+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:18:01.675+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:18:01.676+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:18:01.678+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:18:01.679+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:01.680+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:01.681+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:18:01.682+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:01.684+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:18:01.685+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:18:01.687+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:18:01.688+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:18:01.689+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:18:01.691+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:18:01.692+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:18:01.694+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:18:01.695+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:18:01.697+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:18:01.698+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:18:01.700+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:18:01.701+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:18:01.702+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:18:01.704+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:18:01.705+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:18:01.706+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:18:01.707+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:01.709+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:01.710+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:01.711+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:01.712+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:18:01.712+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:18:01.713+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:18:01.714+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:18:01.715+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:18:01.716+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:01.717+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:01.718+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:01.719+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:01.720+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:18:01.721+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:18:01.722+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:18:01.723+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:18:01.724+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:18:01.725+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:18:01.726+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:18:01.726+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:18:01.727+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:18:01.729+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:18:01.730+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:18:01.731+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:18:01.733+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:18:01.735+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:18:01.736+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:18:01.737+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:18:01.739+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:18:01.741+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:18:01.742+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:18:01.743+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:18:01.744+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:18:01.745+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:18:01.747+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:18:01.748+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:18:01.749+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:18:01.750+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:18:01.752+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:01.753+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:18:01.755+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:18:01.757+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:18:01.758+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:18:01.760+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:18:01.761+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:01.763+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:18:01.764+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:18:01.765+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:01.767+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:18:01.769+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:18:01.770+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:01.772+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:01.773+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:01.775+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:01.776+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:18:01.778+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:18:01.779+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:18:01.782+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:18:01.785+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:18:01.787+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:18:01.788+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:18:01.790+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:18:01.792+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:01.793+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:01.794+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:01.796+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:18:01.798+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:18:01.800+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:18:01.802+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:01.804+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:01.806+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:01.807+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:18:01.808+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:01.810+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:01.811+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:18:01.813+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:18:01.815+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:18:01.817+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:18:01.818+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:18:01.819+0000] {subprocess.py:106} INFO - 	... 156 more
[2025-04-02T09:18:01.821+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:01.822+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:01.825+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:18:01.828+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:18:01.832+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:18:01.835+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:01.838+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:01.842+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:01.844+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:18:01.847+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:01.850+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:01.853+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:18:01.857+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:01.859+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:01.862+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:01.866+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:01.867+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:01.869+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:18:01.870+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:01.872+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:18:01.874+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:18:01.875+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:01.877+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:01.878+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:01.879+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:01.880+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:01.881+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:18:01.882+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:01.883+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:18:01.885+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:18:01.886+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:01.887+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:01.889+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:01.890+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:01.892+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:01.893+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:18:01.895+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:01.896+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:18:01.898+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:18:01.900+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:18:01.901+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:01.904+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:01.906+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:18:01.907+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:18:01.910+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:18:01.912+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:01.913+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:01.916+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:01.918+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:01.920+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:01.921+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:18:01.923+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:18:01.924+0000] {subprocess.py:106} INFO - 25/04/02 09:18:00 ERROR Datastore: Exception thrown creating StoreManager. See the nested exception
[2025-04-02T09:18:01.925+0000] {subprocess.py:106} INFO - Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:18:01.927+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:01.928+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:01.929+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:01.931+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:18:01.934+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:18:01.935+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:18:01.938+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:01.939+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:01.941+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:01.946+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:18:01.956+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:01.958+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:01.959+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:18:01.961+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:18:01.963+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:18:01.964+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:18:01.966+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:18:01.967+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:18:01.968+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:18:01.969+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:18:01.970+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:01.972+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:01.974+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:01.975+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:01.976+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:01.977+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:18:01.979+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:18:01.980+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:18:01.981+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:18:01.984+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:18:01.986+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:18:01.987+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:18:01.989+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:01.990+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:01.991+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:01.993+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:01.994+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:18:01.995+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:01.997+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:18:02.003+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:18:02.005+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:18:02.006+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:18:02.007+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:18:02.009+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:18:02.010+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:18:02.011+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:18:02.012+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:18:02.014+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:18:02.016+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:18:02.018+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:18:02.019+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:18:02.020+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:18:02.022+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:18:02.023+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:18:02.025+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)
[2025-04-02T09:18:02.026+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:18:02.029+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:02.030+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:02.035+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:02.038+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:02.040+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:18:02.041+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:18:02.042+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:18:02.045+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:18:02.046+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:18:02.047+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:18:02.049+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:18:02.050+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:02.052+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:02.053+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:02.054+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:02.056+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:02.057+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:18:02.058+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:18:02.060+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:18:02.061+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:18:02.063+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:18:02.065+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:18:02.066+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:18:02.067+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:18:02.068+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:18:02.070+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:18:02.071+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:18:02.072+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:02.073+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:18:02.075+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:18:02.076+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:18:02.077+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:18:02.079+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:18:02.080+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:02.081+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:02.082+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:18:02.083+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:02.085+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:18:02.086+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:18:02.087+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:18:02.090+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:18:02.091+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:18:02.094+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:18:02.096+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:18:02.097+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:18:02.098+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:18:02.099+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:18:02.101+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:18:02.102+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:18:02.104+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:18:02.105+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:18:02.107+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:18:02.109+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:18:02.110+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:18:02.112+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:02.113+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:02.115+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:02.118+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:02.119+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:18:02.121+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:18:02.122+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:18:02.124+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:18:02.125+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:18:02.126+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:02.127+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:02.128+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:02.129+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:02.131+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:18:02.132+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:18:02.134+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:18:02.136+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:18:02.137+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:18:02.138+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:18:02.140+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:18:02.141+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:18:02.142+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:18:02.143+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:18:02.144+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:18:02.145+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:18:02.146+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:18:02.147+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:18:02.149+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:18:02.151+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:18:02.153+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:18:02.155+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:18:02.156+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:18:02.158+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:18:02.159+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:18:02.160+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:18:02.161+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:18:02.162+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:18:02.163+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:18:02.164+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:18:02.165+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:02.167+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:18:02.169+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:18:02.170+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:18:02.171+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:18:02.172+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:18:02.173+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:02.175+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:18:02.177+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:18:02.179+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:02.180+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:18:02.181+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:18:02.182+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:02.184+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:02.185+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:02.186+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:02.188+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:18:02.189+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:18:02.191+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:18:02.193+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:18:02.194+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:18:02.195+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:18:02.196+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:18:02.197+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:18:02.198+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:02.200+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:02.201+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:18:02.204+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:18:02.205+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:18:02.206+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:02.207+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:02.208+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:02.210+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:18:02.211+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:02.212+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:02.213+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:18:02.215+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:02.216+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:02.218+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:02.220+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:02.221+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:02.223+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:18:02.225+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:02.226+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:18:02.227+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:18:02.229+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:02.230+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:02.231+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:02.233+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:02.234+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:02.235+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:18:02.237+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:02.239+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:18:02.240+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:18:02.242+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:02.243+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:02.244+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:02.246+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:02.247+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:02.248+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:18:02.250+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:02.251+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:18:02.252+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:18:02.254+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:18:02.255+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:02.256+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:02.257+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:18:02.259+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:18:02.260+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:18:02.262+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:02.263+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:02.264+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:02.265+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:02.266+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:02.267+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:18:02.268+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:18:02.270+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:18:02.271+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:18:02.272+0000] {subprocess.py:106} INFO - org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:18:02.273+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:02.275+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:02.276+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:02.278+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:18:02.279+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:18:02.280+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:18:02.281+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:02.283+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:02.284+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:02.288+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:18:02.289+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:02.291+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:02.292+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:18:02.293+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:18:02.294+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:18:02.295+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:18:02.296+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:18:02.297+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:18:02.299+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:18:02.301+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:18:02.302+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:02.304+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:02.306+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:02.307+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:02.307+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:02.308+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:18:02.310+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:18:02.311+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:18:02.312+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:18:02.313+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:18:02.314+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:18:02.315+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:18:02.316+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:02.318+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:02.319+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:02.320+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:02.321+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:18:02.322+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:02.323+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:18:02.325+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:18:02.326+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:18:02.328+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:18:02.329+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:18:02.331+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:18:02.332+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:18:02.336+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:18:02.337+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:18:02.339+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:18:02.340+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:18:02.341+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:18:02.343+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:18:02.343+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:18:02.345+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:18:02.346+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:18:02.348+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)
[2025-04-02T09:18:02.353+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:18:02.355+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:02.356+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:02.358+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:02.359+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:02.361+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:18:02.362+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:18:02.363+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:18:02.364+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:18:02.367+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:18:02.368+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:18:02.370+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:18:02.371+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:02.372+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:02.374+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:02.376+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:02.377+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:02.378+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:18:02.380+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:18:02.381+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:18:02.383+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:18:02.385+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:18:02.386+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:18:02.388+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:18:02.390+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:18:02.391+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:18:02.392+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:18:02.394+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:18:02.396+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:02.397+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:18:02.399+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:18:02.400+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:18:02.401+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:18:02.404+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:18:02.405+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:02.407+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:02.408+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:18:02.410+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:02.411+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:18:02.412+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:18:02.413+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:18:02.414+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:18:02.416+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:18:02.417+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:18:02.419+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:18:02.423+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:18:02.424+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:18:02.426+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:18:02.427+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:18:02.429+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:18:02.431+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:18:02.432+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:18:02.434+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:18:02.435+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:18:02.437+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:18:02.438+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:02.440+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:02.441+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:02.442+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:02.444+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:18:02.446+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:18:02.447+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:18:02.449+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:18:02.450+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:18:02.452+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:02.454+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:02.455+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:02.457+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:02.458+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:18:02.459+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:18:02.461+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:18:02.463+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:18:02.465+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:18:02.466+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:18:02.468+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:18:02.469+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:18:02.470+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:18:02.472+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:18:02.474+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:18:02.475+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:18:02.477+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:18:02.478+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:18:02.480+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:18:02.481+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:18:02.482+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:18:02.484+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:18:02.488+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:18:02.490+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:18:02.491+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:18:02.492+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:18:02.494+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:18:02.495+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:18:02.497+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:18:02.500+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:18:02.502+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:02.503+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:18:02.506+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:18:02.508+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:18:02.509+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:18:02.510+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:18:02.513+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:02.516+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:18:02.519+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:18:02.521+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:02.523+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:18:02.524+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:18:02.527+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:02.528+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:02.530+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:02.532+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:02.535+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:18:02.538+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:18:02.556+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:18:02.568+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:18:02.570+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:18:02.573+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:18:02.575+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:18:02.577+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:18:02.579+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:02.580+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:02.581+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:18:02.582+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:18:02.583+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:18:02.585+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:02.586+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:02.587+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:02.588+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:18:02.590+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:02.591+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:02.592+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:18:02.593+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:02.594+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:02.595+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:02.597+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:02.599+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:02.602+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:18:02.603+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:02.604+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:18:02.605+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:18:02.606+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:02.608+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:02.609+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:02.611+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:02.612+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:02.613+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:18:02.614+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:02.616+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:18:02.618+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:18:02.619+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:02.620+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:02.621+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:02.623+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:02.624+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:02.626+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:18:02.627+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:02.628+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:18:02.629+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:18:02.631+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:18:02.633+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:02.634+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:02.636+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:18:02.637+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:18:02.640+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:18:02.641+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:02.642+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:02.644+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:02.646+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:02.647+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:02.648+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:18:02.649+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:18:02.651+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:18:02.652+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:18:02.654+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)
[2025-04-02T09:18:02.656+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:18:02.658+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:02.659+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:02.661+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:02.662+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:02.664+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:02.665+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:18:02.666+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:18:02.667+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:18:02.668+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:18:02.670+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:18:02.671+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:18:02.673+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:18:02.674+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:02.675+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:02.677+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:02.679+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:02.681+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:18:02.682+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:02.684+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:18:02.685+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:18:02.688+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:18:02.690+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:18:02.692+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:18:02.694+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:18:02.695+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:18:02.697+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:18:02.698+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:18:02.701+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:18:02.702+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:18:02.705+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:18:02.706+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:18:02.708+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:18:02.710+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:18:02.711+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:18:02.713+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)
[2025-04-02T09:18:02.714+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:18:02.716+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:02.718+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:02.719+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:02.720+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:02.722+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:18:02.725+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:18:02.727+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:18:02.728+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:18:02.729+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:18:02.731+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:18:02.733+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:18:02.734+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:02.736+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:02.739+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:02.741+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:02.744+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:02.746+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:18:02.748+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:18:02.750+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:18:02.752+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:18:02.753+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:18:02.755+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:18:02.757+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:18:02.759+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:18:02.760+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:18:02.761+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:18:02.762+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:18:02.764+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:02.766+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:18:02.767+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:18:02.768+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:18:02.770+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:18:02.772+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:18:02.773+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:02.774+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:02.777+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:18:02.779+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:02.781+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:18:02.783+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:18:02.787+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:18:02.789+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:18:02.790+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:18:02.792+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:18:02.793+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:18:02.795+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:18:02.796+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:18:02.797+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:18:02.798+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:18:02.799+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:18:02.801+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:18:02.802+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:18:02.804+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:18:02.806+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:18:02.808+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:18:02.809+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:02.811+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:02.812+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:02.813+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:02.815+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:18:02.816+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:18:02.818+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:18:02.819+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:18:02.821+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:18:02.823+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:02.825+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:02.826+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:02.828+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:02.829+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:18:02.830+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:18:02.832+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:18:02.834+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:18:02.835+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:18:02.837+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:18:02.840+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:18:02.841+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:18:02.842+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:18:02.843+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:18:02.846+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:18:02.847+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:18:02.850+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:18:02.852+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:18:02.853+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:18:02.856+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:18:02.857+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:18:02.858+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:18:02.860+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:18:02.862+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:18:02.863+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:18:02.865+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:18:02.867+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:18:02.868+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:18:02.871+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:18:02.874+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:18:02.876+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:02.879+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:18:02.883+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:18:02.886+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:18:02.889+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:18:02.892+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:18:02.894+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:02.898+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:18:02.901+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:18:02.904+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:02.906+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:18:02.908+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:18:02.910+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:02.912+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:02.913+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:02.916+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:02.918+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:18:02.921+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:18:02.922+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:18:02.923+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:18:02.925+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:18:02.926+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:18:02.929+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:18:02.931+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:18:02.932+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:18:02.935+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:02.936+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:02.938+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:02.939+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:18:02.940+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:18:02.942+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:18:02.943+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:02.944+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:02.946+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:02.947+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:18:02.948+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:02.950+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:02.952+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:18:02.953+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:18:02.954+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:18:02.956+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:18:02.957+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:18:02.958+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:18:02.959+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:18:02.960+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:18:02.961+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:02.963+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:02.965+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:02.969+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:02.971+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:02.973+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:18:02.975+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:18:02.976+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:18:02.978+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:18:02.979+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:18:02.980+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:18:02.981+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:18:02.982+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:02.984+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:02.985+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:02.987+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:02.989+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:18:02.991+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:02.992+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:18:02.994+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:18:02.996+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:18:02.998+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:18:03.001+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:18:03.007+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:18:03.010+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:18:03.011+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:18:03.012+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:18:03.013+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:18:03.016+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:18:03.018+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:18:03.019+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:18:03.020+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:18:03.021+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:18:03.022+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:18:03.024+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)
[2025-04-02T09:18:03.025+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:18:03.028+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:03.029+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:03.030+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:03.031+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:03.033+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:18:03.035+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:18:03.037+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:18:03.039+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:18:03.040+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:18:03.042+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:18:03.043+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:18:03.045+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:03.048+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:03.049+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:03.050+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:03.052+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:03.054+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:18:03.056+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:18:03.057+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:18:03.058+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:18:03.059+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:18:03.061+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:18:03.062+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:18:03.063+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:18:03.064+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:18:03.065+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:18:03.066+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:18:03.068+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:03.069+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:18:03.071+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:18:03.073+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:18:03.074+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:18:03.076+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:18:03.077+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:03.078+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:03.080+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:18:03.083+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:03.086+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:18:03.088+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:18:03.089+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:18:03.090+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:18:03.092+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:18:03.093+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:18:03.095+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:18:03.096+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:18:03.097+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:18:03.099+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:18:03.101+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:18:03.102+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:18:03.104+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:18:03.105+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:18:03.107+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:18:03.109+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:18:03.110+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:18:03.111+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:03.112+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:03.113+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:03.114+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:03.116+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:18:03.117+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:18:03.118+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:18:03.119+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:18:03.120+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:18:03.121+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:03.122+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:03.124+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:03.126+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:03.127+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:18:03.128+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:18:03.130+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:18:03.132+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:18:03.134+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:18:03.135+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:18:03.136+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:18:03.137+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:18:03.139+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:18:03.141+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:18:03.143+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:18:03.144+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:18:03.145+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:18:03.146+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:18:03.148+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:18:03.150+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:18:03.151+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:18:03.152+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:18:03.154+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:18:03.155+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:18:03.156+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:18:03.157+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:18:03.158+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:18:03.160+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:18:03.161+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:18:03.162+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:18:03.163+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:03.165+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:18:03.167+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:18:03.168+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:18:03.169+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:18:03.171+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:18:03.173+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:03.174+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:18:03.175+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:18:03.177+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:03.177+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:18:03.179+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:18:03.180+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:03.182+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:03.184+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:03.185+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:03.186+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:18:03.188+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:18:03.190+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:18:03.191+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:18:03.192+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:18:03.194+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:18:03.195+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:18:03.197+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:18:03.199+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:03.201+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:03.202+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:18:03.203+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:18:03.205+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:18:03.207+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:03.208+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:03.212+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:03.214+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:18:03.219+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:03.220+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:03.222+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:18:03.223+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:03.225+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:03.228+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:03.229+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:03.232+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:03.234+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:18:03.235+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:03.236+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:18:03.238+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:18:03.239+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:03.240+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:03.242+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:03.243+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:03.244+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:03.246+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:18:03.248+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:03.249+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:18:03.251+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:18:03.253+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:03.254+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:03.255+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:03.257+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:03.258+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:03.260+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:18:03.261+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:03.262+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:18:03.264+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:18:03.265+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:18:03.266+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:03.267+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:03.268+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:18:03.269+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:18:03.270+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:18:03.271+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:03.272+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:03.273+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:03.274+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:03.275+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:03.278+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:18:03.279+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:18:03.281+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:18:03.282+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:18:03.283+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:03.284+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:03.285+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:03.288+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:03.291+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:03.293+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)
[2025-04-02T09:18:03.294+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)
[2025-04-02T09:18:03.296+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:18:03.298+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:18:03.299+0000] {subprocess.py:106} INFO - 	... 154 more
[2025-04-02T09:18:03.301+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:03.303+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:03.305+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:03.306+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:18:03.307+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:18:03.309+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:18:03.310+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:03.312+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:03.313+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:03.315+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:18:03.316+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:03.318+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:03.319+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:18:03.321+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:18:03.323+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:18:03.325+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:18:03.326+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:18:03.327+0000] {subprocess.py:106} INFO - 	... 156 more
[2025-04-02T09:18:03.328+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:03.330+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:03.331+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:18:03.332+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:18:03.333+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:18:03.335+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:03.337+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:03.338+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:03.339+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:18:03.341+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:03.342+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:03.343+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:18:03.344+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:03.345+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:03.346+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:03.347+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:03.348+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:03.349+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:18:03.351+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:03.352+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:18:03.354+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:18:03.355+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:03.356+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:03.358+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:03.359+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:03.360+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:03.363+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:18:03.364+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:03.366+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:18:03.367+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:18:03.371+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:03.372+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:03.374+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:03.375+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:03.376+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:03.378+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:18:03.379+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:03.381+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:18:03.383+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:18:03.385+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:18:03.387+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:03.389+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:03.390+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:18:03.392+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:18:03.393+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:18:03.395+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:03.396+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:03.397+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:03.399+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:03.402+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:03.403+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:18:03.405+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:18:03.407+0000] {subprocess.py:106} INFO - Nested Throwables StackTrace:
[2025-04-02T09:18:03.408+0000] {subprocess.py:106} INFO - java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:18:03.409+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:03.412+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:03.413+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:03.415+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:18:03.417+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:18:03.418+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:18:03.420+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:03.422+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:03.424+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:03.426+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:18:03.428+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:03.429+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:03.431+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:18:03.432+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:18:03.434+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:18:03.435+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:18:03.436+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:18:03.438+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:18:03.439+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:18:03.440+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:18:03.441+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:03.442+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:03.443+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:03.446+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:03.447+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:03.448+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:18:03.448+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:18:03.450+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:18:03.451+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:18:03.453+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:18:03.455+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:18:03.456+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:18:03.457+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:03.459+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:03.460+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:03.461+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:03.462+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:18:03.463+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:03.464+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:18:03.466+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:18:03.467+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:18:03.468+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:18:03.469+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:18:03.470+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:18:03.471+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:18:03.472+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:18:03.473+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:18:03.474+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:18:03.476+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:18:03.477+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:18:03.479+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:18:03.480+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:18:03.482+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:18:03.483+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:18:03.485+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)
[2025-04-02T09:18:03.486+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:18:03.487+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:03.488+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:03.490+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:03.493+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:03.495+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:18:03.496+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:18:03.498+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:18:03.500+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:18:03.501+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:18:03.502+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:18:03.503+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:18:03.504+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:03.506+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:03.508+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:03.510+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:03.511+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:03.518+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:18:03.522+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:18:03.524+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:18:03.525+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:18:03.527+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:18:03.528+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:18:03.530+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:18:03.533+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:18:03.534+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:18:03.536+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:18:03.537+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:18:03.538+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:03.540+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:18:03.541+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:18:03.542+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:18:03.543+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:18:03.545+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:18:03.546+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:03.548+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:03.551+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:18:03.553+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:03.554+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:18:03.556+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:18:03.558+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:18:03.560+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:18:03.562+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:18:03.564+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:18:03.566+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:18:03.568+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:18:03.569+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:18:03.571+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:18:03.574+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:18:03.575+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:18:03.576+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:18:03.577+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:18:03.578+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:18:03.579+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:18:03.581+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:18:03.582+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:03.586+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:03.587+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:03.588+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:03.590+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:18:03.591+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:18:03.592+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:18:03.593+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:18:03.594+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:18:03.598+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:03.599+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:03.602+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:03.604+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:03.606+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:18:03.609+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:18:03.610+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:18:03.611+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:18:03.612+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:18:03.614+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:18:03.617+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:18:03.618+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:18:03.620+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:18:03.622+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:18:03.623+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:18:03.624+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:18:03.626+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:18:03.627+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:18:03.628+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:18:03.629+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:18:03.630+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:18:03.633+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:18:03.639+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:18:03.642+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:18:03.644+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:18:03.645+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:18:03.646+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:18:03.650+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:18:03.654+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:18:03.657+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:18:03.660+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:03.663+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:18:03.665+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:18:03.667+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:18:03.669+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:18:03.672+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:18:03.675+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:03.678+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:18:03.679+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:18:03.681+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:03.685+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:18:03.687+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:18:03.689+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:03.690+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:03.692+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:03.696+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:03.697+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:18:03.699+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:18:03.701+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:18:03.702+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:18:03.703+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:18:03.704+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:18:03.706+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:18:03.707+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:18:03.708+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:03.709+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:03.710+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:18:03.710+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:18:03.711+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:18:03.712+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:03.714+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:03.715+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:03.716+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:18:03.719+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:03.720+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:03.723+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:18:03.724+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:03.725+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:03.726+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:03.727+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:03.729+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:03.730+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:18:03.732+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:03.734+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:18:03.735+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:18:03.739+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:03.740+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:03.741+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:03.743+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:03.744+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:03.746+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:18:03.748+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:03.749+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:18:03.750+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:18:03.752+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:03.753+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:03.755+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:03.757+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:03.758+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:03.760+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:18:03.761+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:03.763+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:18:03.764+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:18:03.766+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:18:03.767+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:03.768+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:03.770+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:18:03.772+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:18:03.774+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:18:03.776+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:03.777+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:03.778+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:03.779+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:03.781+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:03.783+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:18:03.784+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:18:03.785+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:18:03.787+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:18:03.788+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:03.789+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:03.792+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:03.793+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:03.795+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:03.796+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)
[2025-04-02T09:18:03.797+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)
[2025-04-02T09:18:03.799+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:18:03.801+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:18:03.803+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:18:03.806+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:03.808+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:03.809+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:03.811+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:03.813+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:03.814+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:18:03.815+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:18:03.816+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:18:03.818+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:18:03.819+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:18:03.821+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:18:03.822+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:18:03.823+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:03.824+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:03.825+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:03.826+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:03.828+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:18:03.829+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:03.830+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:18:03.831+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:18:03.833+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:18:03.834+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:18:03.835+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:18:03.836+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:18:03.837+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:18:03.838+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:18:03.839+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:18:03.841+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:18:03.842+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:18:03.843+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:18:03.844+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:18:03.845+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:18:03.846+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:18:03.847+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:18:03.848+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)
[2025-04-02T09:18:03.850+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:18:03.851+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:03.853+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:03.853+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:03.856+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:03.857+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:18:03.858+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:18:03.859+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:18:03.860+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:18:03.862+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:18:03.864+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:18:03.865+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:18:03.866+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:03.867+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:03.868+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:03.870+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:03.871+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:03.872+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:18:03.873+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:18:03.875+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:18:03.876+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:18:03.877+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:18:03.879+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:18:03.880+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:18:03.881+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:18:03.882+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:18:03.884+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:18:03.885+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:18:03.887+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:03.889+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:18:03.890+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:18:03.892+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:18:03.893+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:18:03.894+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:18:03.895+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:03.898+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:03.905+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:18:03.907+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:03.913+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:18:03.918+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:18:03.930+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:18:03.932+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:18:03.933+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:18:03.934+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:18:03.936+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:18:03.938+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:18:03.941+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:18:03.944+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:18:03.945+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:18:03.948+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:18:03.949+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:18:03.951+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:18:03.953+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:18:03.955+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:18:03.957+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:18:03.959+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:03.960+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:03.962+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:03.965+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:03.967+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:18:03.968+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:18:03.971+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:18:03.975+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:18:03.976+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:18:03.979+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:03.980+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:03.983+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:03.985+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:03.986+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:18:03.987+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:18:03.989+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:18:03.991+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:18:03.992+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:18:03.993+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:18:03.994+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:18:03.995+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:18:03.996+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:18:03.997+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:18:03.999+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:18:04.000+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:18:04.002+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:18:04.003+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:18:04.004+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:18:04.006+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:18:04.008+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:18:04.009+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:18:04.011+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:18:04.013+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:18:04.015+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:18:04.016+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:18:04.018+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:18:04.020+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:18:04.022+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:18:04.023+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:18:04.025+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:04.026+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:18:04.027+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:18:04.029+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:18:04.030+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:18:04.032+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:18:04.034+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:04.035+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:18:04.037+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:18:04.039+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:04.040+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:18:04.041+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:18:04.043+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:04.044+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:04.045+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:04.047+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:04.048+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:18:04.051+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:18:04.053+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:18:04.055+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:18:04.057+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:18:04.059+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:18:04.062+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:18:04.063+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:18:04.064+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:04.065+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:04.066+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:04.068+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:18:04.069+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:18:04.071+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:18:04.072+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:04.074+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:04.075+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:04.076+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:18:04.078+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:04.079+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:04.080+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:18:04.081+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:18:04.083+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:18:04.084+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:18:04.085+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:18:04.086+0000] {subprocess.py:106} INFO - 	... 156 more
[2025-04-02T09:18:04.089+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:04.090+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:04.091+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:18:04.093+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:18:04.094+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:18:04.095+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:04.097+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:04.099+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:04.102+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:18:04.104+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:04.106+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:04.107+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:18:04.108+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:04.110+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:04.111+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:04.113+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:04.115+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:04.117+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:18:04.120+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:04.121+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:18:04.123+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:18:04.125+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:04.126+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:04.127+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:04.128+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:04.129+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:04.130+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:18:04.132+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:04.134+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:18:04.136+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:18:04.138+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:04.139+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:04.140+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:04.141+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:04.142+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:04.144+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:18:04.145+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:04.146+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:18:04.147+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:18:04.149+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:18:04.151+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:04.152+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:04.153+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:18:04.154+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:18:04.155+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:18:04.157+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:04.158+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:04.159+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:04.161+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:04.163+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:04.164+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:18:04.166+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:18:05.172+0000] {subprocess.py:106} INFO - 25/04/02 09:18:05 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
[2025-04-02T09:18:05.176+0000] {subprocess.py:106} INFO - 25/04/02 09:18:05 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
[2025-04-02T09:18:05.177+0000] {subprocess.py:106} INFO - 25/04/02 09:18:05 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
[2025-04-02T09:18:05.179+0000] {subprocess.py:106} INFO - 25/04/02 09:18:05 INFO ObjectStore: ObjectStore, initialize called
[2025-04-02T09:18:05.218+0000] {subprocess.py:106} INFO - 25/04/02 09:18:05 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
[2025-04-02T09:18:05.222+0000] {subprocess.py:106} INFO - 25/04/02 09:18:05 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
[2025-04-02T09:18:05.324+0000] {subprocess.py:106} INFO - 25/04/02 09:18:05 ERROR Schema: Failed initialising database.
[2025-04-02T09:18:05.326+0000] {subprocess.py:106} INFO - Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:18:05.327+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:05.328+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:05.330+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:05.331+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:18:05.332+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:18:05.333+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:18:05.336+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:05.337+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:05.338+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:05.339+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:18:05.340+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:05.340+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:05.341+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:18:05.342+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:18:05.343+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:18:05.344+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:18:05.345+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:18:05.346+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:18:05.347+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:18:05.349+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:18:05.350+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:05.352+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:05.354+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:05.355+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:05.356+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:05.357+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:18:05.358+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:18:05.360+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:18:05.362+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:18:05.364+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:18:05.366+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:18:05.368+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:18:05.370+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:05.371+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:05.373+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:05.374+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:05.375+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:18:05.376+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:05.378+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:18:05.379+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:18:05.380+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:18:05.381+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:18:05.382+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:18:05.384+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:18:05.386+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:18:05.387+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:18:05.388+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:18:05.389+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:18:05.390+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:18:05.391+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:18:05.392+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:18:05.393+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:18:05.394+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:18:05.395+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:18:05.397+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:18:05.398+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:18:05.400+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:05.401+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:05.402+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:05.404+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:05.405+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:18:05.406+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:18:05.407+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:18:05.409+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:18:05.410+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:18:05.411+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:18:05.412+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:18:05.413+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:05.414+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:05.415+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:05.416+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:05.418+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:05.420+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:18:05.421+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:18:05.422+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:18:05.423+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:18:05.424+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:18:05.425+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:18:05.426+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:18:05.427+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:18:05.429+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:18:05.431+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:18:05.433+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:18:05.434+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:05.437+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:18:05.438+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:18:05.440+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:18:05.442+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:18:05.443+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:18:05.444+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:05.444+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:05.445+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:18:05.446+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:05.447+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:18:05.449+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:18:05.450+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:18:05.451+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:18:05.452+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:18:05.454+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:18:05.455+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:18:05.456+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:18:05.457+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:18:05.458+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:18:05.459+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:18:05.460+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:18:05.461+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:18:05.462+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:18:05.464+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:18:05.465+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:18:05.466+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:18:05.467+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:05.468+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:05.469+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:05.470+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:05.471+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:18:05.473+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:18:05.474+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:18:05.475+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:18:05.478+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:18:05.480+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:05.481+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:05.485+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:05.486+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:05.489+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:18:05.490+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:18:05.491+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:18:05.493+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:18:05.494+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:18:05.496+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:18:05.496+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:18:05.497+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:18:05.498+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:18:05.499+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:18:05.500+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:18:05.502+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:18:05.503+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:18:05.504+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:18:05.505+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:18:05.506+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:18:05.507+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:18:05.508+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:18:05.509+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:18:05.511+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:18:05.512+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:18:05.513+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:18:05.514+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:18:05.515+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:18:05.516+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:18:05.518+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:18:05.519+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:05.520+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:18:05.522+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:18:05.523+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:18:05.524+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:18:05.525+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:18:05.526+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:05.527+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:18:05.528+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:18:05.529+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:05.530+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:18:05.531+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:18:05.532+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:05.535+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:05.536+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:05.538+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:05.539+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:18:05.540+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:18:05.541+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:18:05.542+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:18:05.543+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:18:05.545+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:18:05.546+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:18:05.547+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:18:05.548+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:05.549+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:05.550+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:18:05.551+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:18:05.553+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:18:05.554+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:05.555+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:05.556+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:05.557+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:18:05.559+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:05.559+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:05.561+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:18:05.562+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:05.563+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:05.564+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:05.565+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:05.567+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:05.569+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:18:05.570+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:05.571+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:18:05.572+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:18:05.573+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:05.573+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:05.574+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:05.575+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:05.576+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:05.577+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:18:05.578+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:05.579+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:18:05.580+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:18:05.581+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:05.582+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:05.584+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:05.585+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:05.586+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:05.587+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:18:05.591+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:05.592+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:18:05.593+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:18:05.594+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:18:05.596+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:05.598+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:05.600+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:18:05.601+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:18:05.605+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:18:05.606+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:05.608+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:05.609+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:05.611+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:05.612+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:05.613+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:18:05.615+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:18:05.616+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:18:05.618+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:18:05.620+0000] {subprocess.py:106} INFO - org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:18:05.621+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:05.623+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:05.624+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:05.625+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:18:05.626+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:18:05.627+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:18:05.628+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:05.629+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:05.630+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:05.631+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:18:05.632+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:05.633+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:05.635+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:18:05.636+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:18:05.637+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:18:05.638+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:18:05.641+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:18:05.643+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:18:05.645+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:18:05.648+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:18:05.650+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:05.653+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:05.658+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:05.660+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:05.662+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:05.664+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:18:05.666+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:18:05.669+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:18:05.672+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:18:05.675+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:18:05.678+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:18:05.681+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:18:05.684+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:05.688+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:05.691+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:05.694+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:05.697+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:18:05.700+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:05.702+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:18:05.705+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:18:05.707+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:18:05.708+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:18:05.710+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:18:05.711+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:18:05.713+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:18:05.715+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:18:05.716+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:18:05.718+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:18:05.719+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:18:05.721+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:18:05.722+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:18:05.723+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:18:05.724+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:18:05.726+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:18:05.728+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:18:05.729+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:18:05.730+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:05.732+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:05.733+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:05.735+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:05.737+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:18:05.738+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:18:05.739+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:18:05.740+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:18:05.741+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:18:05.743+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:18:05.744+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:18:05.745+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:05.746+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:05.747+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:05.749+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:05.751+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:05.752+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:18:05.759+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:18:05.761+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:18:05.763+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:18:05.764+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:18:05.766+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:18:05.768+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:18:05.769+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:18:05.770+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:18:05.772+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:18:05.773+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:18:05.775+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:05.777+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:18:05.779+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:18:05.781+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:18:05.783+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:18:05.785+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:18:05.787+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:05.789+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:05.791+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:18:05.792+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:05.794+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:18:05.796+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:18:05.797+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:18:05.799+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:18:05.801+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:18:05.803+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:18:05.804+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:18:05.805+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:18:05.807+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:18:05.809+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:18:05.811+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:18:05.812+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:18:05.813+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:18:05.816+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:18:05.817+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:18:05.819+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:18:05.820+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:18:05.822+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:05.823+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:05.825+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:05.827+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:05.823+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:18:05.824+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:18:05.826+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:18:05.828+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:18:05.830+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:18:05.832+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:05.833+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:05.835+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:05.836+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:05.837+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:18:05.838+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:18:05.840+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:18:05.841+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:18:05.845+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:18:05.848+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:18:05.850+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:18:05.851+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:18:05.853+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:18:05.854+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:18:05.855+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:18:05.857+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:18:05.859+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:18:05.862+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:18:05.863+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:18:05.864+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:18:05.865+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:18:05.867+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:18:05.868+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:18:05.869+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:18:05.870+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:18:05.871+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:18:05.872+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:18:05.874+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:18:05.875+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:18:05.876+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:18:05.879+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:05.881+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:18:05.883+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:18:05.884+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:18:05.886+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:18:05.887+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:18:05.889+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:05.891+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:18:05.892+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:18:05.894+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:05.895+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:18:05.896+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:18:05.898+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:05.899+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:05.900+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:05.902+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:05.904+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:18:05.905+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:18:05.907+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:18:05.908+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:18:05.910+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:18:05.911+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:18:05.912+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:18:05.916+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:18:05.918+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:05.919+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:05.920+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:18:05.921+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:18:05.922+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:18:05.923+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:05.924+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:05.925+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:05.927+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:18:05.928+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:05.930+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:05.931+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:18:05.932+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:05.934+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:05.935+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:05.936+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:05.937+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:05.939+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:18:05.940+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:05.941+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:18:05.943+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:18:05.944+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:05.946+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:05.948+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:05.949+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:05.950+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:05.954+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:18:05.955+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:05.957+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:18:05.959+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:18:05.961+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:05.962+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:05.964+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:05.965+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:05.966+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:05.968+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:18:05.969+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:05.970+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:18:05.971+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:18:05.972+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:18:05.973+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:05.974+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:05.976+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:18:05.977+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:18:05.978+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:18:05.979+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:05.981+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:05.983+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:05.984+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:05.987+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:05.989+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:18:05.990+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:18:05.991+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:18:05.995+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:18:05.996+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)
[2025-04-02T09:18:05.997+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:18:05.998+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:06.001+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:06.003+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:06.006+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:06.007+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:06.009+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:18:06.012+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:18:06.015+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:18:06.018+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:18:06.020+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:18:06.021+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:18:06.022+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:18:06.024+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:06.026+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:06.028+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:06.032+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:06.033+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:18:06.035+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:06.036+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:18:06.037+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:18:06.038+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:18:06.039+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:18:06.041+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:18:06.043+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:18:06.045+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:18:06.047+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:18:06.048+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:18:06.050+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:18:06.051+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:18:06.053+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:18:06.054+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:18:06.055+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:18:06.056+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:18:06.057+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:18:06.058+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:18:06.061+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:18:06.062+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:06.064+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:06.065+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:06.068+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:06.070+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:18:06.071+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:18:06.072+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:18:06.073+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:18:06.075+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:18:06.078+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:18:06.079+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:18:06.081+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:06.083+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:06.085+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:06.089+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:06.090+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:06.092+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:18:06.094+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:18:06.095+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:18:06.096+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:18:06.097+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:18:06.098+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:18:06.100+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:18:06.102+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:18:06.103+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:18:06.105+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:18:06.107+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:18:06.109+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:06.113+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:18:06.115+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:18:06.117+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:18:06.119+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:18:06.120+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:18:06.123+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:06.127+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:06.129+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:18:06.130+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:06.132+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:18:06.133+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:18:06.136+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:18:06.137+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:18:06.140+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:18:06.147+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:18:06.152+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:18:06.158+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:18:06.162+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:18:06.166+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:18:06.170+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:18:06.174+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:18:06.177+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:18:06.181+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:18:06.183+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:18:06.186+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:18:06.187+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:18:06.188+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:06.190+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:06.191+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:06.193+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:06.194+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:18:06.197+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:18:06.199+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:18:06.201+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:18:06.202+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:18:06.204+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:06.207+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:06.211+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:06.214+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:06.216+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:18:06.219+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:18:06.221+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:18:06.224+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:18:06.227+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:18:06.228+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:18:06.232+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:18:06.234+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:18:06.236+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:18:06.238+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:18:06.240+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:18:06.242+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:18:06.243+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:18:06.246+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:18:06.252+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:18:06.257+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:18:06.259+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:18:06.264+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:18:06.267+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:18:06.269+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:18:06.273+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:18:06.274+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:18:06.276+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:18:06.279+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:18:06.280+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:18:06.282+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:18:06.284+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:06.285+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:18:06.286+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:18:06.288+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:18:06.290+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:18:06.292+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:18:06.294+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:06.296+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:18:06.298+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:18:06.300+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:06.301+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:18:06.302+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:18:06.304+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:06.305+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:06.306+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:06.307+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:06.308+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:18:06.310+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:18:06.312+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:18:06.315+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:18:06.318+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:18:06.320+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:18:06.322+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:18:06.324+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:18:06.326+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:18:06.328+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:06.330+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:06.333+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:06.334+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:18:06.335+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:18:06.337+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:18:06.338+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:06.341+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:06.342+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:06.343+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:18:06.346+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:06.349+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:06.350+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:18:06.351+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:18:06.353+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:18:06.354+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:18:06.357+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:18:06.359+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:18:06.363+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:18:06.364+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:18:06.367+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:06.369+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:06.372+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:06.374+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:06.376+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:06.377+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:18:06.379+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:18:06.380+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:18:06.381+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:18:06.383+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:18:06.385+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:18:06.387+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:18:06.389+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:06.390+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:06.393+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:06.395+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:06.396+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:18:06.398+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:06.399+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:18:06.401+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:18:06.402+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:18:06.403+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:18:06.404+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:18:06.405+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:18:06.406+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:18:06.408+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:18:06.410+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:18:06.411+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:18:06.413+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:18:06.415+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:18:06.416+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:18:06.417+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:18:06.418+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:18:06.420+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:18:06.421+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:18:06.422+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:18:06.424+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:06.425+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:06.428+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:06.429+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:06.430+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:18:06.433+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:18:06.435+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:18:06.437+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:18:06.439+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:18:06.440+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:18:06.442+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:18:06.444+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:06.447+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:06.449+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:06.451+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:06.452+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:06.454+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:18:06.455+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:18:06.456+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:18:06.458+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:18:06.460+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:18:06.462+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:18:06.464+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:18:06.466+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:18:06.467+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:18:06.469+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:18:06.471+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:18:06.473+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:06.476+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:18:06.478+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:18:06.481+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:18:06.483+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:18:06.484+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:18:06.485+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:06.487+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:06.489+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:18:06.491+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:06.495+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:18:06.496+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:18:06.500+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:18:06.502+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:18:06.504+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:18:06.505+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:18:06.507+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:18:06.509+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:18:06.512+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:18:06.515+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:18:06.517+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:18:06.519+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:18:06.521+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:18:06.522+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:18:06.525+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:18:06.535+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:18:06.542+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:18:06.546+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:06.553+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:06.562+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:06.566+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:06.571+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:18:06.575+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:18:06.579+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:18:06.588+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:18:06.593+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:18:06.596+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:06.600+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:06.602+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:06.603+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:06.604+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:18:06.605+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:18:06.607+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:18:06.610+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:18:06.611+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:18:06.612+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:18:06.614+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:18:06.617+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:18:06.619+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:18:06.620+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:18:06.621+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:18:06.623+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:18:06.624+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:18:06.626+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:18:06.629+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:18:06.631+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:18:06.632+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:18:06.634+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:18:06.635+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:18:06.636+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:18:06.637+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:18:06.639+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:18:06.641+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:18:06.642+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:18:06.643+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:18:06.646+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:18:06.649+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:06.651+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:18:06.654+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:18:06.657+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:18:06.659+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:18:06.665+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:18:06.669+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:06.672+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:18:06.675+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:18:06.678+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:06.682+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:18:06.686+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:18:06.687+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:06.690+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:06.694+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:06.696+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:06.698+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:18:06.699+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:18:06.701+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:18:06.702+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:18:06.705+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:18:06.707+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:18:06.709+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:18:06.712+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:18:06.714+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:06.716+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:06.718+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:18:06.720+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:18:06.721+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:18:06.722+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:06.723+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:06.725+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:06.726+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:18:06.730+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:06.731+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:06.734+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:18:06.737+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:06.738+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:06.740+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:06.745+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:06.746+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:06.753+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:18:06.755+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:06.756+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:18:06.758+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:18:06.759+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:06.762+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:06.765+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:06.768+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:06.770+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:06.772+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:18:06.774+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:06.775+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:18:06.779+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:18:06.782+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:06.784+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:06.787+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:06.788+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:06.790+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:06.793+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:18:06.794+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:06.796+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:18:06.799+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:18:06.801+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:18:06.803+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:06.806+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:06.808+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:18:06.810+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:18:06.811+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:18:06.813+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:06.814+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:06.819+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:06.822+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:06.827+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:06.830+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:18:06.834+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:18:06.837+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:18:06.839+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:18:06.842+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:06.844+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:06.847+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:06.852+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:06.855+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:06.861+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)
[2025-04-02T09:18:06.866+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)
[2025-04-02T09:18:06.873+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:18:06.876+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:18:06.880+0000] {subprocess.py:106} INFO - 	... 154 more
[2025-04-02T09:18:06.887+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:06.898+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:06.907+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:06.913+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:18:06.917+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:18:06.921+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:18:06.924+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:06.928+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:06.929+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:06.932+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:18:06.934+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:06.936+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:06.937+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:18:06.938+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:18:06.939+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:18:06.941+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:18:06.943+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:18:06.945+0000] {subprocess.py:106} INFO - 	... 156 more
[2025-04-02T09:18:06.947+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:06.950+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:06.952+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:18:06.955+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:18:06.958+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:18:06.961+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:06.964+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:06.969+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:06.973+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:18:06.976+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:06.977+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:06.983+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:18:06.985+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:06.990+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:06.992+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:06.995+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:07.000+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:07.002+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:18:07.005+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:07.009+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:18:07.014+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:18:07.015+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:07.017+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:07.018+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:07.019+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:07.021+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:07.023+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:18:07.025+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:07.027+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:18:07.028+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:18:07.030+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:07.032+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:07.034+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:07.036+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:07.037+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:07.040+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:18:07.042+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:07.043+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:18:07.046+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:18:07.050+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:18:07.052+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:07.054+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:07.056+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:18:07.058+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:18:07.061+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:18:07.063+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:07.065+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:07.066+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:07.068+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:07.071+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:07.074+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:18:07.075+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:18:07.077+0000] {subprocess.py:106} INFO - Nested Throwables StackTrace:
[2025-04-02T09:18:07.079+0000] {subprocess.py:106} INFO - java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:18:07.082+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:07.085+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:07.087+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:07.089+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:18:07.091+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:18:07.093+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:18:07.094+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:07.096+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:07.098+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:07.099+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:18:07.102+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:07.103+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:07.104+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:18:07.106+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:18:07.109+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:18:07.111+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:18:07.112+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:18:07.114+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:18:07.116+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:18:07.118+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:18:07.119+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:07.120+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:07.121+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:07.122+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:07.123+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:07.124+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:18:07.127+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:18:07.130+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:18:07.132+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:18:07.133+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:18:07.134+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:18:07.136+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:18:07.137+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:07.139+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:07.140+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:07.142+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:07.143+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:18:07.144+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:07.145+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:18:07.146+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:18:07.148+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:18:07.149+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:18:07.151+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:18:07.152+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:18:07.154+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:18:07.155+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:18:07.157+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:18:07.158+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:18:07.159+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:18:07.160+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:18:07.161+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:18:07.163+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:18:07.164+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:18:07.165+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:18:07.166+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:18:07.167+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:18:07.168+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:07.170+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:07.171+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:07.172+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:07.173+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:18:07.175+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:18:07.176+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:18:07.178+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:18:07.180+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:18:07.181+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:18:07.182+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:18:07.183+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:07.184+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:07.185+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:07.186+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:07.187+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:07.189+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:18:07.190+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:18:07.192+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:18:07.194+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:18:07.195+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:18:07.196+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:18:07.197+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:18:07.198+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:18:07.199+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:18:07.201+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:18:07.202+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:18:07.204+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:07.205+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:18:07.206+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:18:07.207+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:18:07.208+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:18:07.210+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:18:07.212+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:07.213+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:07.214+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:18:07.216+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:07.217+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:18:07.219+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:18:07.220+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:18:07.222+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:18:07.223+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:18:07.225+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:18:07.227+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:18:07.228+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:18:07.229+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:18:07.231+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:18:07.232+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:18:07.233+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:18:07.234+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:18:07.235+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:18:07.237+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:18:07.238+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:18:07.239+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:18:07.240+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:07.241+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:07.242+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:07.244+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:07.245+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:18:07.246+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:18:07.249+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:18:07.250+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:18:07.252+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:18:07.253+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:07.254+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:07.255+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:07.256+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:07.257+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:18:07.259+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:18:07.260+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:18:07.262+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:18:07.264+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:18:07.266+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:18:07.268+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:18:07.269+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:18:07.270+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:18:07.271+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:18:07.272+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:18:07.273+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:18:07.275+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:18:07.277+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:18:07.278+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:18:07.280+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:18:07.281+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:18:07.283+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:18:07.285+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:18:07.287+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:18:07.288+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:18:07.290+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:18:07.291+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:18:07.292+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:18:07.295+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:18:07.297+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:18:07.299+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:07.301+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:18:07.303+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:18:07.305+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:18:07.307+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:18:07.310+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:18:07.311+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:07.313+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:18:07.315+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:18:07.316+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:07.317+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:18:07.319+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:18:07.320+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:07.321+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:07.323+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:07.324+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:07.325+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:18:07.327+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:18:07.329+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:18:07.331+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:18:07.332+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:18:07.333+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:18:07.334+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:18:07.336+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:18:07.338+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:07.339+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:07.340+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:18:07.341+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:18:07.343+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:18:07.345+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:07.347+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:07.348+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:07.350+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:18:07.352+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:07.355+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:07.357+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:18:07.359+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:07.360+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:07.362+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:07.363+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:07.366+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:07.367+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:18:07.368+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:07.370+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:18:07.372+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:18:07.374+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:07.375+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:07.377+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:07.378+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:07.380+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:07.381+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:18:07.387+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:07.389+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:18:07.391+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:18:07.393+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:07.395+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:07.397+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:07.399+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:07.402+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:07.403+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:18:07.405+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:07.406+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:18:07.407+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:18:07.409+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:18:07.410+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:07.411+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:07.413+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:18:07.414+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:18:07.416+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:18:07.417+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:07.418+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:07.419+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:07.420+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:07.421+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:07.423+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:18:07.424+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:18:07.425+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:18:07.427+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:18:07.428+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:07.430+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:07.433+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:07.436+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:07.438+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:07.439+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)
[2025-04-02T09:18:07.442+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)
[2025-04-02T09:18:07.446+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:18:07.447+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:18:07.451+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:18:07.452+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:07.454+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:07.455+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:07.457+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:07.459+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:07.461+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:18:07.463+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:18:07.465+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:18:07.467+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:18:07.469+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:18:07.471+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:18:07.473+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:18:07.475+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:07.476+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:07.480+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:07.482+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:07.484+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:18:07.487+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:07.490+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:18:07.493+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:18:07.495+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:18:07.498+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:18:07.500+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:18:07.503+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:18:07.505+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:18:07.509+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:18:07.512+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:18:07.514+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:18:07.518+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:18:07.521+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:18:07.524+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:18:07.526+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:18:07.528+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:18:07.534+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:18:07.537+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:18:07.539+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:18:07.544+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:07.547+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:07.549+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:07.551+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:07.553+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:18:07.556+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:18:07.559+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:18:07.562+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:18:07.565+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:18:07.567+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:18:07.569+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:18:07.571+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:07.573+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:07.576+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:07.577+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:07.580+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:07.585+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:18:07.587+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:18:07.590+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:18:07.591+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:18:07.593+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:18:07.595+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:18:07.599+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:18:07.602+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:18:07.606+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:18:07.608+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:18:07.610+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:18:07.612+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:07.613+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:18:07.616+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:18:07.618+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:18:07.620+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:18:07.623+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:18:07.626+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:07.627+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:07.629+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:18:07.632+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:07.634+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:18:07.636+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:18:07.638+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:18:07.640+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:18:07.644+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:18:07.647+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:18:07.648+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:18:07.652+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:18:07.653+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:18:07.655+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:18:07.657+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:18:07.661+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:18:07.663+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:18:07.666+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:18:07.669+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:18:07.676+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:18:07.681+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:18:07.688+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:07.692+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:07.698+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:07.701+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:07.710+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:18:07.716+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:18:07.720+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:18:07.724+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:18:07.729+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:18:07.732+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:07.734+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:07.736+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:07.738+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:07.740+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:18:07.741+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:18:07.744+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:18:07.747+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:18:07.749+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:18:07.751+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:18:07.754+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:18:07.757+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:18:07.761+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:18:07.765+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:18:07.767+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:18:07.770+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:18:07.772+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:18:07.774+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:18:07.777+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:18:07.780+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:18:07.782+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:18:07.785+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:18:07.787+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:18:07.789+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:18:07.793+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:18:07.797+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:18:07.805+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:18:07.824+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:18:07.862+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:18:07.911+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:18:07.948+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:08.012+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:18:08.177+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:18:08.385+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:18:08.588+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:18:08.682+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:18:08.796+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:08.947+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:18:09.032+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:18:09.131+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:09.188+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:18:09.231+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:18:09.334+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:09.482+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:09.611+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:09.865+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:10.044+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:18:10.189+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:18:10.385+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:18:10.624+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:18:10.736+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:18:10.738+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:18:10.760+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:18:10.765+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:18:10.773+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:10.775+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:10.778+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:10.781+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:18:10.784+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:18:10.785+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:18:10.788+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:10.790+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:10.791+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:10.792+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:18:10.793+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:10.796+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:10.799+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:18:10.801+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:18:10.803+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:18:10.805+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:18:10.810+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:18:10.812+0000] {subprocess.py:106} INFO - 	... 156 more
[2025-04-02T09:18:10.814+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:10.816+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:10.818+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:18:10.819+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:18:10.821+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:18:10.824+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:10.826+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:10.828+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:10.832+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:18:10.833+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:10.835+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:10.839+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:18:10.841+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:10.843+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:10.845+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:10.847+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:10.848+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:10.850+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:18:10.852+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:10.854+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:18:10.856+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:18:10.858+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:10.860+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:10.863+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:10.865+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:10.866+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:10.868+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:18:10.870+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:10.871+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:18:10.873+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:18:10.874+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:10.876+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:10.878+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:10.880+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:10.882+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:10.883+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:18:10.885+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:10.887+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:18:10.890+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:18:10.892+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:18:10.894+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:10.896+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:10.899+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:18:10.901+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:18:10.903+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:18:10.904+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:10.907+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:10.909+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:10.910+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:10.912+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:10.914+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:18:10.916+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:18:10.920+0000] {subprocess.py:106} INFO - 25/04/02 09:18:06 ERROR Datastore: Exception thrown creating StoreManager. See the nested exception
[2025-04-02T09:18:10.924+0000] {subprocess.py:106} INFO - Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:18:10.925+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:10.930+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:10.932+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:10.933+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:18:10.934+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:18:10.936+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:18:10.937+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:10.938+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:10.941+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:10.943+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:18:10.947+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:10.949+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:10.951+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:18:10.952+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:18:10.954+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:18:10.955+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:18:10.956+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:18:10.958+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:18:10.962+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:18:10.963+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:18:10.965+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:10.968+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:10.969+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:10.970+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:10.971+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:10.972+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:18:10.975+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:18:10.977+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:18:10.979+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:18:10.980+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:18:10.983+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:18:10.985+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:18:10.986+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:10.988+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:10.994+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:10.997+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:11.000+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:18:11.002+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:11.004+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:18:11.006+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:18:11.009+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:18:11.012+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:18:11.013+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:18:11.015+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:18:11.016+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:18:11.017+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:18:11.018+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:18:11.019+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:18:11.021+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:18:11.023+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:18:11.025+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:18:11.028+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:18:11.031+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:18:11.034+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:18:11.036+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:18:11.039+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:18:11.040+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:11.043+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:11.047+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:11.048+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:11.050+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:18:11.052+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:18:11.054+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:18:11.056+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:18:11.058+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:18:11.061+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:18:11.064+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:18:11.066+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:11.069+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:11.074+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:11.077+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:11.079+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:11.082+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:18:11.084+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:18:11.087+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:18:11.088+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:18:11.095+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:18:11.097+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:18:11.098+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:18:11.100+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:18:11.102+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:18:11.104+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:18:11.106+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:18:11.108+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:11.110+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:18:11.111+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:18:11.115+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:18:11.117+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:18:11.118+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:18:11.119+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:11.121+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:11.123+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:18:11.124+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:11.126+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:18:11.128+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:18:11.132+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:18:11.136+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:18:11.139+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:18:11.143+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:18:11.145+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:18:11.147+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:18:11.149+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:18:11.150+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:18:11.152+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:18:11.154+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:18:11.155+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:18:11.156+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:18:11.157+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:18:11.158+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:18:11.159+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:18:11.161+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:11.162+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:11.163+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:11.164+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:11.169+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:18:11.170+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:18:11.172+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:18:11.174+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:18:11.175+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:18:11.179+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:11.182+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:11.184+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:11.185+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:11.188+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:18:11.189+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:18:11.190+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:18:11.191+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:18:11.194+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:18:11.196+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:18:11.199+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:18:11.201+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:18:11.202+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:18:11.204+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:18:11.206+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:18:11.208+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:18:11.209+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:18:11.212+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:18:11.215+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:18:11.216+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:18:11.220+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:18:11.223+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:18:11.225+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:18:11.229+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:18:11.234+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:18:11.236+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:18:11.247+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:18:11.249+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:18:11.252+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:18:11.254+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:18:11.255+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:11.257+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:18:11.259+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:18:11.263+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:18:11.266+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:18:11.267+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:18:11.269+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:11.272+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:18:11.278+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:18:11.282+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:11.290+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:18:11.293+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:18:11.294+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:11.295+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:11.297+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:11.299+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:11.307+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:18:11.308+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:18:11.310+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:18:11.314+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:18:11.320+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:18:11.322+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:18:11.324+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:18:11.326+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:18:11.328+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:11.331+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:11.334+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:18:11.337+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:18:11.340+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:18:11.341+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:11.349+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:11.353+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:11.356+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:18:11.361+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:11.364+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:11.366+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:18:11.369+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:11.370+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:11.371+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:11.373+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:11.374+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:11.376+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:18:11.379+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:11.380+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:18:11.383+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:18:11.387+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:11.391+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:11.394+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:11.396+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:11.397+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:11.399+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:18:11.401+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:11.405+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:18:11.407+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:18:11.410+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:11.411+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:11.416+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:11.418+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:11.421+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:11.427+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:18:11.434+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:11.440+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:18:11.442+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:18:11.446+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:18:11.450+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:11.453+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:11.454+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:18:11.460+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:18:11.467+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:18:11.469+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:11.473+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:11.479+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:11.486+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:11.490+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:11.492+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:18:11.495+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:18:11.503+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:18:11.509+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:18:11.511+0000] {subprocess.py:106} INFO - org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:18:11.558+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:11.609+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:11.679+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:11.697+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:18:11.701+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:18:11.704+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:18:11.706+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:11.709+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:11.714+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:11.722+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:18:11.737+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:11.743+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:11.744+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:18:11.747+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:18:11.748+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:18:11.752+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:18:11.756+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:18:11.762+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:18:11.765+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:18:11.768+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:18:11.769+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:11.772+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:11.775+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:11.777+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:11.779+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:11.783+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:18:11.786+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:18:11.790+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:18:11.793+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:18:11.796+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:18:11.799+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:18:11.800+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:18:11.802+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:11.806+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:11.808+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:11.812+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:11.813+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:18:11.815+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:11.819+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:18:11.826+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:18:11.830+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:18:11.834+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:18:11.839+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:18:11.843+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:18:11.847+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:18:11.851+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:18:11.858+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:18:11.863+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:18:11.868+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:18:11.871+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:18:11.873+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:18:11.882+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:18:11.884+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:18:11.889+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:18:11.892+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:18:11.900+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:18:11.902+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:11.906+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:11.910+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:11.913+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:11.918+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:18:11.921+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:18:11.925+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:18:11.927+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:18:11.933+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:18:11.938+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:18:11.940+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:18:11.942+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:11.945+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:11.947+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:11.949+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:11.951+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:11.953+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:18:11.956+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:18:11.957+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:18:11.960+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:18:11.962+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:18:11.967+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:18:11.969+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:18:11.971+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:18:11.974+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:18:11.977+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:18:11.978+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:18:11.981+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:11.989+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:18:11.993+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:18:11.994+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:18:12.000+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:18:12.006+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:18:12.008+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:12.011+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:12.014+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:18:12.018+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:12.020+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:18:12.027+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:18:12.030+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:18:12.033+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:18:12.035+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:18:12.038+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:18:12.041+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:18:12.043+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:18:12.045+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:18:12.047+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:18:12.049+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:18:12.051+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:18:12.053+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:18:12.054+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:18:12.055+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:18:12.056+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:18:12.058+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:18:12.061+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:12.066+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:12.070+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:12.074+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:12.076+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:18:12.081+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:18:12.083+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:18:12.085+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:18:12.090+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:18:12.094+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:12.099+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:12.100+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:12.102+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:12.107+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:18:12.110+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:18:12.113+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:18:12.115+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:18:12.119+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:18:12.122+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:18:12.125+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:18:12.129+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:18:12.134+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:18:12.146+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:18:12.155+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:18:12.160+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:18:12.166+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:18:12.171+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:18:12.178+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:18:12.181+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:18:12.185+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:18:12.187+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:18:12.192+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:18:12.207+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:18:12.214+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:18:12.219+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:18:12.225+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:18:12.231+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:18:12.235+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:18:12.246+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:18:12.252+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:12.258+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:18:12.261+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:18:12.263+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:18:12.265+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:18:12.269+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:18:12.272+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:12.275+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:18:12.277+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:18:12.279+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:12.282+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:18:12.284+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:18:12.285+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:12.286+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:12.288+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:12.291+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:12.293+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:18:12.295+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:18:12.298+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:18:12.302+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:18:12.309+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:18:12.311+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:18:12.314+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:18:12.317+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:18:12.319+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:12.322+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:12.324+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:18:12.326+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:18:12.328+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:18:12.331+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:12.333+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:12.334+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:12.335+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:18:12.337+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:12.338+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:12.340+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:18:12.342+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:12.343+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:12.344+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:12.345+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:12.347+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:12.348+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:18:12.349+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:12.351+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:18:12.352+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:18:12.354+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:12.355+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:12.357+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:12.359+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:12.361+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:12.363+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:18:12.364+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:12.366+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:18:12.368+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:18:12.370+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:12.373+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:12.375+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:12.378+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:12.383+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:12.385+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:18:12.386+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:12.388+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:18:12.390+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:18:12.393+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:18:12.395+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:12.396+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:12.398+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:18:12.399+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:18:12.401+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:18:12.402+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:12.404+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:12.407+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:12.409+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:12.411+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:12.412+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:18:12.414+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:18:12.415+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:18:12.420+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:18:12.423+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)
[2025-04-02T09:18:12.425+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:18:12.426+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:12.428+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:12.429+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:12.431+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:12.433+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:12.434+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:18:12.439+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:18:12.442+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:18:12.445+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:18:12.446+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:18:12.448+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:18:12.450+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:18:12.453+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:12.455+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:12.457+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:12.459+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:12.461+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:18:12.463+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:12.465+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:18:12.466+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:18:12.470+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:18:12.474+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:18:12.481+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:18:12.485+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:18:12.492+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:18:12.494+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:18:12.495+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:18:12.497+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:18:12.499+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:18:12.503+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:18:12.506+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:18:12.508+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:18:12.513+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:18:12.516+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:18:12.518+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:18:12.520+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:18:12.522+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:12.524+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:12.525+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:12.528+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:12.530+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:18:12.533+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:18:12.535+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:18:12.537+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:18:12.539+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:18:12.541+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:18:12.543+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:18:12.545+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:12.549+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:12.551+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:12.552+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:12.554+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:12.556+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:18:12.558+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:18:12.560+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:18:12.562+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:18:12.565+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:18:12.567+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:18:12.568+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:18:12.570+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:18:12.572+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:18:12.577+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:18:12.582+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:18:12.583+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:12.585+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:18:12.588+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:18:12.591+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:18:12.594+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:18:12.596+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:18:12.598+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:12.600+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:12.602+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:18:12.604+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:12.606+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:18:12.608+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:18:12.611+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:18:12.613+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:18:12.614+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:18:12.616+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:18:12.618+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:18:12.621+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:18:12.623+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:18:12.624+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:18:12.627+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:18:12.628+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:18:12.630+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:18:12.632+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:18:12.635+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:18:12.637+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:18:12.640+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:18:12.642+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:12.645+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:12.646+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:12.647+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:12.651+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:18:12.653+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:18:12.655+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:18:12.656+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:18:12.657+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:18:12.659+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:12.660+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:12.662+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:12.665+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:12.666+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:18:12.668+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:18:12.675+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:18:12.676+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:18:12.678+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:18:12.679+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:18:12.682+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:18:12.688+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:18:12.690+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:18:12.693+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:18:12.695+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:18:12.697+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:18:12.702+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:18:12.704+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:18:12.709+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:18:12.711+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:18:12.713+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:18:12.716+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:18:12.717+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:18:12.719+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:18:12.721+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:18:12.723+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:18:12.725+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:18:12.727+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:18:12.730+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:18:12.736+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:18:12.739+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:12.743+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:18:12.745+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:18:12.749+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:18:12.751+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:18:12.753+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:18:12.755+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:12.757+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:18:12.759+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:18:12.766+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:12.769+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:18:12.775+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:18:12.778+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:12.780+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:12.783+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:12.785+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:12.789+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:18:12.792+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:18:12.793+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:18:12.795+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:18:12.799+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:18:12.803+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:18:12.810+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:18:12.813+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:18:12.819+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:18:12.822+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:12.825+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:12.827+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:12.832+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:18:12.834+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:18:12.835+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:18:12.836+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:12.838+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:12.840+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:12.842+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:18:12.844+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:12.846+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:12.849+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:18:12.851+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:18:12.853+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:18:12.856+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:18:12.860+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:18:12.863+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:18:12.865+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:18:12.867+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:18:12.868+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:12.870+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:12.871+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:12.873+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:12.876+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:12.878+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:18:12.880+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:18:12.884+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:18:12.887+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:18:12.889+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:18:12.891+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:18:12.892+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:18:12.894+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:12.896+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:12.897+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:12.899+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:12.900+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:18:12.901+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:12.902+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:18:12.904+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:18:12.905+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:18:12.908+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:18:12.910+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:18:12.912+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:18:12.913+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:18:12.915+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:18:12.918+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:18:12.921+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:18:12.923+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:18:12.924+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:18:12.925+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:18:12.927+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:18:12.929+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:18:12.930+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:18:12.933+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:18:12.934+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:18:12.936+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:12.938+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:12.939+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:12.942+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:12.943+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:18:12.945+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:18:12.947+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:18:12.949+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:18:12.951+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:18:12.952+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:18:12.954+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:18:12.955+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:12.959+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:12.960+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:12.962+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:12.963+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:12.965+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:18:12.968+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:18:12.969+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:18:12.972+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:18:12.973+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:18:12.974+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:18:12.975+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:18:12.977+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:18:12.980+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:18:12.981+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:18:12.984+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:18:12.985+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:12.988+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:18:12.991+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:18:12.993+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:18:12.995+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:18:12.997+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:18:13.000+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:13.002+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:13.004+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:18:13.007+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:13.008+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:18:13.010+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:18:13.012+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:18:13.014+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:18:13.016+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:18:13.018+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:18:13.019+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:18:13.021+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:18:13.023+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:18:13.024+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:18:13.025+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:18:13.027+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:18:13.028+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:18:13.030+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:18:13.032+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:18:13.034+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:18:13.036+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:18:13.037+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:13.039+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:13.043+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:13.045+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:13.047+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:18:13.048+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:18:13.049+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:18:13.050+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:18:13.051+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:18:13.053+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:13.054+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:13.055+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:13.057+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:13.059+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:18:13.060+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:18:13.062+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:18:13.063+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:18:13.064+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:18:13.065+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:18:13.067+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:18:13.068+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:18:13.069+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:18:13.071+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:18:13.072+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:18:13.074+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:18:13.075+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:18:13.076+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:18:13.077+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:18:13.078+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:18:13.080+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:18:13.082+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:18:13.083+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:18:13.085+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:18:13.087+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:18:13.088+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:18:13.089+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:18:13.091+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:18:13.093+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:18:13.094+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:18:13.095+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:13.096+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:18:13.099+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:18:13.100+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:18:13.102+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:18:13.104+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:18:13.105+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:13.106+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:18:13.108+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:18:13.109+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:13.111+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:18:13.112+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:18:13.114+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:13.115+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:13.116+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:13.117+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:13.118+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:18:13.119+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:18:13.121+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:18:13.125+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:18:13.127+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:18:13.128+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:18:13.131+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:18:13.133+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:18:13.135+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:13.136+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:13.137+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:18:13.139+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:18:13.141+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:18:13.145+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:13.147+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:13.149+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:13.150+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:18:13.151+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:13.153+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:13.155+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:18:13.157+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:13.159+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:13.161+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:13.163+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:13.164+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:13.166+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:18:13.167+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:13.168+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:18:13.170+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:18:13.171+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:13.172+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:13.174+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:13.175+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:13.176+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:13.180+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:18:13.181+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:13.183+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:18:13.185+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:18:13.186+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:13.188+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:13.190+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:13.191+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:13.193+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:13.194+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:18:13.195+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:13.196+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:18:13.197+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:18:13.199+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:18:13.200+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:13.202+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:13.203+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:18:13.204+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:18:13.205+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:18:13.207+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:13.208+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:13.209+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:13.211+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:13.212+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:13.214+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:18:13.216+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:18:13.218+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:18:13.220+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:18:13.223+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:13.225+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:13.226+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:13.228+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:13.229+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:13.233+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)
[2025-04-02T09:18:13.235+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)
[2025-04-02T09:18:13.237+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:18:13.239+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:18:13.240+0000] {subprocess.py:106} INFO - 	... 154 more
[2025-04-02T09:18:13.241+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:13.243+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:13.244+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:13.247+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:18:13.249+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:18:13.251+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:18:13.253+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:13.255+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:13.259+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:13.261+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:18:13.262+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:13.265+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:13.266+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:18:13.268+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:18:13.269+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:18:13.270+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:18:13.272+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:18:13.274+0000] {subprocess.py:106} INFO - 	... 156 more
[2025-04-02T09:18:13.275+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:13.276+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:13.277+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:18:13.279+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:18:13.280+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:18:13.283+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:13.284+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:13.286+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:13.287+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:18:13.288+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:13.291+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:13.292+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:18:13.294+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:13.295+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:13.296+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:13.300+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:13.301+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:13.302+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:18:13.303+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:13.304+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:18:13.307+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:18:13.308+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:13.310+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:13.312+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:13.314+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:13.316+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:13.317+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:18:13.318+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:13.319+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:18:13.320+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:18:13.322+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:13.323+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:13.325+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:13.327+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:13.328+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:13.330+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:18:13.332+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:13.334+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:18:13.336+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:18:13.338+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:18:13.341+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:13.343+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:13.346+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:18:13.349+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:18:13.352+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:18:13.353+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:13.357+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:13.358+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:13.360+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:13.363+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:13.365+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:18:13.367+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:18:13.369+0000] {subprocess.py:106} INFO - Nested Throwables StackTrace:
[2025-04-02T09:18:13.371+0000] {subprocess.py:106} INFO - java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:18:13.373+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:13.374+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:13.377+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:13.382+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:18:13.384+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:18:13.389+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:18:13.395+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:13.396+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:13.400+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:13.401+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:18:13.404+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:13.406+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:13.408+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:18:13.412+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:18:13.415+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:18:13.419+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:18:13.423+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:18:13.432+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:18:13.433+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:18:13.437+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:18:13.442+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:13.444+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:13.450+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:13.451+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:13.452+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:13.454+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:18:13.455+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:18:13.459+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:18:13.461+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:18:13.464+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:18:13.466+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:18:13.468+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:18:13.469+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:13.470+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:13.473+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:13.474+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:13.475+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:18:13.476+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:13.478+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:18:13.480+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:18:13.482+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:18:13.484+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:18:13.486+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:18:13.488+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:18:13.490+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:18:13.492+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:18:13.493+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:18:13.495+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:18:13.497+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:18:13.499+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:18:13.502+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:18:13.505+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:18:13.507+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:18:13.509+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:18:13.510+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:18:13.512+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:18:13.514+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:13.515+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:13.516+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:13.517+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:13.519+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:18:13.520+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:18:13.521+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:18:13.522+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:18:13.523+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:18:13.524+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:18:13.525+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:18:13.526+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:13.527+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:13.529+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:13.531+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:13.533+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:13.535+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:18:13.536+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:18:13.537+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:18:13.538+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:18:13.539+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:18:13.541+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:18:13.543+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:18:13.545+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:18:13.546+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:18:13.548+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:18:13.550+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:18:13.552+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:13.553+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:18:13.554+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:18:13.555+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:18:13.557+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:18:13.558+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:18:13.560+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:13.561+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:13.562+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:18:13.564+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:13.565+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:18:13.566+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:18:13.568+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:18:13.569+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:18:13.571+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:18:13.572+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:18:13.574+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:18:13.576+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:18:13.577+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:18:13.580+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:18:13.581+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:18:13.582+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:18:13.584+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:18:13.586+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:18:13.588+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:18:13.591+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:18:13.593+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:18:13.597+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:13.601+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:13.604+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:13.606+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:13.608+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:18:13.611+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:18:13.612+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:18:13.614+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:18:13.616+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:18:13.618+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:13.620+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:13.622+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:13.624+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:13.628+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:18:13.633+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:18:13.636+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:18:13.639+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:18:13.642+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:18:13.645+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:18:13.647+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:18:13.648+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:18:13.650+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:18:13.651+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:18:13.653+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:18:13.655+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:18:13.656+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:18:13.657+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:18:13.659+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:18:13.660+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:18:13.661+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:18:13.662+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:18:13.663+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:18:13.664+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:18:13.666+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:18:13.667+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:18:13.669+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:18:13.670+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:18:13.671+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:18:13.673+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:18:13.674+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:13.675+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:18:13.676+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:18:13.677+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:18:13.678+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:18:13.680+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:18:13.681+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:13.682+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:18:13.683+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:18:13.685+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:13.686+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:18:13.688+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:18:13.689+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:13.690+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:13.692+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:13.693+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:13.695+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:18:13.696+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:18:13.697+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:18:13.699+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:18:13.700+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:18:13.701+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:18:13.702+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:18:13.703+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:18:13.705+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:13.706+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:13.707+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:18:13.708+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:18:13.710+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:18:13.711+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:13.712+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:13.713+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:13.715+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:18:13.716+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:13.717+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:13.718+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:18:13.719+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:13.720+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:13.722+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:13.723+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:13.724+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:13.726+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:18:13.727+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:13.728+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:18:13.731+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:18:13.732+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:13.733+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:13.734+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:13.735+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:13.737+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:13.738+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:18:13.740+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:13.741+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:18:13.743+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:18:13.744+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:13.745+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:13.747+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:13.748+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:13.749+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:13.750+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:18:13.751+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:13.753+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:18:13.754+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:18:13.756+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:18:13.757+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:13.758+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:13.759+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:18:13.760+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:18:13.762+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:18:13.763+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:13.764+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:13.765+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:13.766+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:13.768+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:13.769+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:18:13.770+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:18:13.771+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:18:13.772+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:18:13.773+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:13.774+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:13.775+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:13.776+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:13.777+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:13.778+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)
[2025-04-02T09:18:13.779+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)
[2025-04-02T09:18:13.780+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:18:13.781+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:18:13.782+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:18:13.783+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:13.785+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:13.786+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:13.787+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:13.789+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:13.790+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:18:13.792+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:18:13.793+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:18:13.795+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:18:13.796+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:18:13.798+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:18:13.799+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:18:13.800+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:13.801+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:13.802+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:13.803+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:13.804+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:18:13.805+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:13.806+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:18:13.807+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:18:13.809+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:18:13.810+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:18:13.811+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:18:13.812+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:18:13.813+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:18:13.814+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:18:13.815+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:18:13.816+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:18:13.817+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:18:13.818+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:18:13.819+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:18:13.820+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:18:13.821+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:18:13.822+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:18:13.823+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:18:13.824+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:18:13.826+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:13.827+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:13.828+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:13.829+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:13.830+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:18:13.831+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:18:13.832+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:18:13.833+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:18:13.834+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:18:13.836+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:18:13.838+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:18:13.840+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:13.843+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:13.845+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:13.846+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:13.847+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:13.849+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:18:13.850+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:18:13.851+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:18:13.853+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:18:13.856+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:18:13.858+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:18:13.859+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:18:13.860+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:18:13.861+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:18:13.863+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:18:13.865+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:18:13.867+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:13.868+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:18:13.869+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:18:13.870+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:18:13.872+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:18:13.873+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:18:13.875+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:13.876+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:13.877+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:18:13.879+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:13.880+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:18:13.882+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:18:13.883+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:18:13.885+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:18:13.887+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:18:13.888+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:18:13.890+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:18:13.891+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:18:13.893+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:18:13.894+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:18:13.896+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:18:13.897+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:18:13.901+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:18:13.902+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:18:13.903+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:18:13.904+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:18:13.906+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:18:13.908+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:13.910+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:13.912+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:13.914+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:13.916+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:18:13.920+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:18:13.922+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:18:13.923+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:18:13.924+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:18:13.926+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:13.927+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:13.929+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:13.932+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:13.933+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:18:13.934+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:18:13.936+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:18:13.938+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:18:13.939+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:18:13.940+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:18:13.943+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:18:13.944+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:18:13.945+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:18:13.946+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:18:13.948+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:18:13.949+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:18:13.951+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:18:13.952+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:18:13.954+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:18:13.955+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:18:13.956+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:18:13.957+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:18:13.958+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:18:13.959+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:18:13.961+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:18:13.962+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:18:13.964+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:18:13.965+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:18:13.966+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:18:13.967+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:18:13.968+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:13.969+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:18:13.970+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:18:13.971+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:18:13.972+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:18:13.973+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:18:13.974+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:13.975+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:18:13.976+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:18:13.977+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:13.978+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:18:13.979+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:18:13.980+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:13.981+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:13.982+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:13.983+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:13.984+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:18:13.985+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:18:13.986+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:18:13.987+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:18:13.988+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:18:13.989+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:18:13.990+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:18:13.991+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:18:13.992+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:13.993+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:13.994+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:13.995+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:18:13.996+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:18:13.997+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:18:13.998+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:13.999+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:14.000+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:14.000+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:18:14.001+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:14.002+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:14.003+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:18:14.004+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:18:14.005+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:18:14.006+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:18:14.007+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:18:14.008+0000] {subprocess.py:106} INFO - 	... 156 more
[2025-04-02T09:18:14.009+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:14.010+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:14.011+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:18:14.012+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:18:14.013+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:18:14.014+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:14.015+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:14.016+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:14.017+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:18:14.019+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:14.020+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:14.021+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:18:14.023+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:14.024+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:14.025+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:14.026+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:14.027+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:14.029+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:18:14.030+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:14.031+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:18:14.033+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:18:14.034+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:14.035+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:14.036+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:14.037+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:14.038+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:14.039+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:18:14.040+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:14.041+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:18:14.042+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:18:14.043+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:14.044+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:14.045+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:14.046+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:14.047+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:14.048+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:18:14.049+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:14.050+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:18:14.051+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:18:14.052+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:18:14.053+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:14.055+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:14.055+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:18:14.056+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:18:14.058+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:18:14.059+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:14.060+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:14.060+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:14.061+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:14.062+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:14.063+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:18:14.064+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:18:14.065+0000] {subprocess.py:106} INFO - 25/04/02 09:18:12 WARN HiveMetaStore: Retrying creating default database after error: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:18:14.066+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:14.071+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:14.072+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:14.074+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:18:14.075+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:18:14.076+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:18:14.077+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:14.078+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:14.080+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:14.081+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:18:14.082+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:14.083+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:14.086+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:18:14.088+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:18:14.089+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:18:14.090+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:18:14.091+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:18:14.093+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:18:14.094+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:18:14.096+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:18:14.098+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:14.099+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:14.100+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:14.101+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:14.102+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:14.103+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:18:14.105+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:18:14.106+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:18:14.107+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:18:14.108+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:18:14.109+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:18:14.110+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:18:14.111+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:14.112+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:14.113+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:14.114+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:14.116+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:18:14.118+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:14.120+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:18:14.121+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:18:14.123+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:18:14.124+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:18:14.124+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:18:14.125+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:18:14.126+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:18:14.127+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:18:14.128+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:18:14.129+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:18:14.131+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:18:14.132+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:18:14.133+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:18:14.135+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:18:14.137+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:18:14.139+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:18:14.140+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:18:14.141+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:18:14.142+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:14.143+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:14.144+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:14.145+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:14.146+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:18:14.148+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:18:14.149+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:18:14.150+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:18:14.151+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:18:14.152+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:18:14.153+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:18:14.155+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:14.156+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:14.157+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:14.158+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:14.159+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:14.160+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:18:14.160+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:18:14.161+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:18:14.162+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:18:14.163+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:18:14.164+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:18:14.165+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:18:14.166+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:18:14.167+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:18:14.169+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:18:14.170+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:18:14.171+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:14.173+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:18:14.174+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:18:14.175+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:18:14.176+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:18:14.177+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:18:14.178+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:14.179+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:14.180+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:18:14.181+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:14.182+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:18:14.183+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:18:14.184+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:18:14.185+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:18:14.186+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:18:14.187+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:18:14.188+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:18:14.189+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:18:14.190+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:18:14.191+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:18:14.192+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:18:14.193+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:18:14.194+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:18:14.195+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:18:14.197+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:18:14.198+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:18:14.200+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:18:14.202+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:14.203+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:14.204+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:14.206+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:14.207+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:18:14.208+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:18:14.208+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:18:14.209+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:18:14.211+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:18:14.213+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:14.214+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:14.215+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:14.216+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:14.218+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:18:14.219+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:18:14.220+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:18:14.221+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:18:14.222+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:18:14.223+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:18:14.224+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:18:14.226+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:18:14.227+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:18:14.228+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:18:14.230+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:18:14.233+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:18:14.234+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:18:14.236+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:18:14.237+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:18:14.239+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:18:14.241+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:18:14.242+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:18:14.243+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:18:14.244+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:18:14.245+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:18:14.247+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:18:14.248+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:18:14.250+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:18:14.252+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:18:14.253+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:18:14.256+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:14.258+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:18:14.259+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:18:14.260+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:18:14.261+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:18:14.263+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:18:14.264+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:14.265+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:18:14.266+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:18:14.267+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:14.270+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:18:14.272+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:18:14.274+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:14.277+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:14.279+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:14.280+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:14.282+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:18:14.284+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:18:14.286+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:18:14.288+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:18:14.290+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:18:14.292+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:18:14.294+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:18:14.295+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:18:14.297+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:14.299+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:14.300+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:18:14.302+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:18:14.304+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:18:14.305+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:14.307+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:14.308+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:14.311+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:18:14.312+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:14.313+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:14.314+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:18:14.316+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:14.317+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:14.319+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:14.320+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:14.322+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:14.324+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:18:14.326+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:14.328+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:18:14.330+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:18:14.331+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:14.333+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:14.334+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:14.336+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:14.338+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:14.340+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:18:14.341+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:14.343+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:18:14.345+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:18:14.346+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:14.349+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:14.350+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:14.352+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:14.353+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:14.354+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:18:14.356+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:14.357+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:18:14.358+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:18:14.360+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:18:14.361+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:14.362+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:14.364+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:18:14.366+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:18:14.368+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:18:14.370+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:14.372+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:14.374+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:14.376+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:14.377+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:14.378+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:18:14.379+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:18:14.380+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:18:14.381+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:18:14.383+0000] {subprocess.py:106} INFO - javax.jdo.JDOFatalDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:18:14.384+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:14.385+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:14.387+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:14.388+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:18:14.389+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:18:14.390+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:18:14.392+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:14.393+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:14.395+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:14.396+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:18:14.398+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:14.399+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:14.401+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:18:14.402+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:18:14.404+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:18:14.405+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:18:14.407+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:18:14.409+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:18:14.410+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:18:14.412+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:18:14.414+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:14.416+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:14.418+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:14.420+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:14.421+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:14.423+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:18:14.424+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:18:14.426+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:18:14.427+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:18:14.429+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:18:14.430+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:18:14.432+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:18:14.434+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:14.436+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:14.438+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:14.439+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:14.444+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:18:14.446+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:14.448+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:18:14.450+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:18:14.452+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:18:14.453+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:18:14.455+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:18:14.456+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:18:14.458+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:18:14.460+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:18:14.461+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:18:14.463+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:18:14.464+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:18:14.465+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:18:14.467+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:18:14.469+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:18:14.470+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:18:14.472+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:18:14.473+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:18:14.475+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:18:14.477+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:14.478+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:14.479+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:14.481+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:14.483+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:18:14.484+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:18:14.486+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:18:14.487+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:18:14.489+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:18:14.490+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:18:14.492+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:18:14.494+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:14.496+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:14.497+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:14.499+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:14.502+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:14.504+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:18:14.507+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:18:14.509+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:18:14.511+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:18:14.512+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:18:14.515+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:18:14.517+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:18:14.519+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:18:14.521+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:18:14.523+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:18:14.524+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:18:14.525+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:14.527+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:18:14.528+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:18:14.529+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:18:14.531+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:18:14.532+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:18:14.533+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:14.534+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:14.536+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:18:14.538+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:14.539+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:18:14.540+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:18:14.542+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:18:14.543+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:18:14.545+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:18:14.547+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:18:14.548+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:18:14.549+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:18:14.551+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:18:14.552+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:18:14.554+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:18:14.555+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:18:14.556+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:18:14.557+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:18:14.559+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:18:14.561+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:18:14.562+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:18:14.563+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:14.565+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:14.566+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:14.568+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:14.569+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:18:14.571+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:18:14.572+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:18:14.573+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:18:14.574+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:18:14.576+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:14.578+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:14.580+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:14.581+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:14.583+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:18:14.585+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:18:14.586+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:18:14.588+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:18:14.590+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:18:14.591+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:18:14.593+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:18:14.594+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:18:14.596+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:18:14.597+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:18:14.599+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:18:14.600+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:18:14.601+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:18:14.602+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:18:14.604+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:18:14.606+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:18:14.607+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:18:14.608+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:18:14.609+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:18:14.611+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:18:14.612+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:18:14.613+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:18:14.615+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:18:14.616+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:18:14.618+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:18:14.619+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:18:14.621+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:14.622+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:18:14.623+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:18:14.625+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:18:14.626+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:18:14.629+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:18:14.631+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:14.633+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:18:14.635+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:18:14.637+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:14.638+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:18:14.640+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:18:14.643+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:14.645+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:14.648+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:14.650+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:14.652+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:18:14.654+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:18:14.656+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:18:14.658+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:18:14.660+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:18:14.661+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:18:14.663+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:18:14.664+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:18:14.666+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:14.667+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:14.669+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:18:14.671+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:18:14.674+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:18:14.676+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:14.679+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:14.681+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:14.684+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:18:14.686+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:14.687+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:14.689+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:18:14.691+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:14.693+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:14.694+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:14.695+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:14.697+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:14.698+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:18:14.699+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:14.701+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:18:14.703+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:18:14.704+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:14.706+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:14.708+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:14.709+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:14.711+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:14.712+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:18:14.714+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:14.715+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:18:14.716+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:18:14.718+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:14.719+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:14.721+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:14.722+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:14.724+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:14.725+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:18:14.727+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:14.729+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:18:14.730+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:18:14.732+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:18:14.735+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:14.737+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:14.738+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:18:14.740+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:18:14.742+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:18:14.743+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:14.746+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:14.748+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:14.750+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:14.751+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:14.755+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:18:14.757+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:18:14.760+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:18:14.761+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:18:14.763+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:529)
[2025-04-02T09:18:14.765+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:830)
[2025-04-02T09:18:14.766+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:18:14.768+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:18:14.769+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:14.771+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:14.772+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:14.774+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:14.775+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:18:14.777+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:14.778+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:18:14.780+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:18:14.782+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:18:14.787+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:18:14.789+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:18:14.791+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:18:14.793+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:18:14.795+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:18:14.797+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:18:14.799+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:18:14.801+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:18:14.802+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:18:14.805+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:18:14.810+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:18:14.814+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:18:14.815+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:18:14.817+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:18:14.818+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:18:14.820+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:14.821+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:14.822+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:14.824+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:14.825+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:18:14.826+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:18:14.827+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:18:14.829+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:18:14.830+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:18:14.832+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:18:14.833+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:18:14.834+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:14.837+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:14.839+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:14.841+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:14.843+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:14.847+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:18:14.849+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:18:14.850+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:18:14.852+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:18:14.855+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:18:14.856+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:18:14.858+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:18:14.859+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:18:14.861+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:18:14.862+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:18:14.864+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:18:14.865+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:14.867+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:18:14.868+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:18:14.869+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:18:14.871+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:18:14.872+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:18:14.873+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:14.875+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:14.876+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:18:14.878+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:14.879+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:18:14.881+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:18:14.883+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:18:14.884+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:18:14.885+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:18:14.886+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:18:14.888+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:18:14.889+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:18:14.891+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:18:14.893+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:18:14.895+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:18:14.896+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:18:14.898+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:18:14.900+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:18:14.901+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:18:14.902+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:18:14.904+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:18:14.905+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:14.907+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:14.909+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:14.911+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:14.912+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:18:14.913+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:18:14.915+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:18:14.917+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:18:14.919+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:18:14.920+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:14.922+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:14.924+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:14.926+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:14.930+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:18:14.933+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:18:14.936+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:18:14.941+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:18:14.942+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:18:14.943+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:18:14.945+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:18:14.946+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:18:14.948+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:18:14.952+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:18:14.954+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:18:14.956+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:18:14.957+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:18:14.959+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:18:14.960+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:18:14.962+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:18:14.964+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:18:14.969+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:18:14.971+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:18:14.975+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:18:14.978+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:18:14.980+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:18:14.983+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:18:14.987+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:18:14.990+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:18:14.993+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:18:14.996+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:15.000+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:18:15.002+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:18:15.005+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:18:15.006+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:18:15.008+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:18:15.009+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:15.011+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:18:15.014+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:18:15.017+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:15.020+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:18:15.022+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:18:15.023+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:15.025+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:15.026+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:15.027+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:15.028+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:18:15.030+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:18:15.032+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:18:15.034+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:18:15.037+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:18:15.039+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:18:15.040+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:18:15.041+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:18:15.044+0000] {subprocess.py:106} INFO - NestedThrowablesStackTrace:
[2025-04-02T09:18:15.046+0000] {subprocess.py:106} INFO - java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
[2025-04-02T09:18:15.048+0000] {subprocess.py:106} INFO - java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:15.050+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:15.053+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:15.054+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:18:15.058+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:18:15.060+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:18:15.063+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:15.066+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:15.070+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:15.072+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:18:15.075+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:15.077+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:15.079+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:18:15.080+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:18:15.082+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:18:15.083+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:18:15.085+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:18:15.087+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:18:15.089+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:18:15.091+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:18:15.092+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:15.093+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:15.095+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:15.096+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:15.098+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:15.099+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:18:15.100+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:18:15.102+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:18:15.103+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:18:15.104+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:18:15.106+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:18:15.107+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:18:15.108+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:15.109+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:15.110+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:15.112+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:15.114+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:18:15.115+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:15.116+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:18:15.117+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:18:15.121+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:18:15.123+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:18:15.124+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:18:15.126+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:18:15.128+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:18:15.131+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:18:15.133+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:18:15.134+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:18:15.139+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:18:15.143+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:18:15.146+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:18:15.151+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:18:15.153+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:18:15.156+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:18:15.158+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:18:15.162+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:18:15.166+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:15.168+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:15.170+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:15.172+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:15.176+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:18:15.178+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:18:15.184+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:18:15.185+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:18:15.189+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:18:15.192+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:18:15.194+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:18:15.199+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:15.202+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:15.205+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:15.209+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:15.211+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:15.213+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:18:15.216+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:18:15.219+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:18:15.222+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:18:15.224+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:18:15.227+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:18:15.229+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:18:15.233+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:18:15.235+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:18:15.239+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:18:15.241+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:18:15.244+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:15.247+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:18:15.249+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:18:15.252+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:18:15.255+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:18:15.258+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:18:15.261+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:15.262+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:15.265+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:18:15.269+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:15.271+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:18:15.274+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:18:15.276+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:18:15.278+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:18:15.280+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:18:15.285+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:18:15.289+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:18:15.290+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:18:15.293+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:18:15.296+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:18:15.298+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:18:15.300+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:18:15.302+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:18:15.304+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:18:15.307+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:18:15.311+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:18:15.314+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:18:15.316+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:15.318+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:15.321+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:15.323+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:15.326+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:18:15.329+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:18:15.332+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:18:15.334+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:18:15.336+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:18:15.339+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:15.341+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:15.351+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:15.353+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:15.354+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:18:15.356+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:18:15.357+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:18:15.358+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:18:15.360+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:18:15.361+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:18:15.363+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:18:15.364+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:18:15.366+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:18:15.367+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:18:15.368+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:18:15.370+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:18:15.373+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:18:15.375+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:18:15.376+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:18:15.378+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:18:15.379+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:18:15.382+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:18:15.383+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:18:15.384+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:18:15.385+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:18:15.386+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:18:15.391+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:18:15.392+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:18:15.393+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:18:15.394+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:18:15.395+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:15.395+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:18:15.396+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:18:15.398+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:18:15.399+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:18:15.400+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:18:15.400+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:15.401+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:18:15.402+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:18:15.403+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:15.404+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:18:15.405+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:18:15.406+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:15.407+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:15.408+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:15.409+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:15.410+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:18:15.411+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:18:15.412+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:18:15.413+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:18:15.414+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:18:15.415+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:18:15.416+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:18:15.418+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:18:15.419+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:15.420+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:15.421+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:18:15.421+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:18:15.422+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:18:15.423+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:15.424+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:15.425+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:15.427+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:18:15.428+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:15.429+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:15.430+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:18:15.431+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:15.432+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:15.433+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:15.435+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:15.436+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:15.438+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:18:15.439+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:15.440+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:18:15.442+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:18:15.442+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:15.445+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:15.446+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:15.449+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:15.450+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:15.455+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:18:15.459+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:15.465+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:18:15.469+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:18:15.471+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:15.473+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:15.475+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:15.476+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:15.478+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:15.479+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:18:15.481+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:15.483+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:18:15.486+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:18:15.487+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:18:15.489+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:15.490+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:15.492+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:18:15.493+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:18:15.494+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:18:15.496+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:15.497+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:15.500+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:15.501+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:15.502+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:15.504+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:18:15.505+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:18:15.506+0000] {subprocess.py:106} INFO - ------
[2025-04-02T09:18:15.508+0000] {subprocess.py:106} INFO - 
[2025-04-02T09:18:15.509+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:15.511+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:15.512+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:15.513+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:15.514+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:15.516+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)
[2025-04-02T09:18:15.518+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)
[2025-04-02T09:18:15.519+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)
[2025-04-02T09:18:15.521+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)
[2025-04-02T09:18:15.523+0000] {subprocess.py:106} INFO - 	at org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)
[2025-04-02T09:18:15.524+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:15.526+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:15.528+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:15.529+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:15.530+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:15.534+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)
[2025-04-02T09:18:15.535+0000] {subprocess.py:106} INFO - 	at org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)
[2025-04-02T09:18:15.537+0000] {subprocess.py:106} INFO - 	at org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)
[2025-04-02T09:18:15.538+0000] {subprocess.py:106} INFO - 	at org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)
[2025-04-02T09:18:15.539+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)
[2025-04-02T09:18:15.541+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)
[2025-04-02T09:18:15.542+0000] {subprocess.py:106} INFO - 	at org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)
[2025-04-02T09:18:15.544+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:15.546+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:15.548+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:15.550+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:15.552+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)
[2025-04-02T09:18:15.554+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:15.556+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)
[2025-04-02T09:18:15.557+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)
[2025-04-02T09:18:15.558+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)
[2025-04-02T09:18:15.560+0000] {subprocess.py:106} INFO - 	at javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)
[2025-04-02T09:18:15.562+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)
[2025-04-02T09:18:15.564+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)
[2025-04-02T09:18:15.565+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)
[2025-04-02T09:18:15.567+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)
[2025-04-02T09:18:15.568+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)
[2025-04-02T09:18:15.570+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79)
[2025-04-02T09:18:15.571+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
[2025-04-02T09:18:15.573+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)
[2025-04-02T09:18:15.573+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)
[2025-04-02T09:18:15.574+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)
[2025-04-02T09:18:15.577+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)
[2025-04-02T09:18:15.579+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)
[2025-04-02T09:18:15.581+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)
[2025-04-02T09:18:15.582+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)
[2025-04-02T09:18:15.584+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:15.585+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:15.587+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:15.588+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:15.590+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)
[2025-04-02T09:18:15.591+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
[2025-04-02T09:18:15.593+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)
[2025-04-02T09:18:15.594+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)
[2025-04-02T09:18:15.595+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)
[2025-04-02T09:18:15.601+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:162)
[2025-04-02T09:18:15.603+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)
[2025-04-02T09:18:15.605+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-04-02T09:18:15.608+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)
[2025-04-02T09:18:15.609+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)
[2025-04-02T09:18:15.610+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)
[2025-04-02T09:18:15.612+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)
[2025-04-02T09:18:15.615+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)
[2025-04-02T09:18:15.616+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)
[2025-04-02T09:18:15.617+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)
[2025-04-02T09:18:15.619+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)
[2025-04-02T09:18:15.621+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3607)
[2025-04-02T09:18:15.622+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3659)
[2025-04-02T09:18:15.624+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3639)
[2025-04-02T09:18:15.625+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1563)
[2025-04-02T09:18:15.627+0000] {subprocess.py:106} INFO - 	at org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1552)
[2025-04-02T09:18:15.628+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.Shim_v0_12.databaseExists(HiveShim.scala:609)
[2025-04-02T09:18:15.630+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:407)
[2025-04-02T09:18:15.633+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:15.635+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:304)
[2025-04-02T09:18:15.636+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:235)
[2025-04-02T09:18:15.638+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:234)
[2025-04-02T09:18:15.639+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:284)
[2025-04-02T09:18:15.640+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:407)
[2025-04-02T09:18:15.641+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:15.643+0000] {subprocess.py:106} INFO - 	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
[2025-04-02T09:18:15.644+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)
[2025-04-02T09:18:15.645+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)
[2025-04-02T09:18:15.647+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:146)
[2025-04-02T09:18:15.648+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)
[2025-04-02T09:18:15.649+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:176)
[2025-04-02T09:18:15.650+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:174)
[2025-04-02T09:18:15.651+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:70)
[2025-04-02T09:18:15.653+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:124)
[2025-04-02T09:18:15.654+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:124)
[2025-04-02T09:18:15.656+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.isGlobalTempViewDB(SessionCatalog.scala:1003)
[2025-04-02T09:18:15.657+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.getRawLocalOrGlobalTempView(SessionCatalog.scala:718)
[2025-04-02T09:18:15.659+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.lookupTempView(Analyzer.scala:1194)
[2025-04-02T09:18:15.660+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveTempView(Analyzer.scala:1201)
[2025-04-02T09:18:15.661+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$resolveRelation(Analyzer.scala:1295)
[2025-04-02T09:18:15.663+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1153)
[2025-04-02T09:18:15.664+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$14.applyOrElse(Analyzer.scala:1117)
[2025-04-02T09:18:15.665+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)
[2025-04-02T09:18:15.666+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
[2025-04-02T09:18:15.667+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)
[2025-04-02T09:18:15.668+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:15.669+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:15.670+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:15.671+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:15.672+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)
[2025-04-02T09:18:15.673+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1216)
[2025-04-02T09:18:15.675+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1215)
[2025-04-02T09:18:15.677+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.Project.mapChildren(basicLogicalOperators.scala:71)
[2025-04-02T09:18:15.678+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)
[2025-04-02T09:18:15.678+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
[2025-04-02T09:18:15.680+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)
[2025-04-02T09:18:15.681+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)
[2025-04-02T09:18:15.682+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:32)
[2025-04-02T09:18:15.683+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1117)
[2025-04-02T09:18:15.684+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1076)
[2025-04-02T09:18:15.685+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
[2025-04-02T09:18:15.686+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
[2025-04-02T09:18:15.687+0000] {subprocess.py:106} INFO - 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
[2025-04-02T09:18:15.688+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foldLeft(List.scala:91)
[2025-04-02T09:18:15.689+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
[2025-04-02T09:18:15.691+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
[2025-04-02T09:18:15.692+0000] {subprocess.py:106} INFO - 	at scala.collection.immutable.List.foreach(List.scala:431)
[2025-04-02T09:18:15.693+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
[2025-04-02T09:18:15.694+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:240)
[2025-04-02T09:18:15.695+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:236)
[2025-04-02T09:18:15.696+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:187)
[2025-04-02T09:18:15.696+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:236)
[2025-04-02T09:18:15.697+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:202)
[2025-04-02T09:18:15.698+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
[2025-04-02T09:18:15.699+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
[2025-04-02T09:18:15.700+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
[2025-04-02T09:18:15.701+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:223)
[2025-04-02T09:18:15.703+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
[2025-04-02T09:18:15.704+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:222)
[2025-04-02T09:18:15.705+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
[2025-04-02T09:18:15.706+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
[2025-04-02T09:18:15.707+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
[2025-04-02T09:18:15.708+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
[2025-04-02T09:18:15.709+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
[2025-04-02T09:18:15.710+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:15.712+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
[2025-04-02T09:18:15.713+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
[2025-04-02T09:18:15.714+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
[2025-04-02T09:18:15.715+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
[2025-04-02T09:18:15.716+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
[2025-04-02T09:18:15.718+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:15.719+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
[2025-04-02T09:18:15.720+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
[2025-04-02T09:18:15.720+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-04-02T09:18:15.722+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
[2025-04-02T09:18:15.723+0000] {subprocess.py:106} INFO - 	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
[2025-04-02T09:18:15.724+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2025-04-02T09:18:15.725+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
[2025-04-02T09:18:15.726+0000] {subprocess.py:106} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
[2025-04-02T09:18:15.727+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
[2025-04-02T09:18:15.729+0000] {subprocess.py:106} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2025-04-02T09:18:15.731+0000] {subprocess.py:106} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2025-04-02T09:18:15.732+0000] {subprocess.py:106} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2025-04-02T09:18:15.733+0000] {subprocess.py:106} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2025-04-02T09:18:15.735+0000] {subprocess.py:106} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2025-04-02T09:18:15.737+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2025-04-02T09:18:15.739+0000] {subprocess.py:106} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2025-04-02T09:18:15.740+0000] {subprocess.py:106} INFO - 	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-02T09:18:15.742+0000] {subprocess.py:106} INFO - Caused by: java.sql.SQLException: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:15.743+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:15.744+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
[2025-04-02T09:18:15.745+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
[2025-04-02T09:18:15.747+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
[2025-04-02T09:18:15.748+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.<init>(Unknown Source)
[2025-04-02T09:18:15.749+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:15.751+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver$1.run(Unknown Source)
[2025-04-02T09:18:15.752+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:15.753+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.getNewEmbedConnection(Unknown Source)
[2025-04-02T09:18:15.754+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:15.755+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.InternalDriver.connect(Unknown Source)
[2025-04-02T09:18:15.756+0000] {subprocess.py:106} INFO - 	at org.apache.derby.jdbc.AutoloadedDriver.connect(Unknown Source)
[2025-04-02T09:18:15.757+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:683)
[2025-04-02T09:18:15.758+0000] {subprocess.py:106} INFO - 	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:191)
[2025-04-02T09:18:15.758+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)
[2025-04-02T09:18:15.759+0000] {subprocess.py:106} INFO - 	at com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)
[2025-04-02T09:18:15.760+0000] {subprocess.py:106} INFO - 	... 156 more
[2025-04-02T09:18:15.761+0000] {subprocess.py:106} INFO - Caused by: ERROR XJ040: Failed to start database 'metastore_db' with class loader jdk.internal.loader.ClassLoaders$AppClassLoader@5ffd2b27, see the next exception for details.
[2025-04-02T09:18:15.762+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:15.763+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
[2025-04-02T09:18:15.765+0000] {subprocess.py:106} INFO - 	... 172 more
[2025-04-02T09:18:15.766+0000] {subprocess.py:106} INFO - Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /opt/spark/metastore_db.
[2025-04-02T09:18:15.767+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:15.768+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
[2025-04-02T09:18:15.769+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:15.770+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
[2025-04-02T09:18:15.771+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:15.773+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
[2025-04-02T09:18:15.774+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
[2025-04-02T09:18:15.775+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:15.776+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:15.777+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:15.778+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:15.780+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:15.780+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore$6.run(Unknown Source)
[2025-04-02T09:18:15.781+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:15.782+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.bootServiceModule(Unknown Source)
[2025-04-02T09:18:15.783+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.raw.RawStore.boot(Unknown Source)
[2025-04-02T09:18:15.784+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:15.785+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:15.785+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:15.786+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:15.787+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:15.788+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager$5.run(Unknown Source)
[2025-04-02T09:18:15.789+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:15.790+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.bootServiceModule(Unknown Source)
[2025-04-02T09:18:15.791+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.store.access.RAMAccessManager.boot(Unknown Source)
[2025-04-02T09:18:15.792+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:15.794+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:15.795+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startModule(Unknown Source)
[2025-04-02T09:18:15.796+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.FileMonitor.startModule(Unknown Source)
[2025-04-02T09:18:15.797+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.bootServiceModule(Unknown Source)
[2025-04-02T09:18:15.798+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase$5.run(Unknown Source)
[2025-04-02T09:18:15.799+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:15.800+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootServiceModule(Unknown Source)
[2025-04-02T09:18:15.801+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.bootStore(Unknown Source)
[2025-04-02T09:18:15.801+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.db.BasicDatabase.boot(Unknown Source)
[2025-04-02T09:18:15.802+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)
[2025-04-02T09:18:15.804+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.TopService.bootModule(Unknown Source)
[2025-04-02T09:18:15.805+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.bootService(Unknown Source)
[2025-04-02T09:18:15.806+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startProviderService(Unknown Source)
[2025-04-02T09:18:15.807+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.findProviderAndStartService(Unknown Source)
[2025-04-02T09:18:15.808+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.services.monitor.BaseMonitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:15.809+0000] {subprocess.py:106} INFO - 	at org.apache.derby.iapi.services.monitor.Monitor.startPersistentService(Unknown Source)
[2025-04-02T09:18:15.811+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:15.812+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection$4.run(Unknown Source)
[2025-04-02T09:18:15.812+0000] {subprocess.py:106} INFO - 	at java.base/java.security.AccessController.doPrivileged(AccessController.java:571)
[2025-04-02T09:18:15.813+0000] {subprocess.py:106} INFO - 	at org.apache.derby.impl.jdbc.EmbedConnection.startPersistentService(Unknown Source)
[2025-04-02T09:18:15.814+0000] {subprocess.py:106} INFO - 	... 169 more
[2025-04-02T09:18:15.815+0000] {subprocess.py:106} INFO - 25/04/02 09:18:14 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
[2025-04-02T09:18:15.816+0000] {subprocess.py:106} INFO - 25/04/02 09:18:14 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
[2025-04-02T09:18:15.817+0000] {subprocess.py:106} INFO - 25/04/02 09:18:14 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
[2025-04-02T09:18:15.818+0000] {subprocess.py:106} INFO - 25/04/02 09:18:14 INFO ObjectStore: ObjectStore, initialize called
[2025-04-02T09:18:15.819+0000] {subprocess.py:106} INFO - 25/04/02 09:18:14 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
[2025-04-02T09:18:15.820+0000] {subprocess.py:106} INFO - 25/04/02 09:18:14 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
[2025-04-02T09:18:17.148+0000] {subprocess.py:106} INFO - 25/04/02 09:18:17 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
[2025-04-02T09:18:18.591+0000] {subprocess.py:106} INFO - 25/04/02 09:18:18 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
[2025-04-02T09:18:18.596+0000] {subprocess.py:106} INFO - 25/04/02 09:18:18 INFO ObjectStore: Initialized ObjectStore
[2025-04-02T09:18:18.680+0000] {subprocess.py:106} INFO - 25/04/02 09:18:18 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
[2025-04-02T09:18:18.682+0000] {subprocess.py:106} INFO - 25/04/02 09:18:18 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@172.18.0.6
[2025-04-02T09:18:18.835+0000] {subprocess.py:106} INFO - 25/04/02 09:18:18 INFO HiveMetaStore: Added admin role in metastore
[2025-04-02T09:18:18.838+0000] {subprocess.py:106} INFO - 25/04/02 09:18:18 INFO HiveMetaStore: Added public role in metastore
[2025-04-02T09:18:18.895+0000] {subprocess.py:106} INFO - 25/04/02 09:18:18 INFO HiveMetaStore: No user is added in admin role, since config is empty
[2025-04-02T09:18:18.955+0000] {subprocess.py:106} INFO - 25/04/02 09:18:18 INFO HiveMetaStore: 0: get_database: default
[2025-04-02T09:18:18.959+0000] {subprocess.py:106} INFO - 25/04/02 09:18:18 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_database: default
[2025-04-02T09:18:18.972+0000] {subprocess.py:106} INFO - 25/04/02 09:18:18 INFO HiveMetaStore: 0: get_database: global_temp
[2025-04-02T09:18:18.974+0000] {subprocess.py:106} INFO - 25/04/02 09:18:18 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_database: global_temp
[2025-04-02T09:18:18.975+0000] {subprocess.py:106} INFO - 25/04/02 09:18:18 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
[2025-04-02T09:18:19.651+0000] {subprocess.py:106} INFO - 25/04/02 09:18:19 INFO HiveMetaStore: 0: get_database: default
[2025-04-02T09:18:19.652+0000] {subprocess.py:106} INFO - 25/04/02 09:18:19 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_database: default
[2025-04-02T09:18:19.658+0000] {subprocess.py:106} INFO - 25/04/02 09:18:19 INFO HiveMetaStore: 0: get_table : db=default tbl=transformed_data
[2025-04-02T09:18:19.659+0000] {subprocess.py:106} INFO - 25/04/02 09:18:19 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_table : db=default tbl=transformed_data
[2025-04-02T09:18:19.927+0000] {subprocess.py:106} INFO - 25/04/02 09:18:19 INFO HiveMetaStore: 0: get_table : db=default tbl=transformed_data
[2025-04-02T09:18:19.928+0000] {subprocess.py:106} INFO - 25/04/02 09:18:19 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_table : db=default tbl=transformed_data
[2025-04-02T09:18:22.561+0000] {subprocess.py:106} INFO - 25/04/02 09:18:22 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=1a0a7926-7617-48d7-b31e-c62360490805, clientType=HIVECLI]
[2025-04-02T09:18:22.563+0000] {subprocess.py:106} INFO - 25/04/02 09:18:22 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
[2025-04-02T09:18:22.565+0000] {subprocess.py:106} INFO - 25/04/02 09:18:22 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
[2025-04-02T09:18:22.566+0000] {subprocess.py:106} INFO - 25/04/02 09:18:22 INFO HiveMetaStore: 0: Cleaning up thread local RawStore...
[2025-04-02T09:18:22.567+0000] {subprocess.py:106} INFO - 25/04/02 09:18:22 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...
[2025-04-02T09:18:22.568+0000] {subprocess.py:106} INFO - 25/04/02 09:18:22 INFO HiveMetaStore: 0: Done cleaning up thread local RawStore
[2025-04-02T09:18:22.569+0000] {subprocess.py:106} INFO - 25/04/02 09:18:22 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore
[2025-04-02T09:18:22.871+0000] {subprocess.py:106} INFO - 25/04/02 09:18:22 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 200.6 KiB, free 434.2 MiB)
[2025-04-02T09:18:22.953+0000] {subprocess.py:106} INFO - 25/04/02 09:18:22 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.6 KiB, free 434.2 MiB)
[2025-04-02T09:18:22.968+0000] {subprocess.py:106} INFO - 25/04/02 09:18:22 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on a72b9165479b:39593 (size: 34.6 KiB, free: 434.4 MiB)
[2025-04-02T09:18:22.975+0000] {subprocess.py:106} INFO - 25/04/02 09:18:22 INFO SparkContext: Created broadcast 0 from
[2025-04-02T09:18:23.313+0000] {subprocess.py:106} INFO - 25/04/02 09:18:23 INFO FileInputFormat: Total input files to process : 3
[2025-04-02T09:18:23.377+0000] {subprocess.py:106} INFO - 25/04/02 09:18:23 INFO SparkContext: Starting job: jdbc at NativeMethodAccessorImpl.java:0
[2025-04-02T09:18:23.404+0000] {subprocess.py:106} INFO - 25/04/02 09:18:23 INFO DAGScheduler: Got job 0 (jdbc at NativeMethodAccessorImpl.java:0) with 3 output partitions
[2025-04-02T09:18:23.406+0000] {subprocess.py:106} INFO - 25/04/02 09:18:23 INFO DAGScheduler: Final stage: ResultStage 0 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-04-02T09:18:23.407+0000] {subprocess.py:106} INFO - 25/04/02 09:18:23 INFO DAGScheduler: Parents of final stage: List()
[2025-04-02T09:18:23.408+0000] {subprocess.py:106} INFO - 25/04/02 09:18:23 INFO DAGScheduler: Missing parents: List()
[2025-04-02T09:18:23.414+0000] {subprocess.py:106} INFO - 25/04/02 09:18:23 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-04-02T09:18:23.567+0000] {subprocess.py:106} INFO - 25/04/02 09:18:23 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 29.3 KiB, free 434.1 MiB)
[2025-04-02T09:18:23.572+0000] {subprocess.py:106} INFO - 25/04/02 09:18:23 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 13.9 KiB, free 434.1 MiB)
[2025-04-02T09:18:23.573+0000] {subprocess.py:106} INFO - 25/04/02 09:18:23 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on a72b9165479b:39593 (size: 13.9 KiB, free: 434.4 MiB)
[2025-04-02T09:18:23.574+0000] {subprocess.py:106} INFO - 25/04/02 09:18:23 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
[2025-04-02T09:18:23.612+0000] {subprocess.py:106} INFO - 25/04/02 09:18:23 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2))
[2025-04-02T09:18:23.615+0000] {subprocess.py:106} INFO - 25/04/02 09:18:23 INFO TaskSchedulerImpl: Adding task set 0.0 with 3 tasks resource profile 0
[2025-04-02T09:18:23.687+0000] {subprocess.py:106} INFO - 25/04/02 09:18:23 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (a72b9165479b, executor driver, partition 0, PROCESS_LOCAL, 9298 bytes)
[2025-04-02T09:18:23.693+0000] {subprocess.py:106} INFO - 25/04/02 09:18:23 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (a72b9165479b, executor driver, partition 1, PROCESS_LOCAL, 9298 bytes)
[2025-04-02T09:18:23.694+0000] {subprocess.py:106} INFO - 25/04/02 09:18:23 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2) (a72b9165479b, executor driver, partition 2, PROCESS_LOCAL, 9298 bytes)
[2025-04-02T09:18:23.715+0000] {subprocess.py:106} INFO - 25/04/02 09:18:23 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
[2025-04-02T09:18:23.720+0000] {subprocess.py:106} INFO - 25/04/02 09:18:23 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
[2025-04-02T09:18:23.725+0000] {subprocess.py:106} INFO - 25/04/02 09:18:23 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
[2025-04-02T09:18:23.913+0000] {subprocess.py:106} INFO - 25/04/02 09:18:23 INFO HadoopRDD: Input split: file:/dbt/dbt-spark-project/spark-warehouse/transformed_data/part-00002-98b16163-b9f2-4b2a-9ea4-f57dfa66f8b8-c000:0+11
[2025-04-02T09:18:23.915+0000] {subprocess.py:106} INFO - 25/04/02 09:18:23 INFO HadoopRDD: Input split: file:/dbt/dbt-spark-project/spark-warehouse/transformed_data/part-00000-98b16163-b9f2-4b2a-9ea4-f57dfa66f8b8-c000:0+13
[2025-04-02T09:18:23.916+0000] {subprocess.py:106} INFO - 25/04/02 09:18:23 INFO HadoopRDD: Input split: file:/dbt/dbt-spark-project/spark-warehouse/transformed_data/part-00001-98b16163-b9f2-4b2a-9ea4-f57dfa66f8b8-c000:0+9
[2025-04-02T09:18:24.402+0000] {subprocess.py:106} INFO - 25/04/02 09:18:24 INFO CodeGenerator: Code generated in 337.172914 ms
[2025-04-02T09:18:25.668+0000] {subprocess.py:106} INFO - 25/04/02 09:18:25 INFO CodeGenerator: Code generated in 21.534848 ms
[2025-04-02T09:18:25.788+0000] {subprocess.py:106} INFO - 25/04/02 09:18:25 WARN JdbcUtils: Requested isolation level 1 is not supported; falling back to default isolation level 2
[2025-04-02T09:18:25.790+0000] {subprocess.py:106} INFO - 25/04/02 09:18:25 WARN JdbcUtils: Requested isolation level 1 is not supported; falling back to default isolation level 2
[2025-04-02T09:18:25.795+0000] {subprocess.py:106} INFO - 25/04/02 09:18:25 WARN JdbcUtils: Requested isolation level 1 is not supported; falling back to default isolation level 2
[2025-04-02T09:18:25.900+0000] {subprocess.py:106} INFO - 25/04/02 09:18:25 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1287 bytes result sent to driver
[2025-04-02T09:18:25.902+0000] {subprocess.py:106} INFO - 25/04/02 09:18:25 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1330 bytes result sent to driver
[2025-04-02T09:18:25.904+0000] {subprocess.py:106} INFO - 25/04/02 09:18:25 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1330 bytes result sent to driver
[2025-04-02T09:18:25.933+0000] {subprocess.py:106} INFO - 25/04/02 09:18:25 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2262 ms on a72b9165479b (executor driver) (1/3)
[2025-04-02T09:18:25.934+0000] {subprocess.py:106} INFO - 25/04/02 09:18:25 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 2239 ms on a72b9165479b (executor driver) (2/3)
[2025-04-02T09:18:25.936+0000] {subprocess.py:106} INFO - 25/04/02 09:18:25 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 2241 ms on a72b9165479b (executor driver) (3/3)
[2025-04-02T09:18:25.937+0000] {subprocess.py:106} INFO - 25/04/02 09:18:25 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2025-04-02T09:18:25.946+0000] {subprocess.py:106} INFO - 25/04/02 09:18:25 INFO DAGScheduler: ResultStage 0 (jdbc at NativeMethodAccessorImpl.java:0) finished in 2.497 s
[2025-04-02T09:18:25.950+0000] {subprocess.py:106} INFO - 25/04/02 09:18:25 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-04-02T09:18:25.952+0000] {subprocess.py:106} INFO - 25/04/02 09:18:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
[2025-04-02T09:18:25.957+0000] {subprocess.py:106} INFO - 25/04/02 09:18:25 INFO DAGScheduler: Job 0 finished: jdbc at NativeMethodAccessorImpl.java:0, took 2.578750 s
[2025-04-02T09:18:26.066+0000] {subprocess.py:106} INFO - Data successfully written to METADATA.TEST
[2025-04-02T09:18:26.103+0000] {subprocess.py:106} INFO - 25/04/02 09:18:26 INFO HiveMetaStore: 0: get_database: default
[2025-04-02T09:18:26.104+0000] {subprocess.py:106} INFO - 25/04/02 09:18:26 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_database: default
[2025-04-02T09:18:26.122+0000] {subprocess.py:106} INFO - 25/04/02 09:18:26 WARN HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist
[2025-04-02T09:18:26.124+0000] {subprocess.py:106} INFO - 25/04/02 09:18:26 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
[2025-04-02T09:18:26.128+0000] {subprocess.py:106} INFO - 25/04/02 09:18:26 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
[2025-04-02T09:18:26.130+0000] {subprocess.py:106} INFO - 25/04/02 09:18:26 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
[2025-04-02T09:18:26.132+0000] {subprocess.py:106} INFO - 25/04/02 09:18:26 INFO ObjectStore: ObjectStore, initialize called
[2025-04-02T09:18:26.138+0000] {subprocess.py:106} INFO - 25/04/02 09:18:26 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
[2025-04-02T09:18:26.139+0000] {subprocess.py:106} INFO - 25/04/02 09:18:26 INFO ObjectStore: Initialized ObjectStore
[2025-04-02T09:18:26.142+0000] {subprocess.py:106} INFO - 25/04/02 09:18:26 INFO HiveMetaStore: 0: get_table : db=default tbl=transformed_data
[2025-04-02T09:18:26.144+0000] {subprocess.py:106} INFO - 25/04/02 09:18:26 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_table : db=default tbl=transformed_data
[2025-04-02T09:18:26.161+0000] {subprocess.py:106} INFO - 25/04/02 09:18:26 INFO HiveMetaStore: 0: get_table : db=default tbl=transformed_data
[2025-04-02T09:18:26.163+0000] {subprocess.py:106} INFO - 25/04/02 09:18:26 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_table : db=default tbl=transformed_data
[2025-04-02T09:18:26.182+0000] {subprocess.py:106} INFO - 25/04/02 09:18:26 INFO HiveMetaStore: 0: get_database: default
[2025-04-02T09:18:26.183+0000] {subprocess.py:106} INFO - 25/04/02 09:18:26 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_database: default
[2025-04-02T09:18:26.185+0000] {subprocess.py:106} INFO - 25/04/02 09:18:26 INFO HiveMetaStore: 0: get_table : db=default tbl=transformed_data
[2025-04-02T09:18:26.186+0000] {subprocess.py:106} INFO - 25/04/02 09:18:26 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_table : db=default tbl=transformed_data
[2025-04-02T09:18:26.202+0000] {subprocess.py:106} INFO - 25/04/02 09:18:26 INFO HiveMetaStore: 0: get_table : db=default tbl=transformed_data
[2025-04-02T09:18:26.203+0000] {subprocess.py:106} INFO - 25/04/02 09:18:26 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_table : db=default tbl=transformed_data
[2025-04-02T09:18:26.225+0000] {subprocess.py:106} INFO - 25/04/02 09:18:26 INFO HiveMetaStore: 0: get_database: default
[2025-04-02T09:18:26.226+0000] {subprocess.py:106} INFO - 25/04/02 09:18:26 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_database: default
[2025-04-02T09:18:26.229+0000] {subprocess.py:106} INFO - 25/04/02 09:18:26 INFO HiveMetaStore: 0: get_table : db=default tbl=transformed_data
[2025-04-02T09:18:26.230+0000] {subprocess.py:106} INFO - 25/04/02 09:18:26 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_table : db=default tbl=transformed_data
[2025-04-02T09:18:26.253+0000] {subprocess.py:106} INFO - 25/04/02 09:18:26 INFO HiveMetaStore: 0: get_database: default
[2025-04-02T09:18:26.254+0000] {subprocess.py:106} INFO - 25/04/02 09:18:26 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_database: default
[2025-04-02T09:18:26.265+0000] {subprocess.py:106} INFO - 25/04/02 09:18:26 INFO HiveMetaStore: 0: get_table : db=default tbl=transformed_data
[2025-04-02T09:18:26.266+0000] {subprocess.py:106} INFO - 25/04/02 09:18:26 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_table : db=default tbl=transformed_data
[2025-04-02T09:18:26.286+0000] {subprocess.py:106} INFO - 25/04/02 09:18:26 INFO HiveMetaStore: 0: drop_table : db=default tbl=transformed_data
[2025-04-02T09:18:26.287+0000] {subprocess.py:106} INFO - 25/04/02 09:18:26 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=drop_table : db=default tbl=transformed_data
[2025-04-02T09:18:26.842+0000] {subprocess.py:106} INFO - 25/04/02 09:18:26 INFO deprecation: org.apache.hadoop.shaded.io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
[2025-04-02T09:18:26.858+0000] {subprocess.py:106} INFO - Processing table default.transformed_data2 to METADATA.TEST2
[2025-04-02T09:18:26.864+0000] {subprocess.py:106} INFO - 25/04/02 09:18:26 INFO HiveMetaStore: 0: get_database: default
[2025-04-02T09:18:26.865+0000] {subprocess.py:106} INFO - 25/04/02 09:18:26 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_database: default
[2025-04-02T09:18:26.868+0000] {subprocess.py:106} INFO - 25/04/02 09:18:26 INFO HiveMetaStore: 0: get_table : db=default tbl=transformed_data2
[2025-04-02T09:18:26.869+0000] {subprocess.py:106} INFO - 25/04/02 09:18:26 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_table : db=default tbl=transformed_data2
[2025-04-02T09:18:26.889+0000] {subprocess.py:106} INFO - 25/04/02 09:18:26 INFO HiveMetaStore: 0: get_table : db=default tbl=transformed_data2
[2025-04-02T09:18:26.890+0000] {subprocess.py:106} INFO - 25/04/02 09:18:26 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_table : db=default tbl=transformed_data2
[2025-04-02T09:18:27.056+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 200.6 KiB, free 433.9 MiB)
[2025-04-02T09:18:27.071+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 34.6 KiB, free 433.9 MiB)
[2025-04-02T09:18:27.072+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on a72b9165479b:39593 (size: 34.6 KiB, free: 434.3 MiB)
[2025-04-02T09:18:27.074+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO SparkContext: Created broadcast 2 from
[2025-04-02T09:18:27.115+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO FileInputFormat: Total input files to process : 3
[2025-04-02T09:18:27.135+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO SparkContext: Starting job: jdbc at NativeMethodAccessorImpl.java:0
[2025-04-02T09:18:27.137+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO DAGScheduler: Got job 1 (jdbc at NativeMethodAccessorImpl.java:0) with 3 output partitions
[2025-04-02T09:18:27.139+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO DAGScheduler: Final stage: ResultStage 1 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-04-02T09:18:27.140+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO DAGScheduler: Parents of final stage: List()
[2025-04-02T09:18:27.142+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO DAGScheduler: Missing parents: List()
[2025-04-02T09:18:27.143+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-04-02T09:18:27.148+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 29.4 KiB, free 433.9 MiB)
[2025-04-02T09:18:27.152+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 13.8 KiB, free 433.9 MiB)
[2025-04-02T09:18:27.153+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on a72b9165479b:39593 (size: 13.8 KiB, free: 434.3 MiB)
[2025-04-02T09:18:27.154+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585
[2025-04-02T09:18:27.156+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2))
[2025-04-02T09:18:27.158+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO TaskSchedulerImpl: Adding task set 1.0 with 3 tasks resource profile 0
[2025-04-02T09:18:27.160+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 3) (a72b9165479b, executor driver, partition 0, PROCESS_LOCAL, 9299 bytes)
[2025-04-02T09:18:27.161+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 4) (a72b9165479b, executor driver, partition 1, PROCESS_LOCAL, 9299 bytes)
[2025-04-02T09:18:27.163+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 5) (a72b9165479b, executor driver, partition 2, PROCESS_LOCAL, 9299 bytes)
[2025-04-02T09:18:27.166+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO Executor: Running task 0.0 in stage 1.0 (TID 3)
[2025-04-02T09:18:27.170+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO Executor: Running task 2.0 in stage 1.0 (TID 5)
[2025-04-02T09:18:27.174+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO Executor: Running task 1.0 in stage 1.0 (TID 4)
[2025-04-02T09:18:27.184+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO HadoopRDD: Input split: file:/dbt/dbt-spark-project/spark-warehouse/transformed_data2/part-00001-a81e19fd-eefe-4b8b-bf03-f0cd19cc0185-c000:0+9
[2025-04-02T09:18:27.185+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO HadoopRDD: Input split: file:/dbt/dbt-spark-project/spark-warehouse/transformed_data2/part-00000-a81e19fd-eefe-4b8b-bf03-f0cd19cc0185-c000:0+13
[2025-04-02T09:18:27.186+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO HadoopRDD: Input split: file:/dbt/dbt-spark-project/spark-warehouse/transformed_data2/part-00002-a81e19fd-eefe-4b8b-bf03-f0cd19cc0185-c000:0+11
[2025-04-02T09:18:27.302+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 WARN JdbcUtils: Requested isolation level 1 is not supported; falling back to default isolation level 2
[2025-04-02T09:18:27.307+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 WARN JdbcUtils: Requested isolation level 1 is not supported; falling back to default isolation level 2
[2025-04-02T09:18:27.311+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 WARN JdbcUtils: Requested isolation level 1 is not supported; falling back to default isolation level 2
[2025-04-02T09:18:27.331+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO Executor: Finished task 1.0 in stage 1.0 (TID 4). 1244 bytes result sent to driver
[2025-04-02T09:18:27.340+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 4) in 179 ms on a72b9165479b (executor driver) (1/3)
[2025-04-02T09:18:27.346+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO Executor: Finished task 2.0 in stage 1.0 (TID 5). 1287 bytes result sent to driver
[2025-04-02T09:18:27.350+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 5) in 188 ms on a72b9165479b (executor driver) (2/3)
[2025-04-02T09:18:27.354+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO Executor: Finished task 0.0 in stage 1.0 (TID 3). 1287 bytes result sent to driver
[2025-04-02T09:18:27.357+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 3) in 197 ms on a72b9165479b (executor driver) (3/3)
[2025-04-02T09:18:27.360+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
[2025-04-02T09:18:27.364+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO DAGScheduler: ResultStage 1 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.217 s
[2025-04-02T09:18:27.367+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-04-02T09:18:27.371+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
[2025-04-02T09:18:27.374+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO DAGScheduler: Job 1 finished: jdbc at NativeMethodAccessorImpl.java:0, took 0.227799 s
[2025-04-02T09:18:27.496+0000] {subprocess.py:106} INFO - Data successfully written to METADATA.TEST2
[2025-04-02T09:18:27.542+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO HiveMetaStore: 0: get_database: default
[2025-04-02T09:18:27.545+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_database: default
[2025-04-02T09:18:27.551+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO HiveMetaStore: 0: get_table : db=default tbl=transformed_data2
[2025-04-02T09:18:27.554+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_table : db=default tbl=transformed_data2
[2025-04-02T09:18:27.585+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO HiveMetaStore: 0: get_table : db=default tbl=transformed_data2
[2025-04-02T09:18:27.586+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_table : db=default tbl=transformed_data2
[2025-04-02T09:18:27.612+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO HiveMetaStore: 0: get_database: default
[2025-04-02T09:18:27.612+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_database: default
[2025-04-02T09:18:27.615+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO HiveMetaStore: 0: get_table : db=default tbl=transformed_data2
[2025-04-02T09:18:27.616+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_table : db=default tbl=transformed_data2
[2025-04-02T09:18:27.633+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO HiveMetaStore: 0: get_table : db=default tbl=transformed_data2
[2025-04-02T09:18:27.634+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_table : db=default tbl=transformed_data2
[2025-04-02T09:18:27.660+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO HiveMetaStore: 0: get_database: default
[2025-04-02T09:18:27.661+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_database: default
[2025-04-02T09:18:27.664+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO HiveMetaStore: 0: get_table : db=default tbl=transformed_data2
[2025-04-02T09:18:27.665+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_table : db=default tbl=transformed_data2
[2025-04-02T09:18:27.693+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO HiveMetaStore: 0: get_database: default
[2025-04-02T09:18:27.694+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_database: default
[2025-04-02T09:18:27.697+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO HiveMetaStore: 0: get_table : db=default tbl=transformed_data2
[2025-04-02T09:18:27.698+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_table : db=default tbl=transformed_data2
[2025-04-02T09:18:27.713+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO HiveMetaStore: 0: drop_table : db=default tbl=transformed_data2
[2025-04-02T09:18:27.714+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=drop_table : db=default tbl=transformed_data2
[2025-04-02T09:18:27.774+0000] {subprocess.py:106} INFO - Processing table default.transformed_data3 to METADATA.TEST3
[2025-04-02T09:18:27.781+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO HiveMetaStore: 0: get_database: default
[2025-04-02T09:18:27.781+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_database: default
[2025-04-02T09:18:27.785+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO HiveMetaStore: 0: get_table : db=default tbl=transformed_data3
[2025-04-02T09:18:27.785+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_table : db=default tbl=transformed_data3
[2025-04-02T09:18:27.802+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO HiveMetaStore: 0: get_table : db=default tbl=transformed_data3
[2025-04-02T09:18:27.803+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_table : db=default tbl=transformed_data3
[2025-04-02T09:18:27.963+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 200.6 KiB, free 433.7 MiB)
[2025-04-02T09:18:27.974+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 34.6 KiB, free 433.6 MiB)
[2025-04-02T09:18:27.975+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on a72b9165479b:39593 (size: 34.6 KiB, free: 434.3 MiB)
[2025-04-02T09:18:27.977+0000] {subprocess.py:106} INFO - 25/04/02 09:18:27 INFO SparkContext: Created broadcast 4 from
[2025-04-02T09:18:28.030+0000] {subprocess.py:106} INFO - 25/04/02 09:18:28 INFO FileInputFormat: Total input files to process : 3
[2025-04-02T09:18:28.064+0000] {subprocess.py:106} INFO - 25/04/02 09:18:28 INFO SparkContext: Starting job: jdbc at NativeMethodAccessorImpl.java:0
[2025-04-02T09:18:28.067+0000] {subprocess.py:106} INFO - 25/04/02 09:18:28 INFO DAGScheduler: Got job 2 (jdbc at NativeMethodAccessorImpl.java:0) with 3 output partitions
[2025-04-02T09:18:28.068+0000] {subprocess.py:106} INFO - 25/04/02 09:18:28 INFO DAGScheduler: Final stage: ResultStage 2 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-04-02T09:18:28.070+0000] {subprocess.py:106} INFO - 25/04/02 09:18:28 INFO DAGScheduler: Parents of final stage: List()
[2025-04-02T09:18:28.072+0000] {subprocess.py:106} INFO - 25/04/02 09:18:28 INFO DAGScheduler: Missing parents: List()
[2025-04-02T09:18:28.073+0000] {subprocess.py:106} INFO - 25/04/02 09:18:28 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[20] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-04-02T09:18:28.078+0000] {subprocess.py:106} INFO - 25/04/02 09:18:28 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 29.4 KiB, free 433.6 MiB)
[2025-04-02T09:18:28.094+0000] {subprocess.py:106} INFO - 25/04/02 09:18:28 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 13.9 KiB, free 433.6 MiB)
[2025-04-02T09:18:28.107+0000] {subprocess.py:106} INFO - 25/04/02 09:18:28 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on a72b9165479b:39593 (size: 13.9 KiB, free: 434.3 MiB)
[2025-04-02T09:18:28.110+0000] {subprocess.py:106} INFO - 25/04/02 09:18:28 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1585
[2025-04-02T09:18:28.115+0000] {subprocess.py:106} INFO - 25/04/02 09:18:28 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 2 (MapPartitionsRDD[20] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2))
[2025-04-02T09:18:28.120+0000] {subprocess.py:106} INFO - 25/04/02 09:18:28 INFO TaskSchedulerImpl: Adding task set 2.0 with 3 tasks resource profile 0
[2025-04-02T09:18:28.126+0000] {subprocess.py:106} INFO - 25/04/02 09:18:28 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 6) (a72b9165479b, executor driver, partition 0, PROCESS_LOCAL, 9299 bytes)
[2025-04-02T09:18:28.130+0000] {subprocess.py:106} INFO - 25/04/02 09:18:28 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 7) (a72b9165479b, executor driver, partition 1, PROCESS_LOCAL, 9299 bytes)
[2025-04-02T09:18:28.132+0000] {subprocess.py:106} INFO - 25/04/02 09:18:28 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 8) (a72b9165479b, executor driver, partition 2, PROCESS_LOCAL, 9299 bytes)
[2025-04-02T09:18:28.136+0000] {subprocess.py:106} INFO - 25/04/02 09:18:28 INFO Executor: Running task 1.0 in stage 2.0 (TID 7)
[2025-04-02T09:18:28.138+0000] {subprocess.py:106} INFO - 25/04/02 09:18:28 INFO Executor: Running task 0.0 in stage 2.0 (TID 6)
[2025-04-02T09:18:28.140+0000] {subprocess.py:106} INFO - 25/04/02 09:18:28 INFO BlockManagerInfo: Removed broadcast_3_piece0 on a72b9165479b:39593 in memory (size: 13.8 KiB, free: 434.3 MiB)
[2025-04-02T09:18:28.143+0000] {subprocess.py:106} INFO - 25/04/02 09:18:28 INFO Executor: Running task 2.0 in stage 2.0 (TID 8)
[2025-04-02T09:18:28.144+0000] {subprocess.py:106} INFO - 25/04/02 09:18:28 INFO HadoopRDD: Input split: file:/dbt/dbt-spark-project/spark-warehouse/transformed_data3/part-00000-e1cfa76b-b985-47cf-a5ef-3710398db96f-c000:0+14
[2025-04-02T09:18:28.146+0000] {subprocess.py:106} INFO - 25/04/02 09:18:28 INFO HadoopRDD: Input split: file:/dbt/dbt-spark-project/spark-warehouse/transformed_data3/part-00001-e1cfa76b-b985-47cf-a5ef-3710398db96f-c000:0+9
[2025-04-02T09:18:28.149+0000] {subprocess.py:106} INFO - 25/04/02 09:18:28 INFO BlockManagerInfo: Removed broadcast_2_piece0 on a72b9165479b:39593 in memory (size: 34.6 KiB, free: 434.3 MiB)
[2025-04-02T09:18:28.151+0000] {subprocess.py:106} INFO - 25/04/02 09:18:28 INFO HadoopRDD: Input split: file:/dbt/dbt-spark-project/spark-warehouse/transformed_data3/part-00002-e1cfa76b-b985-47cf-a5ef-3710398db96f-c000:0+11
[2025-04-02T09:18:28.191+0000] {subprocess.py:106} INFO - 25/04/02 09:18:28 INFO BlockManagerInfo: Removed broadcast_1_piece0 on a72b9165479b:39593 in memory (size: 13.9 KiB, free: 434.3 MiB)
[2025-04-02T09:18:28.203+0000] {subprocess.py:106} INFO - 25/04/02 09:18:28 INFO BlockManagerInfo: Removed broadcast_0_piece0 on a72b9165479b:39593 in memory (size: 34.6 KiB, free: 434.4 MiB)
[2025-04-02T09:18:28.395+0000] {subprocess.py:106} INFO - 25/04/02 09:18:28 WARN JdbcUtils: Requested isolation level 1 is not supported; falling back to default isolation level 2
[2025-04-02T09:18:28.405+0000] {subprocess.py:106} INFO - 25/04/02 09:18:28 WARN JdbcUtils: Requested isolation level 1 is not supported; falling back to default isolation level 2
[2025-04-02T09:18:28.440+0000] {subprocess.py:106} INFO - 25/04/02 09:18:28 INFO Executor: Finished task 1.0 in stage 2.0 (TID 7). 1287 bytes result sent to driver
[2025-04-02T09:18:28.442+0000] {subprocess.py:106} INFO - 25/04/02 09:18:28 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 7) in 327 ms on a72b9165479b (executor driver) (1/3)
[2025-04-02T09:18:28.453+0000] {subprocess.py:106} INFO - 25/04/02 09:18:28 INFO Executor: Finished task 2.0 in stage 2.0 (TID 8). 1287 bytes result sent to driver
[2025-04-02T09:18:28.455+0000] {subprocess.py:106} INFO - 25/04/02 09:18:28 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 8) in 337 ms on a72b9165479b (executor driver) (2/3)
[2025-04-02T09:18:29.315+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 WARN JdbcUtils: Requested isolation level 1 is not supported; falling back to default isolation level 2
[2025-04-02T09:18:29.338+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 INFO Executor: Finished task 0.0 in stage 2.0 (TID 6). 1287 bytes result sent to driver
[2025-04-02T09:18:29.342+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 6) in 1228 ms on a72b9165479b (executor driver) (3/3)
[2025-04-02T09:18:29.344+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2025-04-02T09:18:29.347+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 INFO DAGScheduler: ResultStage 2 (jdbc at NativeMethodAccessorImpl.java:0) finished in 1.271 s
[2025-04-02T09:18:29.349+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-04-02T09:18:29.351+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
[2025-04-02T09:18:29.353+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 INFO DAGScheduler: Job 2 finished: jdbc at NativeMethodAccessorImpl.java:0, took 1.281048 s
[2025-04-02T09:18:29.445+0000] {subprocess.py:106} INFO - Data successfully written to METADATA.TEST3
[2025-04-02T09:18:29.466+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 INFO HiveMetaStore: 0: get_database: default
[2025-04-02T09:18:29.469+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_database: default
[2025-04-02T09:18:29.471+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 INFO HiveMetaStore: 0: get_table : db=default tbl=transformed_data3
[2025-04-02T09:18:29.476+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_table : db=default tbl=transformed_data3
[2025-04-02T09:18:29.500+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 INFO HiveMetaStore: 0: get_table : db=default tbl=transformed_data3
[2025-04-02T09:18:29.502+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_table : db=default tbl=transformed_data3
[2025-04-02T09:18:29.522+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 INFO HiveMetaStore: 0: get_database: default
[2025-04-02T09:18:29.523+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_database: default
[2025-04-02T09:18:29.527+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 INFO HiveMetaStore: 0: get_table : db=default tbl=transformed_data3
[2025-04-02T09:18:29.528+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_table : db=default tbl=transformed_data3
[2025-04-02T09:18:29.544+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 INFO HiveMetaStore: 0: get_table : db=default tbl=transformed_data3
[2025-04-02T09:18:29.545+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_table : db=default tbl=transformed_data3
[2025-04-02T09:18:29.565+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 INFO HiveMetaStore: 0: get_database: default
[2025-04-02T09:18:29.566+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_database: default
[2025-04-02T09:18:29.569+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 INFO HiveMetaStore: 0: get_table : db=default tbl=transformed_data3
[2025-04-02T09:18:29.570+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_table : db=default tbl=transformed_data3
[2025-04-02T09:18:29.590+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 INFO HiveMetaStore: 0: get_database: default
[2025-04-02T09:18:29.592+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_database: default
[2025-04-02T09:18:29.596+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 INFO HiveMetaStore: 0: get_table : db=default tbl=transformed_data3
[2025-04-02T09:18:29.599+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_table : db=default tbl=transformed_data3
[2025-04-02T09:18:29.626+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 INFO HiveMetaStore: 0: drop_table : db=default tbl=transformed_data3
[2025-04-02T09:18:29.629+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=drop_table : db=default tbl=transformed_data3
[2025-04-02T09:18:29.719+0000] {subprocess.py:106} INFO - Processing table default.transformed_data4 to METADATA.TEST4
[2025-04-02T09:18:29.728+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 INFO HiveMetaStore: 0: get_database: default
[2025-04-02T09:18:29.729+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_database: default
[2025-04-02T09:18:29.732+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 INFO HiveMetaStore: 0: get_table : db=default tbl=transformed_data4
[2025-04-02T09:18:29.734+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_table : db=default tbl=transformed_data4
[2025-04-02T09:18:29.749+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 INFO HiveMetaStore: 0: get_table : db=default tbl=transformed_data4
[2025-04-02T09:18:29.750+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_table : db=default tbl=transformed_data4
[2025-04-02T09:18:29.912+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 200.6 KiB, free 433.9 MiB)
[2025-04-02T09:18:29.932+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 34.6 KiB, free 433.9 MiB)
[2025-04-02T09:18:29.935+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on a72b9165479b:39593 (size: 34.6 KiB, free: 434.3 MiB)
[2025-04-02T09:18:29.937+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 INFO SparkContext: Created broadcast 6 from
[2025-04-02T09:18:29.993+0000] {subprocess.py:106} INFO - 25/04/02 09:18:29 INFO FileInputFormat: Total input files to process : 3
[2025-04-02T09:18:30.004+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO SparkContext: Starting job: jdbc at NativeMethodAccessorImpl.java:0
[2025-04-02T09:18:30.007+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO DAGScheduler: Got job 3 (jdbc at NativeMethodAccessorImpl.java:0) with 3 output partitions
[2025-04-02T09:18:30.011+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO DAGScheduler: Final stage: ResultStage 3 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-04-02T09:18:30.017+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO DAGScheduler: Parents of final stage: List()
[2025-04-02T09:18:30.022+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO DAGScheduler: Missing parents: List()
[2025-04-02T09:18:30.025+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[27] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-04-02T09:18:30.030+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 29.4 KiB, free 433.9 MiB)
[2025-04-02T09:18:30.033+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 13.9 KiB, free 433.9 MiB)
[2025-04-02T09:18:30.037+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on a72b9165479b:39593 (size: 13.9 KiB, free: 434.3 MiB)
[2025-04-02T09:18:30.041+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1585
[2025-04-02T09:18:30.043+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 3 (MapPartitionsRDD[27] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2))
[2025-04-02T09:18:30.046+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO TaskSchedulerImpl: Adding task set 3.0 with 3 tasks resource profile 0
[2025-04-02T09:18:30.050+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 9) (a72b9165479b, executor driver, partition 0, PROCESS_LOCAL, 9299 bytes)
[2025-04-02T09:18:30.052+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 10) (a72b9165479b, executor driver, partition 1, PROCESS_LOCAL, 9299 bytes)
[2025-04-02T09:18:30.054+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 11) (a72b9165479b, executor driver, partition 2, PROCESS_LOCAL, 9299 bytes)
[2025-04-02T09:18:30.056+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO Executor: Running task 0.0 in stage 3.0 (TID 9)
[2025-04-02T09:18:30.059+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO Executor: Running task 1.0 in stage 3.0 (TID 10)
[2025-04-02T09:18:30.067+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO Executor: Running task 2.0 in stage 3.0 (TID 11)
[2025-04-02T09:18:30.076+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO HadoopRDD: Input split: file:/dbt/dbt-spark-project/spark-warehouse/transformed_data4/part-00002-26a1ce20-fce0-41a4-97e7-162015d57fd5-c000:0+11
[2025-04-02T09:18:30.087+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO HadoopRDD: Input split: file:/dbt/dbt-spark-project/spark-warehouse/transformed_data4/part-00001-26a1ce20-fce0-41a4-97e7-162015d57fd5-c000:0+10
[2025-04-02T09:18:30.097+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO HadoopRDD: Input split: file:/dbt/dbt-spark-project/spark-warehouse/transformed_data4/part-00000-26a1ce20-fce0-41a4-97e7-162015d57fd5-c000:0+14
[2025-04-02T09:18:30.220+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 WARN JdbcUtils: Requested isolation level 1 is not supported; falling back to default isolation level 2
[2025-04-02T09:18:30.227+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 WARN JdbcUtils: Requested isolation level 1 is not supported; falling back to default isolation level 2
[2025-04-02T09:18:30.233+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 WARN JdbcUtils: Requested isolation level 1 is not supported; falling back to default isolation level 2
[2025-04-02T09:18:30.254+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO Executor: Finished task 0.0 in stage 3.0 (TID 9). 1244 bytes result sent to driver
[2025-04-02T09:18:30.255+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO Executor: Finished task 1.0 in stage 3.0 (TID 10). 1244 bytes result sent to driver
[2025-04-02T09:18:30.257+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 9) in 217 ms on a72b9165479b (executor driver) (1/3)
[2025-04-02T09:18:30.261+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO Executor: Finished task 2.0 in stage 3.0 (TID 11). 1244 bytes result sent to driver
[2025-04-02T09:18:30.267+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 10) in 219 ms on a72b9165479b (executor driver) (2/3)
[2025-04-02T09:18:30.270+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 11) in 218 ms on a72b9165479b (executor driver) (3/3)
[2025-04-02T09:18:30.276+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
[2025-04-02T09:18:30.285+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO DAGScheduler: ResultStage 3 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.258 s
[2025-04-02T09:18:30.291+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-04-02T09:18:30.298+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
[2025-04-02T09:18:30.308+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO DAGScheduler: Job 3 finished: jdbc at NativeMethodAccessorImpl.java:0, took 0.270814 s
[2025-04-02T09:18:30.405+0000] {subprocess.py:106} INFO - Data successfully written to METADATA.TEST4
[2025-04-02T09:18:30.425+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO HiveMetaStore: 0: get_database: default
[2025-04-02T09:18:30.427+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_database: default
[2025-04-02T09:18:30.430+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO HiveMetaStore: 0: get_table : db=default tbl=transformed_data4
[2025-04-02T09:18:30.433+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_table : db=default tbl=transformed_data4
[2025-04-02T09:18:30.449+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO HiveMetaStore: 0: get_table : db=default tbl=transformed_data4
[2025-04-02T09:18:30.451+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_table : db=default tbl=transformed_data4
[2025-04-02T09:18:30.470+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO HiveMetaStore: 0: get_database: default
[2025-04-02T09:18:30.471+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_database: default
[2025-04-02T09:18:30.474+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO HiveMetaStore: 0: get_table : db=default tbl=transformed_data4
[2025-04-02T09:18:30.475+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_table : db=default tbl=transformed_data4
[2025-04-02T09:18:30.490+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO HiveMetaStore: 0: get_table : db=default tbl=transformed_data4
[2025-04-02T09:18:30.492+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_table : db=default tbl=transformed_data4
[2025-04-02T09:18:30.511+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO HiveMetaStore: 0: get_database: default
[2025-04-02T09:18:30.514+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_database: default
[2025-04-02T09:18:30.517+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO HiveMetaStore: 0: get_table : db=default tbl=transformed_data4
[2025-04-02T09:18:30.519+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_table : db=default tbl=transformed_data4
[2025-04-02T09:18:30.535+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO HiveMetaStore: 0: get_database: default
[2025-04-02T09:18:30.536+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_database: default
[2025-04-02T09:18:30.538+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO HiveMetaStore: 0: get_table : db=default tbl=transformed_data4
[2025-04-02T09:18:30.539+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_table : db=default tbl=transformed_data4
[2025-04-02T09:18:30.555+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO HiveMetaStore: 0: drop_table : db=default tbl=transformed_data4
[2025-04-02T09:18:30.556+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=drop_table : db=default tbl=transformed_data4
[2025-04-02T09:18:30.674+0000] {subprocess.py:106} INFO - Processing table default.transformed_data5 to METADATA.TEST5
[2025-04-02T09:18:30.684+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO HiveMetaStore: 0: get_database: default
[2025-04-02T09:18:30.685+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_database: default
[2025-04-02T09:18:30.687+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO HiveMetaStore: 0: get_table : db=default tbl=transformed_data5
[2025-04-02T09:18:30.688+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_table : db=default tbl=transformed_data5
[2025-04-02T09:18:30.702+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO HiveMetaStore: 0: get_table : db=default tbl=transformed_data5
[2025-04-02T09:18:30.703+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_table : db=default tbl=transformed_data5
[2025-04-02T09:18:30.746+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO BlockManagerInfo: Removed broadcast_6_piece0 on a72b9165479b:39593 in memory (size: 34.6 KiB, free: 434.3 MiB)
[2025-04-02T09:18:30.753+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO BlockManagerInfo: Removed broadcast_7_piece0 on a72b9165479b:39593 in memory (size: 13.9 KiB, free: 434.4 MiB)
[2025-04-02T09:18:30.759+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO BlockManagerInfo: Removed broadcast_4_piece0 on a72b9165479b:39593 in memory (size: 34.6 KiB, free: 434.4 MiB)
[2025-04-02T09:18:30.769+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO BlockManagerInfo: Removed broadcast_5_piece0 on a72b9165479b:39593 in memory (size: 13.9 KiB, free: 434.4 MiB)
[2025-04-02T09:18:30.884+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 200.6 KiB, free 434.2 MiB)
[2025-04-02T09:18:30.899+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 34.6 KiB, free 434.2 MiB)
[2025-04-02T09:18:30.901+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on a72b9165479b:39593 (size: 34.6 KiB, free: 434.4 MiB)
[2025-04-02T09:18:30.902+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO SparkContext: Created broadcast 8 from
[2025-04-02T09:18:30.952+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO FileInputFormat: Total input files to process : 3
[2025-04-02T09:18:30.964+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO SparkContext: Starting job: jdbc at NativeMethodAccessorImpl.java:0
[2025-04-02T09:18:30.967+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO DAGScheduler: Got job 4 (jdbc at NativeMethodAccessorImpl.java:0) with 3 output partitions
[2025-04-02T09:18:30.969+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO DAGScheduler: Final stage: ResultStage 4 (jdbc at NativeMethodAccessorImpl.java:0)
[2025-04-02T09:18:30.972+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO DAGScheduler: Parents of final stage: List()
[2025-04-02T09:18:30.975+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO DAGScheduler: Missing parents: List()
[2025-04-02T09:18:30.977+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[34] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-04-02T09:18:30.982+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 29.4 KiB, free 434.1 MiB)
[2025-04-02T09:18:30.988+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 13.9 KiB, free 434.1 MiB)
[2025-04-02T09:18:30.990+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on a72b9165479b:39593 (size: 13.9 KiB, free: 434.4 MiB)
[2025-04-02T09:18:30.991+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1585
[2025-04-02T09:18:30.996+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 4 (MapPartitionsRDD[34] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2))
[2025-04-02T09:18:31.000+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO TaskSchedulerImpl: Adding task set 4.0 with 3 tasks resource profile 0
[2025-04-02T09:18:31.006+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 12) (a72b9165479b, executor driver, partition 0, PROCESS_LOCAL, 9299 bytes)
[2025-04-02T09:18:31.008+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 13) (a72b9165479b, executor driver, partition 1, PROCESS_LOCAL, 9299 bytes)
[2025-04-02T09:18:31.011+0000] {subprocess.py:106} INFO - 25/04/02 09:18:30 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 14) (a72b9165479b, executor driver, partition 2, PROCESS_LOCAL, 9299 bytes)
[2025-04-02T09:18:31.015+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO Executor: Running task 0.0 in stage 4.0 (TID 12)
[2025-04-02T09:18:31.019+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO Executor: Running task 1.0 in stage 4.0 (TID 13)
[2025-04-02T09:18:31.022+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO Executor: Running task 2.0 in stage 4.0 (TID 14)
[2025-04-02T09:18:31.025+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO HadoopRDD: Input split: file:/dbt/dbt-spark-project/spark-warehouse/transformed_data5/part-00002-95e31a26-0ff7-4612-b852-5f8ca1ed82f2-c000:0+11
[2025-04-02T09:18:31.028+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO HadoopRDD: Input split: file:/dbt/dbt-spark-project/spark-warehouse/transformed_data5/part-00000-95e31a26-0ff7-4612-b852-5f8ca1ed82f2-c000:0+14
[2025-04-02T09:18:31.035+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO HadoopRDD: Input split: file:/dbt/dbt-spark-project/spark-warehouse/transformed_data5/part-00001-95e31a26-0ff7-4612-b852-5f8ca1ed82f2-c000:0+10
[2025-04-02T09:18:31.137+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 WARN JdbcUtils: Requested isolation level 1 is not supported; falling back to default isolation level 2
[2025-04-02T09:18:31.141+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 WARN JdbcUtils: Requested isolation level 1 is not supported; falling back to default isolation level 2
[2025-04-02T09:18:31.147+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 WARN JdbcUtils: Requested isolation level 1 is not supported; falling back to default isolation level 2
[2025-04-02T09:18:31.162+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO Executor: Finished task 2.0 in stage 4.0 (TID 14). 1244 bytes result sent to driver
[2025-04-02T09:18:31.167+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 14) in 167 ms on a72b9165479b (executor driver) (1/3)
[2025-04-02T09:18:31.170+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO Executor: Finished task 0.0 in stage 4.0 (TID 12). 1244 bytes result sent to driver
[2025-04-02T09:18:31.172+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO Executor: Finished task 1.0 in stage 4.0 (TID 13). 1244 bytes result sent to driver
[2025-04-02T09:18:31.173+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 12) in 176 ms on a72b9165479b (executor driver) (2/3)
[2025-04-02T09:18:31.175+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 13) in 176 ms on a72b9165479b (executor driver) (3/3)
[2025-04-02T09:18:31.176+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool
[2025-04-02T09:18:31.178+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO DAGScheduler: ResultStage 4 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.202 s
[2025-04-02T09:18:31.181+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-04-02T09:18:31.185+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
[2025-04-02T09:18:31.188+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO DAGScheduler: Job 4 finished: jdbc at NativeMethodAccessorImpl.java:0, took 0.211569 s
[2025-04-02T09:18:31.264+0000] {subprocess.py:106} INFO - Data successfully written to METADATA.TEST5
[2025-04-02T09:18:31.282+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO HiveMetaStore: 0: get_database: default
[2025-04-02T09:18:31.284+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_database: default
[2025-04-02T09:18:31.286+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO HiveMetaStore: 0: get_table : db=default tbl=transformed_data5
[2025-04-02T09:18:31.287+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_table : db=default tbl=transformed_data5
[2025-04-02T09:18:31.304+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO HiveMetaStore: 0: get_table : db=default tbl=transformed_data5
[2025-04-02T09:18:31.306+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_table : db=default tbl=transformed_data5
[2025-04-02T09:18:31.324+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO HiveMetaStore: 0: get_database: default
[2025-04-02T09:18:31.325+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_database: default
[2025-04-02T09:18:31.327+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO HiveMetaStore: 0: get_table : db=default tbl=transformed_data5
[2025-04-02T09:18:31.330+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_table : db=default tbl=transformed_data5
[2025-04-02T09:18:31.351+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO HiveMetaStore: 0: get_table : db=default tbl=transformed_data5
[2025-04-02T09:18:31.353+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_table : db=default tbl=transformed_data5
[2025-04-02T09:18:31.382+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO HiveMetaStore: 0: get_database: default
[2025-04-02T09:18:31.384+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_database: default
[2025-04-02T09:18:31.387+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO HiveMetaStore: 0: get_table : db=default tbl=transformed_data5
[2025-04-02T09:18:31.388+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_table : db=default tbl=transformed_data5
[2025-04-02T09:18:31.410+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO HiveMetaStore: 0: get_database: default
[2025-04-02T09:18:31.412+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_database: default
[2025-04-02T09:18:31.416+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO HiveMetaStore: 0: get_table : db=default tbl=transformed_data5
[2025-04-02T09:18:31.417+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=get_table : db=default tbl=transformed_data5
[2025-04-02T09:18:31.435+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO HiveMetaStore: 0: drop_table : db=default tbl=transformed_data5
[2025-04-02T09:18:31.437+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO audit: ugi=***	ip=unknown-ip-addr	cmd=drop_table : db=default tbl=transformed_data5
[2025-04-02T09:18:31.494+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO SparkContext: SparkContext is stopping with exitCode 0.
[2025-04-02T09:18:31.511+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO SparkUI: Stopped Spark web UI at http://a72b9165479b:4041
[2025-04-02T09:18:31.526+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2025-04-02T09:18:31.545+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO MemoryStore: MemoryStore cleared
[2025-04-02T09:18:31.546+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO BlockManager: BlockManager stopped
[2025-04-02T09:18:31.550+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO BlockManagerMaster: BlockManagerMaster stopped
[2025-04-02T09:18:31.554+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2025-04-02T09:18:31.566+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO SparkContext: Successfully stopped SparkContext
[2025-04-02T09:18:31.751+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO ShutdownHookManager: Shutdown hook called
[2025-04-02T09:18:31.752+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO ShutdownHookManager: Deleting directory /tmp/spark-c3ecda8c-7915-4325-a4da-e9dc39c0e386
[2025-04-02T09:18:31.758+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO ShutdownHookManager: Deleting directory /tmp/spark-b225fb5e-6c08-4f4f-ba48-dfb9c4f10467/pyspark-f539a582-e82a-4d9b-aec5-2482d88be04b
[2025-04-02T09:18:31.766+0000] {subprocess.py:106} INFO - 25/04/02 09:18:31 INFO ShutdownHookManager: Deleting directory /tmp/spark-b225fb5e-6c08-4f4f-ba48-dfb9c4f10467
[2025-04-02T09:18:31.854+0000] {subprocess.py:110} INFO - Command exited with return code 0
[2025-04-02T09:18:31.899+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-02T09:18:31.900+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=etl_dbt_spark_oracle, task_id=spark_load_to_oracle, run_id=manual__2025-04-02T09:16:41.382092+00:00, execution_date=20250402T091641, start_date=20250402T091730, end_date=20250402T091831
[2025-04-02T09:18:31.947+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-04-02T09:18:31.948+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-04-02T09:18:31.949+0000] {logging_mixin.py:190} INFO - Dag name:etl_dbt_spark_oracle queued_at:2025-04-02 09:16:41.553089+00:00
[2025-04-02T09:18:31.950+0000] {logging_mixin.py:190} INFO - Task hostname:a72b9165479b operator:BashOperator
[2025-04-02T09:18:31.999+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-02T09:18:32.026+0000] {taskinstance.py:3901} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-04-02T09:18:32.033+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
